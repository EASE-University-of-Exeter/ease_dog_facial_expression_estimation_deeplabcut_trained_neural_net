2019-03-25 11:00:30 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],
 'all_joints_names': ['mouth_corner_left',
                      'mouth_corner_right',
                      'inner_brow_left',
                      'inner_brow_right',
                      'upper_lip',
                      'lower_lip',
                      'nose_corner_left',
                      'nose_corner_right',
                      'pinna_ear_left',
                      'pinna_ear_right'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\ease_dog_emotions_1_Steve '
            'North95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 5,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\train\\snapshot-34000',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\Documentation_data-ease_dog_emotions_1_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 10,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 2000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                    'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-03-25 11:00:42 Restoring parameters from C:\Users\steve\Anaconda3\envs\ease_dog_emotions\dev\deepcutlab_projects\ease_dog_emotions\ease_dog_emotions_1-Steve North-2019-03-13\dlc-models\iteration-1\ease_dog_emotions_1Mar13-trainset95shuffle1\train\snapshot-34000
2019-03-25 11:02:00 iteration: 5 loss: 0.4859 lr: 0.005
2019-03-25 11:02:16 iteration: 10 loss: 0.0432 lr: 0.005
2019-03-25 11:03:00 iteration: 15 loss: 0.0540 lr: 0.005
2019-03-25 11:03:21 iteration: 20 loss: 0.0338 lr: 0.005
2019-03-25 11:03:31 iteration: 25 loss: 0.0325 lr: 0.005
2019-03-25 11:04:42 iteration: 30 loss: 0.0347 lr: 0.005
2019-03-25 11:05:02 iteration: 35 loss: 0.0293 lr: 0.005
2019-03-25 11:05:32 iteration: 40 loss: 0.0283 lr: 0.005
2019-03-25 11:06:07 iteration: 45 loss: 0.0254 lr: 0.005
2019-03-25 11:06:31 iteration: 50 loss: 0.0194 lr: 0.005
2019-03-25 11:07:07 iteration: 55 loss: 0.0259 lr: 0.005
2019-03-25 11:08:06 iteration: 60 loss: 0.0243 lr: 0.005
2019-03-25 11:08:58 iteration: 65 loss: 0.0282 lr: 0.005
2019-03-25 11:09:10 iteration: 70 loss: 0.0238 lr: 0.005
2019-03-25 11:09:28 iteration: 75 loss: 0.0260 lr: 0.005
2019-03-25 11:09:43 iteration: 80 loss: 0.0262 lr: 0.005
2019-03-25 11:10:32 iteration: 85 loss: 0.0313 lr: 0.005
2019-03-25 11:10:51 iteration: 90 loss: 0.0200 lr: 0.005
2019-03-25 11:12:21 iteration: 95 loss: 0.0161 lr: 0.005
2019-03-25 11:13:43 iteration: 100 loss: 0.0216 lr: 0.005
2019-03-25 11:14:01 iteration: 105 loss: 0.0293 lr: 0.005
2019-03-25 11:14:45 iteration: 110 loss: 0.0184 lr: 0.005
2019-03-25 11:15:21 iteration: 115 loss: 0.0242 lr: 0.005
2019-03-25 11:15:34 iteration: 120 loss: 0.0239 lr: 0.005
2019-03-25 11:16:00 iteration: 125 loss: 0.0233 lr: 0.005
2019-03-25 11:17:08 iteration: 130 loss: 0.0223 lr: 0.005
2019-03-25 11:17:42 iteration: 135 loss: 0.0202 lr: 0.005
2019-03-25 11:17:59 iteration: 140 loss: 0.0209 lr: 0.005
2019-03-25 11:18:22 iteration: 145 loss: 0.0191 lr: 0.005
2019-03-25 11:18:43 iteration: 150 loss: 0.0178 lr: 0.005
2019-03-25 11:19:14 iteration: 155 loss: 0.0202 lr: 0.005
2019-03-25 11:20:19 iteration: 160 loss: 0.0175 lr: 0.005
2019-03-25 11:20:41 iteration: 165 loss: 0.0192 lr: 0.005
2019-03-25 11:20:56 iteration: 170 loss: 0.0227 lr: 0.005
2019-03-25 11:21:39 iteration: 175 loss: 0.0149 lr: 0.005
2019-03-25 11:22:35 iteration: 180 loss: 0.0161 lr: 0.005
2019-03-25 11:22:49 iteration: 185 loss: 0.0165 lr: 0.005
2019-03-25 11:23:27 iteration: 190 loss: 0.0175 lr: 0.005
2019-03-25 11:23:44 iteration: 195 loss: 0.0167 lr: 0.005
2019-03-25 11:24:34 iteration: 200 loss: 0.0162 lr: 0.005
2019-03-25 11:25:27 iteration: 205 loss: 0.0156 lr: 0.005
2019-03-25 11:25:41 iteration: 210 loss: 0.0154 lr: 0.005
2019-03-25 11:25:57 iteration: 215 loss: 0.0199 lr: 0.005
2019-03-25 11:26:17 iteration: 220 loss: 0.0184 lr: 0.005
2019-03-25 11:26:36 iteration: 225 loss: 0.0134 lr: 0.005
2019-03-25 11:28:00 iteration: 230 loss: 0.0108 lr: 0.005
2019-03-25 11:28:15 iteration: 235 loss: 0.0189 lr: 0.005
2019-03-25 11:29:02 iteration: 240 loss: 0.0096 lr: 0.005
2019-03-25 11:29:33 iteration: 245 loss: 0.0128 lr: 0.005
2019-03-25 11:30:20 iteration: 250 loss: 0.0143 lr: 0.005
2019-03-25 11:30:41 iteration: 255 loss: 0.0161 lr: 0.005
2019-03-25 11:31:04 iteration: 260 loss: 0.0128 lr: 0.005
2019-03-25 11:31:33 iteration: 265 loss: 0.0138 lr: 0.005
2019-03-25 11:32:11 iteration: 270 loss: 0.0113 lr: 0.005
2019-03-25 11:32:57 iteration: 275 loss: 0.0103 lr: 0.005
2019-03-25 11:33:14 iteration: 280 loss: 0.0133 lr: 0.005
2019-03-25 11:34:05 iteration: 285 loss: 0.0128 lr: 0.005
2019-03-25 11:34:19 iteration: 290 loss: 0.0145 lr: 0.005
2019-03-25 11:35:18 iteration: 295 loss: 0.0107 lr: 0.005
2019-03-25 11:35:36 iteration: 300 loss: 0.0122 lr: 0.005
2019-03-25 11:36:07 iteration: 305 loss: 0.0163 lr: 0.005
2019-03-25 11:36:22 iteration: 310 loss: 0.0145 lr: 0.005
2019-03-25 11:37:45 iteration: 315 loss: 0.0107 lr: 0.005
2019-03-25 11:38:51 iteration: 320 loss: 0.0090 lr: 0.005
2019-03-25 11:39:43 iteration: 325 loss: 0.0128 lr: 0.005
2019-03-25 11:41:31 iteration: 330 loss: 0.0071 lr: 0.005
2019-03-25 11:42:13 iteration: 335 loss: 0.0121 lr: 0.005
2019-03-25 11:42:34 iteration: 340 loss: 0.0160 lr: 0.005
2019-03-25 11:43:25 iteration: 345 loss: 0.0128 lr: 0.005
2019-03-25 11:44:44 iteration: 350 loss: 0.0090 lr: 0.005
2019-03-25 11:45:25 iteration: 355 loss: 0.0101 lr: 0.005
2019-03-25 11:46:29 iteration: 360 loss: 0.0088 lr: 0.005
2019-03-25 11:46:56 iteration: 365 loss: 0.0148 lr: 0.005
2019-03-25 11:47:13 iteration: 370 loss: 0.0155 lr: 0.005
2019-03-25 11:48:04 iteration: 375 loss: 0.0134 lr: 0.005
2019-03-25 11:48:53 iteration: 380 loss: 0.0125 lr: 0.005
2019-03-25 11:49:59 iteration: 385 loss: 0.0079 lr: 0.005
2019-03-25 11:50:48 iteration: 390 loss: 0.0090 lr: 0.005
2019-03-25 11:51:16 iteration: 395 loss: 0.0114 lr: 0.005
2019-03-25 11:51:49 iteration: 400 loss: 0.0114 lr: 0.005
2019-03-25 11:52:23 iteration: 405 loss: 0.0125 lr: 0.005
2019-03-25 11:52:38 iteration: 410 loss: 0.0109 lr: 0.005
2019-03-25 11:52:56 iteration: 415 loss: 0.0114 lr: 0.005
2019-03-25 11:53:15 iteration: 420 loss: 0.0120 lr: 0.005
2019-03-25 11:53:46 iteration: 425 loss: 0.0104 lr: 0.005
2019-03-25 11:54:44 iteration: 430 loss: 0.0106 lr: 0.005
2019-03-25 11:55:53 iteration: 435 loss: 0.0064 lr: 0.005
2019-03-25 11:56:17 iteration: 440 loss: 0.0121 lr: 0.005
2019-03-25 11:57:11 iteration: 445 loss: 0.0119 lr: 0.005
2019-03-25 11:57:33 iteration: 450 loss: 0.0107 lr: 0.005
2019-03-25 11:57:49 iteration: 455 loss: 0.0106 lr: 0.005
2019-03-25 11:58:08 iteration: 460 loss: 0.0117 lr: 0.005
2019-03-25 11:58:35 iteration: 465 loss: 0.0109 lr: 0.005
2019-03-25 11:59:22 iteration: 470 loss: 0.0098 lr: 0.005
2019-03-25 12:00:18 iteration: 475 loss: 0.0077 lr: 0.005
2019-03-25 12:01:30 iteration: 480 loss: 0.0091 lr: 0.005
2019-03-25 12:02:04 iteration: 485 loss: 0.0121 lr: 0.005
2019-03-25 12:02:46 iteration: 490 loss: 0.0117 lr: 0.005
2019-03-25 12:03:05 iteration: 495 loss: 0.0145 lr: 0.005
2019-03-25 12:04:03 iteration: 500 loss: 0.0103 lr: 0.005
2019-03-25 12:05:20 iteration: 505 loss: 0.0103 lr: 0.005
2019-03-25 12:05:55 iteration: 510 loss: 0.0109 lr: 0.005
2019-03-25 12:06:14 iteration: 515 loss: 0.0107 lr: 0.005
2019-03-25 12:07:20 iteration: 520 loss: 0.0138 lr: 0.005
2019-03-25 12:07:54 iteration: 525 loss: 0.0113 lr: 0.005
2019-03-25 12:08:17 iteration: 530 loss: 0.0098 lr: 0.005
2019-03-25 12:08:33 iteration: 535 loss: 0.0096 lr: 0.005
2019-03-25 12:09:23 iteration: 540 loss: 0.0086 lr: 0.005
2019-03-25 12:09:40 iteration: 545 loss: 0.0104 lr: 0.005
2019-03-25 12:10:08 iteration: 550 loss: 0.0091 lr: 0.005
2019-03-25 12:10:39 iteration: 555 loss: 0.0131 lr: 0.005
2019-03-25 12:11:04 iteration: 560 loss: 0.0096 lr: 0.005
2019-03-25 12:11:25 iteration: 565 loss: 0.0117 lr: 0.005
2019-03-25 12:12:04 iteration: 570 loss: 0.0087 lr: 0.005
2019-03-25 12:12:44 iteration: 575 loss: 0.0084 lr: 0.005
2019-03-25 12:12:59 iteration: 580 loss: 0.0100 lr: 0.005
2019-03-25 12:13:18 iteration: 585 loss: 0.0111 lr: 0.005
2019-03-25 12:13:24 iteration: 590 loss: 0.0141 lr: 0.005
2019-03-25 12:13:46 iteration: 595 loss: 0.0085 lr: 0.005
2019-03-25 12:14:23 iteration: 600 loss: 0.0108 lr: 0.005
2019-03-25 12:14:52 iteration: 605 loss: 0.0065 lr: 0.005
2019-03-25 12:15:22 iteration: 610 loss: 0.0088 lr: 0.005
2019-03-25 12:16:07 iteration: 615 loss: 0.0084 lr: 0.005
2019-03-25 12:17:15 iteration: 620 loss: 0.0080 lr: 0.005
2019-03-25 12:17:40 iteration: 625 loss: 0.0101 lr: 0.005
2019-03-25 12:18:13 iteration: 630 loss: 0.0103 lr: 0.005
2019-03-25 12:18:47 iteration: 635 loss: 0.0095 lr: 0.005
2019-03-25 12:19:11 iteration: 640 loss: 0.0082 lr: 0.005
2019-03-25 12:19:45 iteration: 645 loss: 0.0092 lr: 0.005
2019-03-25 12:20:06 iteration: 650 loss: 0.0090 lr: 0.005
2019-03-25 12:20:26 iteration: 655 loss: 0.0073 lr: 0.005
2019-03-25 12:20:43 iteration: 660 loss: 0.0122 lr: 0.005
2019-03-25 12:20:59 iteration: 665 loss: 0.0106 lr: 0.005
2019-03-25 12:21:41 iteration: 670 loss: 0.0091 lr: 0.005
2019-03-25 12:21:55 iteration: 675 loss: 0.0126 lr: 0.005
2019-03-25 12:23:04 iteration: 680 loss: 0.0059 lr: 0.005
2019-03-25 12:23:46 iteration: 685 loss: 0.0086 lr: 0.005
2019-03-25 12:24:23 iteration: 690 loss: 0.0068 lr: 0.005
2019-03-25 12:24:49 iteration: 695 loss: 0.0078 lr: 0.005
2019-03-25 12:25:02 iteration: 700 loss: 0.0087 lr: 0.005
2019-03-25 12:25:51 iteration: 705 loss: 0.0092 lr: 0.005
2019-03-25 12:26:10 iteration: 710 loss: 0.0089 lr: 0.005
2019-03-25 12:26:28 iteration: 715 loss: 0.0080 lr: 0.005
2019-03-25 12:26:44 iteration: 720 loss: 0.0103 lr: 0.005
2019-03-25 12:27:41 iteration: 725 loss: 0.0118 lr: 0.005
2019-03-25 12:28:00 iteration: 730 loss: 0.0103 lr: 0.005
2019-03-25 12:28:40 iteration: 735 loss: 0.0072 lr: 0.005
2019-03-25 12:28:57 iteration: 740 loss: 0.0098 lr: 0.005
2019-03-25 12:29:11 iteration: 745 loss: 0.0106 lr: 0.005
2019-03-25 12:29:55 iteration: 750 loss: 0.0088 lr: 0.005
2019-03-25 12:30:51 iteration: 755 loss: 0.0076 lr: 0.005
2019-03-25 12:31:26 iteration: 760 loss: 0.0071 lr: 0.005
2019-03-25 12:31:42 iteration: 765 loss: 0.0079 lr: 0.005
2019-03-25 12:32:12 iteration: 770 loss: 0.0103 lr: 0.005
2019-03-25 12:32:27 iteration: 775 loss: 0.0094 lr: 0.005
2019-03-25 12:33:07 iteration: 780 loss: 0.0089 lr: 0.005
2019-03-25 12:33:22 iteration: 785 loss: 0.0072 lr: 0.005
2019-03-25 12:34:04 iteration: 790 loss: 0.0086 lr: 0.005
2019-03-25 12:34:25 iteration: 795 loss: 0.0094 lr: 0.005
2019-03-25 12:35:24 iteration: 800 loss: 0.0085 lr: 0.005
2019-03-25 12:35:48 iteration: 805 loss: 0.0103 lr: 0.005
2019-03-25 12:36:15 iteration: 810 loss: 0.0070 lr: 0.005
2019-03-25 12:36:53 iteration: 815 loss: 0.0083 lr: 0.005
2019-03-25 12:37:17 iteration: 820 loss: 0.0083 lr: 0.005
2019-03-25 12:37:27 iteration: 825 loss: 0.0114 lr: 0.005
2019-03-25 12:38:20 iteration: 830 loss: 0.0096 lr: 0.005
2019-03-25 12:38:37 iteration: 835 loss: 0.0089 lr: 0.005
2019-03-25 12:39:21 iteration: 840 loss: 0.0100 lr: 0.005
2019-03-25 12:40:08 iteration: 845 loss: 0.0073 lr: 0.005
2019-03-25 12:41:25 iteration: 850 loss: 0.0086 lr: 0.005
2019-03-25 12:42:21 iteration: 855 loss: 0.0063 lr: 0.005
2019-03-25 12:42:49 iteration: 860 loss: 0.0071 lr: 0.005
2019-03-25 12:43:27 iteration: 865 loss: 0.0060 lr: 0.005
2019-03-25 12:44:10 iteration: 870 loss: 0.0053 lr: 0.005
2019-03-25 12:44:27 iteration: 875 loss: 0.0100 lr: 0.005
2019-03-25 12:44:46 iteration: 880 loss: 0.0072 lr: 0.005
2019-03-25 12:45:34 iteration: 885 loss: 0.0085 lr: 0.005
2019-03-25 12:46:07 iteration: 890 loss: 0.0090 lr: 0.005
2019-03-25 12:46:19 iteration: 895 loss: 0.0087 lr: 0.005
2019-03-25 12:46:29 iteration: 900 loss: 0.0086 lr: 0.005
2019-03-25 12:46:50 iteration: 905 loss: 0.0124 lr: 0.005
2019-03-25 12:47:26 iteration: 910 loss: 0.0062 lr: 0.005
2019-03-25 12:48:48 iteration: 915 loss: 0.0067 lr: 0.005
2019-03-25 12:49:42 iteration: 920 loss: 0.0066 lr: 0.005
2019-03-25 12:50:32 iteration: 925 loss: 0.0109 lr: 0.005
2019-03-25 12:51:53 iteration: 930 loss: 0.0064 lr: 0.005
2019-03-25 12:52:19 iteration: 935 loss: 0.0104 lr: 0.005
2019-03-25 12:52:53 iteration: 940 loss: 0.0075 lr: 0.005
2019-03-25 12:53:13 iteration: 945 loss: 0.0133 lr: 0.005
2019-03-25 12:53:38 iteration: 950 loss: 0.0092 lr: 0.005
2019-03-25 12:54:03 iteration: 955 loss: 0.0097 lr: 0.005
2019-03-25 12:54:43 iteration: 960 loss: 0.0074 lr: 0.005
2019-03-25 12:55:01 iteration: 965 loss: 0.0093 lr: 0.005
2019-03-25 12:55:18 iteration: 970 loss: 0.0086 lr: 0.005
2019-03-25 12:55:38 iteration: 975 loss: 0.0062 lr: 0.005
2019-03-25 12:55:56 iteration: 980 loss: 0.0091 lr: 0.005
2019-03-25 12:56:07 iteration: 985 loss: 0.0067 lr: 0.005
2019-03-25 12:57:20 iteration: 990 loss: 0.0057 lr: 0.005
2019-03-25 12:57:59 iteration: 995 loss: 0.0066 lr: 0.005
2019-03-25 12:58:18 iteration: 1000 loss: 0.0085 lr: 0.005
2019-03-25 12:59:07 iteration: 1005 loss: 0.0061 lr: 0.005
2019-03-25 13:00:40 iteration: 1010 loss: 0.0059 lr: 0.005
2019-03-25 13:00:50 iteration: 1015 loss: 0.0082 lr: 0.005
2019-03-25 13:01:43 iteration: 1020 loss: 0.0078 lr: 0.005
2019-03-25 13:02:01 iteration: 1025 loss: 0.0076 lr: 0.005
2019-03-25 13:02:20 iteration: 1030 loss: 0.0079 lr: 0.005
2019-03-25 13:02:48 iteration: 1035 loss: 0.0069 lr: 0.005
2019-03-25 13:03:05 iteration: 1040 loss: 0.0115 lr: 0.005
2019-03-25 13:03:48 iteration: 1045 loss: 0.0071 lr: 0.005
2019-03-25 13:04:53 iteration: 1050 loss: 0.0065 lr: 0.005
2019-03-25 13:05:29 iteration: 1055 loss: 0.0070 lr: 0.005
2019-03-25 13:05:59 iteration: 1060 loss: 0.0064 lr: 0.005
2019-03-25 13:07:07 iteration: 1065 loss: 0.0066 lr: 0.005
2019-03-25 13:07:53 iteration: 1070 loss: 0.0065 lr: 0.005
2019-03-25 13:08:40 iteration: 1075 loss: 0.0068 lr: 0.005
2019-03-25 13:08:55 iteration: 1080 loss: 0.0071 lr: 0.005
2019-03-25 13:09:35 iteration: 1085 loss: 0.0067 lr: 0.005
2019-03-25 13:10:04 iteration: 1090 loss: 0.0070 lr: 0.005
2019-03-25 13:10:37 iteration: 1095 loss: 0.0064 lr: 0.005
2019-03-25 13:10:47 iteration: 1100 loss: 0.0078 lr: 0.005
2019-03-25 13:11:18 iteration: 1105 loss: 0.0074 lr: 0.005
2019-03-25 13:11:45 iteration: 1110 loss: 0.0077 lr: 0.005
2019-03-25 13:12:19 iteration: 1115 loss: 0.0070 lr: 0.005
2019-03-25 13:13:31 iteration: 1120 loss: 0.0064 lr: 0.005
2019-03-25 13:14:25 iteration: 1125 loss: 0.0050 lr: 0.005
2019-03-25 13:15:36 iteration: 1130 loss: 0.0080 lr: 0.005
2019-03-25 13:16:05 iteration: 1135 loss: 0.0080 lr: 0.005
2019-03-25 13:16:20 iteration: 1140 loss: 0.0095 lr: 0.005
2019-03-25 13:17:02 iteration: 1145 loss: 0.0074 lr: 0.005
2019-03-25 13:17:51 iteration: 1150 loss: 0.0077 lr: 0.005
2019-03-25 13:18:52 iteration: 1155 loss: 0.0062 lr: 0.005
2019-03-25 13:19:19 iteration: 1160 loss: 0.0083 lr: 0.005
2019-03-25 13:20:09 iteration: 1165 loss: 0.0067 lr: 0.005
2019-03-25 13:20:56 iteration: 1170 loss: 0.0082 lr: 0.005
2019-03-25 13:21:48 iteration: 1175 loss: 0.0088 lr: 0.005
2019-03-25 13:22:00 iteration: 1180 loss: 0.0075 lr: 0.005
2019-03-25 13:22:37 iteration: 1185 loss: 0.0062 lr: 0.005
2019-03-25 13:23:37 iteration: 1190 loss: 0.0063 lr: 0.005
2019-03-25 13:24:50 iteration: 1195 loss: 0.0075 lr: 0.005
2019-03-25 13:26:56 iteration: 1200 loss: 0.0066 lr: 0.005
2019-03-25 13:27:56 iteration: 1205 loss: 0.0088 lr: 0.005
2019-03-25 13:28:52 iteration: 1210 loss: 0.0055 lr: 0.005
2019-03-25 13:29:25 iteration: 1215 loss: 0.0064 lr: 0.005
2019-03-25 13:30:38 iteration: 1220 loss: 0.0055 lr: 0.005
2019-03-25 13:30:53 iteration: 1225 loss: 0.0060 lr: 0.005
2019-03-25 13:31:53 iteration: 1230 loss: 0.0076 lr: 0.005
2019-03-25 13:32:30 iteration: 1235 loss: 0.0079 lr: 0.005
2019-03-25 13:32:56 iteration: 1240 loss: 0.0082 lr: 0.005
2019-03-25 13:33:41 iteration: 1245 loss: 0.0068 lr: 0.005
2019-03-25 13:34:00 iteration: 1250 loss: 0.0061 lr: 0.005
2019-03-25 13:35:18 iteration: 1255 loss: 0.0057 lr: 0.005
2019-03-25 13:35:43 iteration: 1260 loss: 0.0083 lr: 0.005
2019-03-25 13:36:46 iteration: 1265 loss: 0.0051 lr: 0.005
2019-03-25 13:37:43 iteration: 1270 loss: 0.0076 lr: 0.005
2019-03-25 13:38:14 iteration: 1275 loss: 0.0087 lr: 0.005
2019-03-25 13:38:52 iteration: 1280 loss: 0.0054 lr: 0.005
2019-03-25 13:39:06 iteration: 1285 loss: 0.0082 lr: 0.005
2019-03-25 13:39:25 iteration: 1290 loss: 0.0092 lr: 0.005
2019-03-25 13:39:42 iteration: 1295 loss: 0.0077 lr: 0.005
2019-03-25 13:40:14 iteration: 1300 loss: 0.0055 lr: 0.005
2019-03-25 13:41:07 iteration: 1305 loss: 0.0049 lr: 0.005
2019-03-25 13:41:42 iteration: 1310 loss: 0.0087 lr: 0.005
2019-03-25 13:42:38 iteration: 1315 loss: 0.0081 lr: 0.005
2019-03-25 13:43:06 iteration: 1320 loss: 0.0082 lr: 0.005
2019-03-25 13:43:26 iteration: 1325 loss: 0.0067 lr: 0.005
2019-03-25 13:43:53 iteration: 1330 loss: 0.0056 lr: 0.005
2019-03-25 13:44:23 iteration: 1335 loss: 0.0073 lr: 0.005
2019-03-25 13:44:53 iteration: 1340 loss: 0.0068 lr: 0.005
2019-03-25 13:45:28 iteration: 1345 loss: 0.0071 lr: 0.005
2019-03-25 13:46:06 iteration: 1350 loss: 0.0049 lr: 0.005
2019-03-25 13:46:34 iteration: 1355 loss: 0.0074 lr: 0.005
2019-03-25 13:47:00 iteration: 1360 loss: 0.0090 lr: 0.005
2019-03-25 13:47:39 iteration: 1365 loss: 0.0083 lr: 0.005
2019-03-25 13:48:13 iteration: 1370 loss: 0.0067 lr: 0.005
2019-03-25 13:48:35 iteration: 1375 loss: 0.0083 lr: 0.005
2019-03-25 13:50:03 iteration: 1380 loss: 0.0057 lr: 0.005
2019-03-25 13:50:32 iteration: 1385 loss: 0.0075 lr: 0.005
2019-03-25 13:50:39 iteration: 1390 loss: 0.0081 lr: 0.005
2019-03-25 13:52:23 iteration: 1395 loss: 0.0052 lr: 0.005
2019-03-25 13:53:34 iteration: 1400 loss: 0.0065 lr: 0.005
2019-03-25 13:54:13 iteration: 1405 loss: 0.0061 lr: 0.005
2019-03-25 13:54:28 iteration: 1410 loss: 0.0078 lr: 0.005
2019-03-25 13:55:22 iteration: 1415 loss: 0.0068 lr: 0.005
2019-03-25 13:55:37 iteration: 1420 loss: 0.0080 lr: 0.005
2019-03-25 13:56:49 iteration: 1425 loss: 0.0068 lr: 0.005
2019-03-25 13:57:12 iteration: 1430 loss: 0.0078 lr: 0.005
2019-03-25 13:58:12 iteration: 1435 loss: 0.0070 lr: 0.005
2019-03-25 13:58:33 iteration: 1440 loss: 0.0081 lr: 0.005
2019-03-25 13:59:37 iteration: 1445 loss: 0.0042 lr: 0.005
2019-03-25 13:59:56 iteration: 1450 loss: 0.0065 lr: 0.005
2019-03-25 14:00:48 iteration: 1455 loss: 0.0066 lr: 0.005
2019-03-25 14:01:56 iteration: 1460 loss: 0.0048 lr: 0.005
2019-03-25 14:02:33 iteration: 1465 loss: 0.0069 lr: 0.005
2019-03-25 14:02:51 iteration: 1470 loss: 0.0089 lr: 0.005
2019-03-25 14:03:32 iteration: 1475 loss: 0.0083 lr: 0.005
2019-03-25 14:03:42 iteration: 1480 loss: 0.0061 lr: 0.005
2019-03-25 14:04:26 iteration: 1485 loss: 0.0078 lr: 0.005
2019-03-25 14:04:37 iteration: 1490 loss: 0.0071 lr: 0.005
2019-03-25 14:06:22 iteration: 1495 loss: 0.0045 lr: 0.005
2019-03-25 14:07:06 iteration: 1500 loss: 0.0077 lr: 0.005
2019-03-25 14:07:24 iteration: 1505 loss: 0.0065 lr: 0.005
2019-03-25 14:07:37 iteration: 1510 loss: 0.0096 lr: 0.005
2019-03-25 14:08:33 iteration: 1515 loss: 0.0044 lr: 0.005
2019-03-25 14:09:04 iteration: 1520 loss: 0.0063 lr: 0.005
2019-03-25 14:10:13 iteration: 1525 loss: 0.0038 lr: 0.005
2019-03-25 14:10:46 iteration: 1530 loss: 0.0113 lr: 0.005
2019-03-25 14:10:58 iteration: 1535 loss: 0.0072 lr: 0.005
2019-03-25 14:12:19 iteration: 1540 loss: 0.0059 lr: 0.005
2019-03-25 14:13:10 iteration: 1545 loss: 0.0073 lr: 0.005
2019-03-25 14:14:01 iteration: 1550 loss: 0.0075 lr: 0.005
2019-03-25 14:15:22 iteration: 1555 loss: 0.0051 lr: 0.005
2019-03-25 14:15:36 iteration: 1560 loss: 0.0064 lr: 0.005
2019-03-25 14:15:56 iteration: 1565 loss: 0.0072 lr: 0.005
2019-03-25 14:16:42 iteration: 1570 loss: 0.0067 lr: 0.005
2019-03-25 14:17:43 iteration: 1575 loss: 0.0051 lr: 0.005
2019-03-25 14:17:57 iteration: 1580 loss: 0.0059 lr: 0.005
2019-03-25 14:18:41 iteration: 1585 loss: 0.0073 lr: 0.005
2019-03-25 14:19:08 iteration: 1590 loss: 0.0086 lr: 0.005
2019-03-25 14:19:24 iteration: 1595 loss: 0.0060 lr: 0.005
2019-03-25 14:20:23 iteration: 1600 loss: 0.0058 lr: 0.005
2019-03-25 14:20:38 iteration: 1605 loss: 0.0072 lr: 0.005
2019-03-25 14:21:40 iteration: 1610 loss: 0.0049 lr: 0.005
2019-03-25 14:22:00 iteration: 1615 loss: 0.0125 lr: 0.005
2019-03-25 14:22:33 iteration: 1620 loss: 0.0090 lr: 0.005
2019-03-25 14:23:19 iteration: 1625 loss: 0.0103 lr: 0.005
2019-03-25 14:23:38 iteration: 1630 loss: 0.0085 lr: 0.005
2019-03-25 14:24:18 iteration: 1635 loss: 0.0059 lr: 0.005
2019-03-25 14:24:49 iteration: 1640 loss: 0.0077 lr: 0.005
2019-03-25 14:25:41 iteration: 1645 loss: 0.0044 lr: 0.005
2019-03-25 14:25:54 iteration: 1650 loss: 0.0092 lr: 0.005
2019-03-25 14:26:18 iteration: 1655 loss: 0.0056 lr: 0.005
2019-03-25 14:26:55 iteration: 1660 loss: 0.0055 lr: 0.005
2019-03-25 14:28:51 iteration: 1665 loss: 0.0053 lr: 0.005
2019-03-25 14:29:07 iteration: 1670 loss: 0.0060 lr: 0.005
2019-03-25 14:29:58 iteration: 1675 loss: 0.0062 lr: 0.005
2019-03-25 14:30:10 iteration: 1680 loss: 0.0064 lr: 0.005
2019-03-25 14:31:07 iteration: 1685 loss: 0.0063 lr: 0.005
2019-03-25 14:31:36 iteration: 1690 loss: 0.0066 lr: 0.005
2019-03-25 14:31:55 iteration: 1695 loss: 0.0049 lr: 0.005
2019-03-25 14:32:05 iteration: 1700 loss: 0.0069 lr: 0.005
2019-03-25 14:32:31 iteration: 1705 loss: 0.0062 lr: 0.005
2019-03-25 14:33:06 iteration: 1710 loss: 0.0072 lr: 0.005
2019-03-25 14:33:51 iteration: 1715 loss: 0.0072 lr: 0.005
2019-03-25 14:34:10 iteration: 1720 loss: 0.0057 lr: 0.005
2019-03-25 14:34:39 iteration: 1725 loss: 0.0048 lr: 0.005
2019-03-25 14:35:14 iteration: 1730 loss: 0.0062 lr: 0.005
2019-03-25 14:35:32 iteration: 1735 loss: 0.0074 lr: 0.005
2019-03-25 14:37:00 iteration: 1740 loss: 0.0078 lr: 0.005
2019-03-25 14:37:37 iteration: 1745 loss: 0.0061 lr: 0.005
2019-03-25 14:38:27 iteration: 1750 loss: 0.0069 lr: 0.005
2019-03-25 14:38:35 iteration: 1755 loss: 0.0085 lr: 0.005
2019-03-25 14:39:29 iteration: 1760 loss: 0.0050 lr: 0.005
2019-03-25 14:40:11 iteration: 1765 loss: 0.0061 lr: 0.005
2019-03-25 14:40:33 iteration: 1770 loss: 0.0077 lr: 0.005
2019-03-25 14:41:06 iteration: 1775 loss: 0.0059 lr: 0.005
2019-03-25 14:41:56 iteration: 1780 loss: 0.0046 lr: 0.005
2019-03-25 14:42:34 iteration: 1785 loss: 0.0076 lr: 0.005
2019-03-25 14:43:32 iteration: 1790 loss: 0.0048 lr: 0.005
2019-03-25 14:44:39 iteration: 1795 loss: 0.0065 lr: 0.005
2019-03-25 14:45:13 iteration: 1800 loss: 0.0055 lr: 0.005
2019-03-25 14:46:25 iteration: 1805 loss: 0.0037 lr: 0.005
2019-03-25 14:47:16 iteration: 1810 loss: 0.0061 lr: 0.005
2019-03-25 14:48:38 iteration: 1815 loss: 0.0081 lr: 0.005
2019-03-25 14:49:37 iteration: 1820 loss: 0.0043 lr: 0.005
2019-03-25 14:50:35 iteration: 1825 loss: 0.0076 lr: 0.005
2019-03-25 14:51:39 iteration: 1830 loss: 0.0055 lr: 0.005
2019-03-25 14:51:55 iteration: 1835 loss: 0.0068 lr: 0.005
2019-03-25 14:52:29 iteration: 1840 loss: 0.0072 lr: 0.005
2019-03-25 14:52:53 iteration: 1845 loss: 0.0059 lr: 0.005
2019-03-25 14:53:13 iteration: 1850 loss: 0.0066 lr: 0.005
2019-03-25 14:53:34 iteration: 1855 loss: 0.0075 lr: 0.005
2019-03-25 14:54:10 iteration: 1860 loss: 0.0046 lr: 0.005
2019-03-25 14:54:44 iteration: 1865 loss: 0.0048 lr: 0.005
2019-03-25 14:54:58 iteration: 1870 loss: 0.0053 lr: 0.005
2019-03-25 14:55:40 iteration: 1875 loss: 0.0050 lr: 0.005
2019-03-25 14:57:04 iteration: 1880 loss: 0.0064 lr: 0.005
2019-03-25 14:57:22 iteration: 1885 loss: 0.0078 lr: 0.005
2019-03-25 14:58:11 iteration: 1890 loss: 0.0055 lr: 0.005
2019-03-25 14:58:36 iteration: 1895 loss: 0.0061 lr: 0.005
2019-03-25 14:58:45 iteration: 1900 loss: 0.0065 lr: 0.005
2019-03-25 14:58:56 iteration: 1905 loss: 0.0069 lr: 0.005
2019-03-25 14:59:24 iteration: 1910 loss: 0.0066 lr: 0.005
2019-03-25 15:00:17 iteration: 1915 loss: 0.0056 lr: 0.005
2019-03-25 15:01:06 iteration: 1920 loss: 0.0067 lr: 0.005
2019-03-25 15:01:20 iteration: 1925 loss: 0.0059 lr: 0.005
2019-03-25 15:01:36 iteration: 1930 loss: 0.0064 lr: 0.005
2019-03-25 15:02:43 iteration: 1935 loss: 0.0049 lr: 0.005
2019-03-25 15:03:29 iteration: 1940 loss: 0.0062 lr: 0.005
2019-03-25 15:03:44 iteration: 1945 loss: 0.0076 lr: 0.005
2019-03-25 15:04:26 iteration: 1950 loss: 0.0053 lr: 0.005
2019-03-25 15:06:13 iteration: 1955 loss: 0.0044 lr: 0.005
2019-03-25 15:06:38 iteration: 1960 loss: 0.0053 lr: 0.005
2019-03-25 15:07:09 iteration: 1965 loss: 0.0063 lr: 0.005
2019-03-25 15:07:20 iteration: 1970 loss: 0.0056 lr: 0.005
2019-03-25 15:07:55 iteration: 1975 loss: 0.0091 lr: 0.005
2019-03-25 15:08:13 iteration: 1980 loss: 0.0052 lr: 0.005
2019-03-25 15:08:46 iteration: 1985 loss: 0.0043 lr: 0.005
2019-03-25 15:09:39 iteration: 1990 loss: 0.0049 lr: 0.005
2019-03-25 15:10:10 iteration: 1995 loss: 0.0067 lr: 0.005
2019-03-25 15:10:35 iteration: 2000 loss: 0.0061 lr: 0.005
2019-03-25 15:10:56 iteration: 2005 loss: 0.0059 lr: 0.005
2019-03-25 15:11:12 iteration: 2010 loss: 0.0066 lr: 0.005
2019-03-25 15:11:32 iteration: 2015 loss: 0.0113 lr: 0.005
2019-03-25 15:12:56 iteration: 2020 loss: 0.0063 lr: 0.005
2019-03-25 15:13:59 iteration: 2025 loss: 0.0053 lr: 0.005
2019-03-25 15:15:01 iteration: 2030 loss: 0.0052 lr: 0.005
2019-03-25 15:15:18 iteration: 2035 loss: 0.0062 lr: 0.005
2019-03-25 15:16:45 iteration: 2040 loss: 0.0098 lr: 0.005
2019-03-25 15:17:13 iteration: 2045 loss: 0.0057 lr: 0.005
2019-03-25 15:18:06 iteration: 2050 loss: 0.0078 lr: 0.005
2019-03-25 15:18:38 iteration: 2055 loss: 0.0072 lr: 0.005
2019-03-25 15:19:09 iteration: 2060 loss: 0.0077 lr: 0.005
2019-03-25 15:19:23 iteration: 2065 loss: 0.0055 lr: 0.005
2019-03-25 15:20:14 iteration: 2070 loss: 0.0059 lr: 0.005
2019-03-25 15:21:02 iteration: 2075 loss: 0.0047 lr: 0.005
2019-03-25 15:21:21 iteration: 2080 loss: 0.0086 lr: 0.005
2019-03-25 15:21:36 iteration: 2085 loss: 0.0064 lr: 0.005
2019-03-25 15:22:33 iteration: 2090 loss: 0.0075 lr: 0.005
2019-03-25 15:23:39 iteration: 2095 loss: 0.0063 lr: 0.005
2019-03-25 15:25:04 iteration: 2100 loss: 0.0064 lr: 0.005
2019-03-25 15:25:42 iteration: 2105 loss: 0.0051 lr: 0.005
2019-03-25 15:25:58 iteration: 2110 loss: 0.0083 lr: 0.005
2019-03-25 15:26:15 iteration: 2115 loss: 0.0064 lr: 0.005
2019-03-25 15:26:33 iteration: 2120 loss: 0.0065 lr: 0.005
2019-03-25 15:26:50 iteration: 2125 loss: 0.0059 lr: 0.005
2019-03-25 15:27:14 iteration: 2130 loss: 0.0068 lr: 0.005
2019-03-25 15:27:41 iteration: 2135 loss: 0.0047 lr: 0.005
2019-03-25 15:28:44 iteration: 2140 loss: 0.0039 lr: 0.005
2019-03-25 15:29:32 iteration: 2145 loss: 0.0046 lr: 0.005
2019-03-25 15:29:45 iteration: 2150 loss: 0.0062 lr: 0.005
2019-03-25 15:30:24 iteration: 2155 loss: 0.0112 lr: 0.005
2019-03-25 15:30:53 iteration: 2160 loss: 0.0057 lr: 0.005
2019-03-25 15:31:07 iteration: 2165 loss: 0.0065 lr: 0.005
2019-03-25 15:31:32 iteration: 2170 loss: 0.0045 lr: 0.005
2019-03-25 15:32:24 iteration: 2175 loss: 0.0056 lr: 0.005
2019-03-25 15:32:43 iteration: 2180 loss: 0.0054 lr: 0.005
2019-03-25 15:33:14 iteration: 2185 loss: 0.0066 lr: 0.005
2019-03-25 15:33:58 iteration: 2190 loss: 0.0064 lr: 0.005
2019-03-25 15:34:05 iteration: 2195 loss: 0.0079 lr: 0.005
2019-03-25 15:36:35 iteration: 2200 loss: 0.0057 lr: 0.005
2019-03-25 15:37:13 iteration: 2205 loss: 0.0055 lr: 0.005
2019-03-25 15:37:38 iteration: 2210 loss: 0.0068 lr: 0.005
2019-03-25 15:37:53 iteration: 2215 loss: 0.0069 lr: 0.005
2019-03-25 15:38:16 iteration: 2220 loss: 0.0057 lr: 0.005
2019-03-25 15:39:01 iteration: 2225 loss: 0.0070 lr: 0.005
2019-03-25 15:39:17 iteration: 2230 loss: 0.0054 lr: 0.005
2019-03-25 15:39:45 iteration: 2235 loss: 0.0049 lr: 0.005
2019-03-25 15:41:01 iteration: 2240 loss: 0.0061 lr: 0.005
2019-03-25 15:41:48 iteration: 2245 loss: 0.0087 lr: 0.005
2019-03-25 15:42:06 iteration: 2250 loss: 0.0096 lr: 0.005
2019-03-25 15:43:20 iteration: 2255 loss: 0.0043 lr: 0.005
2019-03-25 15:45:07 iteration: 2260 loss: 0.0051 lr: 0.005
2019-03-25 15:45:52 iteration: 2265 loss: 0.0062 lr: 0.005
2019-03-25 15:47:12 iteration: 2270 loss: 0.0052 lr: 0.005
2019-03-25 15:47:29 iteration: 2275 loss: 0.0061 lr: 0.005
2019-03-25 15:48:26 iteration: 2280 loss: 0.0061 lr: 0.005
2019-03-25 15:48:45 iteration: 2285 loss: 0.0055 lr: 0.005
2019-03-25 15:49:32 iteration: 2290 loss: 0.0051 lr: 0.005
2019-03-25 15:50:14 iteration: 2295 loss: 0.0071 lr: 0.005
2019-03-25 15:50:39 iteration: 2300 loss: 0.0068 lr: 0.005
2019-03-25 15:51:36 iteration: 2305 loss: 0.0060 lr: 0.005
2019-03-25 15:52:37 iteration: 2310 loss: 0.0070 lr: 0.005
2019-03-25 15:53:05 iteration: 2315 loss: 0.0062 lr: 0.005
2019-03-25 15:53:24 iteration: 2320 loss: 0.0072 lr: 0.005
2019-03-25 15:53:39 iteration: 2325 loss: 0.0061 lr: 0.005
2019-03-25 15:54:29 iteration: 2330 loss: 0.0042 lr: 0.005
2019-03-25 15:55:02 iteration: 2335 loss: 0.0060 lr: 0.005
2019-03-25 15:55:49 iteration: 2340 loss: 0.0054 lr: 0.005
2019-03-25 15:56:28 iteration: 2345 loss: 0.0057 lr: 0.005
2019-03-25 15:57:05 iteration: 2350 loss: 0.0070 lr: 0.005
2019-03-25 15:57:42 iteration: 2355 loss: 0.0055 lr: 0.005
2019-03-25 15:57:58 iteration: 2360 loss: 0.0059 lr: 0.005
2019-03-25 15:58:18 iteration: 2365 loss: 0.0070 lr: 0.005
2019-03-25 15:58:55 iteration: 2370 loss: 0.0055 lr: 0.005
2019-03-25 15:59:54 iteration: 2375 loss: 0.0090 lr: 0.005
2019-03-25 16:00:16 iteration: 2380 loss: 0.0067 lr: 0.005
2019-03-25 16:00:30 iteration: 2385 loss: 0.0064 lr: 0.005
2019-03-25 16:01:21 iteration: 2390 loss: 0.0062 lr: 0.005
2019-03-25 16:01:36 iteration: 2395 loss: 0.0111 lr: 0.005
2019-03-25 16:01:57 iteration: 2400 loss: 0.0073 lr: 0.005
2019-03-25 16:02:21 iteration: 2405 loss: 0.0075 lr: 0.005
2019-03-25 16:03:15 iteration: 2410 loss: 0.0057 lr: 0.005
2019-03-25 16:03:53 iteration: 2415 loss: 0.0047 lr: 0.005
2019-03-25 16:05:36 iteration: 2420 loss: 0.0079 lr: 0.005
2019-03-25 16:06:17 iteration: 2425 loss: 0.0054 lr: 0.005
2019-03-25 16:07:05 iteration: 2430 loss: 0.0048 lr: 0.005
2019-03-25 16:07:21 iteration: 2435 loss: 0.0059 lr: 0.005
2019-03-25 16:07:47 iteration: 2440 loss: 0.0082 lr: 0.005
2019-03-25 16:08:28 iteration: 2445 loss: 0.0058 lr: 0.005
2019-03-25 16:09:14 iteration: 2450 loss: 0.0053 lr: 0.005
2019-03-25 16:09:45 iteration: 2455 loss: 0.0050 lr: 0.005
2019-03-25 16:10:04 iteration: 2460 loss: 0.0055 lr: 0.005
2019-03-25 16:10:37 iteration: 2465 loss: 0.0052 lr: 0.005
2019-03-25 16:11:24 iteration: 2470 loss: 0.0070 lr: 0.005
2019-03-25 16:11:56 iteration: 2475 loss: 0.0054 lr: 0.005
2019-03-25 16:12:12 iteration: 2480 loss: 0.0065 lr: 0.005
2019-03-25 16:13:22 iteration: 2485 loss: 0.0052 lr: 0.005
2019-03-25 16:13:33 iteration: 2490 loss: 0.0062 lr: 0.005
2019-03-25 16:13:59 iteration: 2495 loss: 0.0053 lr: 0.005
2019-03-25 16:14:51 iteration: 2500 loss: 0.0034 lr: 0.005
2019-03-25 16:15:45 iteration: 2505 loss: 0.0061 lr: 0.005
2019-03-25 16:16:09 iteration: 2510 loss: 0.0059 lr: 0.005
2019-03-25 16:16:47 iteration: 2515 loss: 0.0060 lr: 0.005
2019-03-25 16:17:17 iteration: 2520 loss: 0.0059 lr: 0.005
2019-03-25 16:18:15 iteration: 2525 loss: 0.0069 lr: 0.005
2019-03-25 16:18:56 iteration: 2530 loss: 0.0059 lr: 0.005
2019-03-25 16:19:45 iteration: 2535 loss: 0.0044 lr: 0.005
2019-03-25 16:20:06 iteration: 2540 loss: 0.0062 lr: 0.005
2019-03-25 16:20:59 iteration: 2545 loss: 0.0050 lr: 0.005
2019-03-25 16:21:10 iteration: 2550 loss: 0.0057 lr: 0.005
2019-03-25 16:21:50 iteration: 2555 loss: 0.0048 lr: 0.005
2019-03-25 16:22:34 iteration: 2560 loss: 0.0092 lr: 0.005
2019-03-25 16:23:25 iteration: 2565 loss: 0.0047 lr: 0.005
2019-03-25 16:23:43 iteration: 2570 loss: 0.0052 lr: 0.005
2019-03-25 16:24:23 iteration: 2575 loss: 0.0055 lr: 0.005
2019-03-25 16:24:50 iteration: 2580 loss: 0.0055 lr: 0.005
2019-03-25 16:25:06 iteration: 2585 loss: 0.0063 lr: 0.005
2019-03-25 16:25:32 iteration: 2590 loss: 0.0063 lr: 0.005
2019-03-25 16:25:50 iteration: 2595 loss: 0.0063 lr: 0.005
2019-03-25 16:26:05 iteration: 2600 loss: 0.0053 lr: 0.005
2019-03-25 16:26:18 iteration: 2605 loss: 0.0064 lr: 0.005
2019-03-25 16:26:55 iteration: 2610 loss: 0.0067 lr: 0.005
2019-03-25 16:27:42 iteration: 2615 loss: 0.0074 lr: 0.005
2019-03-25 16:27:54 iteration: 2620 loss: 0.0059 lr: 0.005
2019-03-25 16:28:14 iteration: 2625 loss: 0.0053 lr: 0.005
2019-03-25 16:28:55 iteration: 2630 loss: 0.0057 lr: 0.005
2019-03-25 16:29:09 iteration: 2635 loss: 0.0075 lr: 0.005
2019-03-25 16:29:33 iteration: 2640 loss: 0.0047 lr: 0.005
2019-03-25 16:30:19 iteration: 2645 loss: 0.0047 lr: 0.005
2019-03-25 16:30:52 iteration: 2650 loss: 0.0063 lr: 0.005
2019-03-25 16:31:30 iteration: 2655 loss: 0.0054 lr: 0.005
2019-03-25 16:32:17 iteration: 2660 loss: 0.0049 lr: 0.005
2019-03-25 16:32:41 iteration: 2665 loss: 0.0059 lr: 0.005
2019-03-25 16:33:40 iteration: 2670 loss: 0.0056 lr: 0.005
2019-03-25 16:34:00 iteration: 2675 loss: 0.0070 lr: 0.005
2019-03-25 16:34:14 iteration: 2680 loss: 0.0070 lr: 0.005
2019-03-25 16:34:34 iteration: 2685 loss: 0.0094 lr: 0.005
2019-03-25 16:35:14 iteration: 2690 loss: 0.0045 lr: 0.005
2019-03-25 16:35:42 iteration: 2695 loss: 0.0041 lr: 0.005
2019-03-25 16:35:58 iteration: 2700 loss: 0.0054 lr: 0.005
2019-03-25 16:36:43 iteration: 2705 loss: 0.0066 lr: 0.005
2019-03-25 16:38:10 iteration: 2710 loss: 0.0041 lr: 0.005
2019-03-25 16:38:21 iteration: 2715 loss: 0.0078 lr: 0.005
2019-03-25 16:39:00 iteration: 2720 loss: 0.0071 lr: 0.005
2019-03-25 16:39:14 iteration: 2725 loss: 0.0090 lr: 0.005
2019-03-25 16:39:56 iteration: 2730 loss: 0.0044 lr: 0.005
2019-03-25 16:41:28 iteration: 2735 loss: 0.0044 lr: 0.005
2019-03-25 16:41:47 iteration: 2740 loss: 0.0081 lr: 0.005
2019-03-25 16:42:08 iteration: 2745 loss: 0.0106 lr: 0.005
2019-03-25 16:42:27 iteration: 2750 loss: 0.0103 lr: 0.005
2019-03-25 16:43:31 iteration: 2755 loss: 0.0044 lr: 0.005
2019-03-25 16:44:34 iteration: 2760 loss: 0.0059 lr: 0.005
2019-03-25 16:44:52 iteration: 2765 loss: 0.0057 lr: 0.005
2019-03-25 16:45:36 iteration: 2770 loss: 0.0058 lr: 0.005
2019-03-25 16:46:02 iteration: 2775 loss: 0.0062 lr: 0.005
2019-03-25 16:46:39 iteration: 2780 loss: 0.0036 lr: 0.005
2019-03-25 16:47:33 iteration: 2785 loss: 0.0055 lr: 0.005
2019-03-25 16:48:47 iteration: 2790 loss: 0.0042 lr: 0.005
2019-03-25 16:49:31 iteration: 2795 loss: 0.0049 lr: 0.005
2019-03-25 16:50:17 iteration: 2800 loss: 0.0081 lr: 0.005
2019-03-25 16:51:29 iteration: 2805 loss: 0.0035 lr: 0.005
2019-03-25 16:51:54 iteration: 2810 loss: 0.0071 lr: 0.005
2019-03-25 16:52:14 iteration: 2815 loss: 0.0051 lr: 0.005
2019-03-25 16:52:28 iteration: 2820 loss: 0.0091 lr: 0.005
2019-03-25 16:53:18 iteration: 2825 loss: 0.0034 lr: 0.005
2019-03-25 16:53:34 iteration: 2830 loss: 0.0052 lr: 0.005
2019-03-25 16:54:09 iteration: 2835 loss: 0.0048 lr: 0.005
2019-03-25 16:54:30 iteration: 2840 loss: 0.0062 lr: 0.005
2019-03-25 16:55:16 iteration: 2845 loss: 0.0058 lr: 0.005
2019-03-25 16:55:48 iteration: 2850 loss: 0.0056 lr: 0.005
2019-03-25 16:56:04 iteration: 2855 loss: 0.0066 lr: 0.005
2019-03-25 16:56:17 iteration: 2860 loss: 0.0074 lr: 0.005
2019-03-25 16:56:35 iteration: 2865 loss: 0.0062 lr: 0.005
2019-03-25 16:57:47 iteration: 2870 loss: 0.0043 lr: 0.005
2019-03-25 16:58:21 iteration: 2875 loss: 0.0049 lr: 0.005
2019-03-25 16:58:42 iteration: 2880 loss: 0.0082 lr: 0.005
2019-03-25 16:59:40 iteration: 2885 loss: 0.0087 lr: 0.005
2019-03-25 16:59:59 iteration: 2890 loss: 0.0088 lr: 0.005
2019-03-25 17:00:09 iteration: 2895 loss: 0.0077 lr: 0.005
2019-03-25 17:01:24 iteration: 2900 loss: 0.0062 lr: 0.005
2019-03-25 17:02:39 iteration: 2905 loss: 0.0070 lr: 0.005
2019-03-25 17:02:50 iteration: 2910 loss: 0.0067 lr: 0.005
2019-03-25 17:03:25 iteration: 2915 loss: 0.0051 lr: 0.005
2019-03-25 17:03:49 iteration: 2920 loss: 0.0073 lr: 0.005
2019-03-25 17:04:12 iteration: 2925 loss: 0.0052 lr: 0.005
2019-03-25 17:05:00 iteration: 2930 loss: 0.0063 lr: 0.005
2019-03-25 17:05:18 iteration: 2935 loss: 0.0064 lr: 0.005
2019-03-25 17:05:42 iteration: 2940 loss: 0.0068 lr: 0.005
2019-03-25 17:06:03 iteration: 2945 loss: 0.0072 lr: 0.005
2019-03-25 17:06:18 iteration: 2950 loss: 0.0049 lr: 0.005
2019-03-25 17:07:07 iteration: 2955 loss: 0.0057 lr: 0.005
2019-03-25 17:07:22 iteration: 2960 loss: 0.0060 lr: 0.005
2019-03-25 17:07:36 iteration: 2965 loss: 0.0084 lr: 0.005
2019-03-25 17:08:04 iteration: 2970 loss: 0.0055 lr: 0.005
2019-03-25 17:08:26 iteration: 2975 loss: 0.0067 lr: 0.005
2019-03-25 17:09:19 iteration: 2980 loss: 0.0050 lr: 0.005
2019-03-25 17:09:30 iteration: 2985 loss: 0.0063 lr: 0.005
2019-03-25 17:09:49 iteration: 2990 loss: 0.0093 lr: 0.005
2019-03-25 17:10:45 iteration: 2995 loss: 0.0070 lr: 0.005
2019-03-25 17:11:35 iteration: 3000 loss: 0.0058 lr: 0.005
2019-03-25 17:11:52 iteration: 3005 loss: 0.0051 lr: 0.005
2019-03-25 17:13:09 iteration: 3010 loss: 0.0052 lr: 0.005
2019-03-25 17:14:22 iteration: 3015 loss: 0.0063 lr: 0.005
2019-03-25 17:15:27 iteration: 3020 loss: 0.0043 lr: 0.005
2019-03-25 17:16:41 iteration: 3025 loss: 0.0059 lr: 0.005
2019-03-25 17:18:05 iteration: 3030 loss: 0.0057 lr: 0.005
2019-03-25 17:18:26 iteration: 3035 loss: 0.0064 lr: 0.005
2019-03-25 17:18:43 iteration: 3040 loss: 0.0070 lr: 0.005
2019-03-25 17:18:59 iteration: 3045 loss: 0.0083 lr: 0.005
2019-03-25 17:19:21 iteration: 3050 loss: 0.0055 lr: 0.005
2019-03-25 17:20:16 iteration: 3055 loss: 0.0063 lr: 0.005
2019-03-25 17:21:04 iteration: 3060 loss: 0.0050 lr: 0.005
2019-03-25 17:21:56 iteration: 3065 loss: 0.0062 lr: 0.005
2019-03-25 17:22:44 iteration: 3070 loss: 0.0056 lr: 0.005
2019-03-25 17:23:02 iteration: 3075 loss: 0.0073 lr: 0.005
2019-03-25 17:23:38 iteration: 3080 loss: 0.0096 lr: 0.005
2019-03-25 17:24:05 iteration: 3085 loss: 0.0062 lr: 0.005
2019-03-25 17:24:20 iteration: 3090 loss: 0.0066 lr: 0.005
2019-03-25 17:24:34 iteration: 3095 loss: 0.0069 lr: 0.005
2019-03-25 17:25:04 iteration: 3100 loss: 0.0078 lr: 0.005
2019-03-25 17:25:19 iteration: 3105 loss: 0.0053 lr: 0.005
2019-03-25 17:25:57 iteration: 3110 loss: 0.0061 lr: 0.005
2019-03-25 17:26:33 iteration: 3115 loss: 0.0056 lr: 0.005
2019-03-25 17:27:36 iteration: 3120 loss: 0.0067 lr: 0.005
2019-03-25 17:28:01 iteration: 3125 loss: 0.0046 lr: 0.005
2019-03-25 17:28:13 iteration: 3130 loss: 0.0067 lr: 0.005
2019-03-25 17:28:53 iteration: 3135 loss: 0.0068 lr: 0.005
2019-03-25 17:29:34 iteration: 3140 loss: 0.0042 lr: 0.005
2019-03-25 17:30:51 iteration: 3145 loss: 0.0063 lr: 0.005
2019-03-25 17:31:32 iteration: 3150 loss: 0.0046 lr: 0.005
2019-03-25 17:32:13 iteration: 3155 loss: 0.0110 lr: 0.005
2019-03-25 17:33:04 iteration: 3160 loss: 0.0037 lr: 0.005
2019-03-25 17:33:31 iteration: 3165 loss: 0.0059 lr: 0.005
2019-03-25 17:34:04 iteration: 3170 loss: 0.0058 lr: 0.005
2019-03-25 17:34:16 iteration: 3175 loss: 0.0073 lr: 0.005
2019-03-25 17:35:34 iteration: 3180 loss: 0.0062 lr: 0.005
2019-03-25 17:36:18 iteration: 3185 loss: 0.0055 lr: 0.005
2019-03-25 17:36:38 iteration: 3190 loss: 0.0038 lr: 0.005
2019-03-25 17:37:31 iteration: 3195 loss: 0.0059 lr: 0.005
2019-03-25 17:37:45 iteration: 3200 loss: 0.0070 lr: 0.005
2019-03-25 17:38:10 iteration: 3205 loss: 0.0055 lr: 0.005
2019-03-25 17:38:36 iteration: 3210 loss: 0.0062 lr: 0.005
2019-03-25 17:39:11 iteration: 3215 loss: 0.0043 lr: 0.005
2019-03-25 17:40:52 iteration: 3220 loss: 0.0049 lr: 0.005
2019-03-25 17:41:48 iteration: 3225 loss: 0.0055 lr: 0.005
2019-03-25 17:42:55 iteration: 3230 loss: 0.0046 lr: 0.005
2019-03-25 17:43:38 iteration: 3235 loss: 0.0043 lr: 0.005
2019-03-25 17:44:37 iteration: 3240 loss: 0.0057 lr: 0.005
2019-03-25 17:44:54 iteration: 3245 loss: 0.0053 lr: 0.005
2019-03-25 17:46:03 iteration: 3250 loss: 0.0032 lr: 0.005
2019-03-25 17:46:24 iteration: 3255 loss: 0.0066 lr: 0.005
2019-03-25 17:46:47 iteration: 3260 loss: 0.0042 lr: 0.005
2019-03-25 17:48:00 iteration: 3265 loss: 0.0047 lr: 0.005
2019-03-25 17:48:24 iteration: 3270 loss: 0.0060 lr: 0.005
2019-03-25 17:48:45 iteration: 3275 loss: 0.0065 lr: 0.005
2019-03-25 17:49:25 iteration: 3280 loss: 0.0060 lr: 0.005
2019-03-25 17:50:14 iteration: 3285 loss: 0.0059 lr: 0.005
2019-03-25 17:50:58 iteration: 3290 loss: 0.0060 lr: 0.005
2019-03-25 17:51:32 iteration: 3295 loss: 0.0053 lr: 0.005
2019-03-25 17:52:07 iteration: 3300 loss: 0.0058 lr: 0.005
2019-03-25 17:54:02 iteration: 3305 loss: 0.0054 lr: 0.005
2019-03-25 17:54:23 iteration: 3310 loss: 0.0052 lr: 0.005
2019-03-25 17:55:02 iteration: 3315 loss: 0.0047 lr: 0.005
2019-03-25 17:55:59 iteration: 3320 loss: 0.0051 lr: 0.005
2019-03-25 17:57:03 iteration: 3325 loss: 0.0048 lr: 0.005
2019-03-25 17:57:40 iteration: 3330 loss: 0.0041 lr: 0.005
2019-03-25 17:57:56 iteration: 3335 loss: 0.0065 lr: 0.005
2019-03-25 17:58:09 iteration: 3340 loss: 0.0064 lr: 0.005
2019-03-25 17:58:27 iteration: 3345 loss: 0.0054 lr: 0.005
2019-03-25 17:58:53 iteration: 3350 loss: 0.0071 lr: 0.005
2019-03-25 18:00:22 iteration: 3355 loss: 0.0037 lr: 0.005
2019-03-25 18:01:26 iteration: 3360 loss: 0.0044 lr: 0.005
2019-03-25 18:02:11 iteration: 3365 loss: 0.0057 lr: 0.005
2019-03-25 18:02:58 iteration: 3370 loss: 0.0068 lr: 0.005
2019-03-25 18:03:25 iteration: 3375 loss: 0.0052 lr: 0.005
2019-03-25 18:03:45 iteration: 3380 loss: 0.0056 lr: 0.005
2019-03-25 18:04:33 iteration: 3385 loss: 0.0057 lr: 0.005
2019-03-25 18:05:23 iteration: 3390 loss: 0.0082 lr: 0.005
2019-03-25 18:05:42 iteration: 3395 loss: 0.0087 lr: 0.005
2019-03-25 18:06:07 iteration: 3400 loss: 0.0063 lr: 0.005
2019-03-25 18:06:45 iteration: 3405 loss: 0.0052 lr: 0.005
2019-03-25 18:07:05 iteration: 3410 loss: 0.0074 lr: 0.005
2019-03-25 18:07:32 iteration: 3415 loss: 0.0066 lr: 0.005
2019-03-25 18:07:45 iteration: 3420 loss: 0.0049 lr: 0.005
2019-03-25 18:08:58 iteration: 3425 loss: 0.0043 lr: 0.005
2019-03-25 18:10:05 iteration: 3430 loss: 0.0061 lr: 0.005
2019-03-25 18:11:16 iteration: 3435 loss: 0.0042 lr: 0.005
2019-03-25 18:12:24 iteration: 3440 loss: 0.0050 lr: 0.005
2019-03-25 18:14:02 iteration: 3445 loss: 0.0050 lr: 0.005
2019-03-25 18:14:20 iteration: 3450 loss: 0.0055 lr: 0.005
2019-03-25 18:14:33 iteration: 3455 loss: 0.0053 lr: 0.005
2019-03-25 18:14:47 iteration: 3460 loss: 0.0095 lr: 0.005
2019-03-25 18:15:31 iteration: 3465 loss: 0.0052 lr: 0.005
2019-03-25 18:16:55 iteration: 3470 loss: 0.0039 lr: 0.005
2019-03-25 18:17:23 iteration: 3475 loss: 0.0053 lr: 0.005
2019-03-25 18:17:59 iteration: 3480 loss: 0.0049 lr: 0.005
2019-03-25 18:19:07 iteration: 3485 loss: 0.0043 lr: 0.005
2019-03-25 18:19:32 iteration: 3490 loss: 0.0059 lr: 0.005
2019-03-25 18:19:55 iteration: 3495 loss: 0.0055 lr: 0.005
2019-03-25 18:20:17 iteration: 3500 loss: 0.0053 lr: 0.005
2019-03-25 18:20:49 iteration: 3505 loss: 0.0051 lr: 0.005
2019-03-25 18:21:10 iteration: 3510 loss: 0.0055 lr: 0.005
2019-03-25 18:21:33 iteration: 3515 loss: 0.0066 lr: 0.005
2019-03-25 18:22:56 iteration: 3520 loss: 0.0076 lr: 0.005
2019-03-25 18:23:07 iteration: 3525 loss: 0.0053 lr: 0.005
2019-03-25 18:23:23 iteration: 3530 loss: 0.0052 lr: 0.005
2019-03-25 18:23:41 iteration: 3535 loss: 0.0057 lr: 0.005
2019-03-25 18:24:01 iteration: 3540 loss: 0.0091 lr: 0.005
2019-03-25 18:24:33 iteration: 3545 loss: 0.0051 lr: 0.005
2019-03-25 18:25:08 iteration: 3550 loss: 0.0053 lr: 0.005
2019-03-25 18:26:20 iteration: 3555 loss: 0.0077 lr: 0.005
2019-03-25 18:26:56 iteration: 3560 loss: 0.0049 lr: 0.005
2019-03-25 18:27:49 iteration: 3565 loss: 0.0061 lr: 0.005
2019-03-25 18:28:32 iteration: 3570 loss: 0.0054 lr: 0.005
2019-03-25 18:29:24 iteration: 3575 loss: 0.0048 lr: 0.005
2019-03-25 18:29:39 iteration: 3580 loss: 0.0047 lr: 0.005
2019-03-25 18:30:21 iteration: 3585 loss: 0.0052 lr: 0.005
2019-03-25 18:31:01 iteration: 3590 loss: 0.0037 lr: 0.005
2019-03-25 18:31:31 iteration: 3595 loss: 0.0064 lr: 0.005
2019-03-25 18:32:33 iteration: 3600 loss: 0.0057 lr: 0.005
2019-03-25 18:32:50 iteration: 3605 loss: 0.0064 lr: 0.005
2019-03-25 18:34:17 iteration: 3610 loss: 0.0047 lr: 0.005
2019-03-25 18:34:33 iteration: 3615 loss: 0.0056 lr: 0.005
2019-03-25 18:35:18 iteration: 3620 loss: 0.0074 lr: 0.005
2019-03-25 18:35:46 iteration: 3625 loss: 0.0064 lr: 0.005
2019-03-25 18:36:38 iteration: 3630 loss: 0.0057 lr: 0.005
2019-03-25 18:37:32 iteration: 3635 loss: 0.0051 lr: 0.005
2019-03-25 18:37:50 iteration: 3640 loss: 0.0074 lr: 0.005
2019-03-25 18:37:59 iteration: 3645 loss: 0.0065 lr: 0.005
2019-03-25 18:38:16 iteration: 3650 loss: 0.0055 lr: 0.005
2019-03-25 18:38:29 iteration: 3655 loss: 0.0070 lr: 0.005
2019-03-25 18:38:50 iteration: 3660 loss: 0.0081 lr: 0.005
2019-03-25 18:39:08 iteration: 3665 loss: 0.0069 lr: 0.005
2019-03-25 18:40:17 iteration: 3670 loss: 0.0052 lr: 0.005
2019-03-25 18:40:31 iteration: 3675 loss: 0.0061 lr: 0.005
2019-03-25 18:40:59 iteration: 3680 loss: 0.0052 lr: 0.005
2019-03-25 18:41:30 iteration: 3685 loss: 0.0043 lr: 0.005
2019-03-25 18:41:56 iteration: 3690 loss: 0.0050 lr: 0.005
2019-03-25 18:42:10 iteration: 3695 loss: 0.0055 lr: 0.005
2019-03-25 18:42:49 iteration: 3700 loss: 0.0044 lr: 0.005
2019-03-25 18:44:23 iteration: 3705 loss: 0.0047 lr: 0.005
2019-03-25 18:46:01 iteration: 3710 loss: 0.0045 lr: 0.005
2019-03-25 18:46:14 iteration: 3715 loss: 0.0048 lr: 0.005
2019-03-25 18:46:31 iteration: 3720 loss: 0.0105 lr: 0.005
2019-03-25 18:47:47 iteration: 3725 loss: 0.0052 lr: 0.005
2019-03-25 18:48:49 iteration: 3730 loss: 0.0052 lr: 0.005
2019-03-25 18:49:22 iteration: 3735 loss: 0.0062 lr: 0.005
2019-03-25 18:50:13 iteration: 3740 loss: 0.0055 lr: 0.005
2019-03-25 18:50:23 iteration: 3745 loss: 0.0064 lr: 0.005
2019-03-25 18:51:00 iteration: 3750 loss: 0.0087 lr: 0.005
2019-03-25 18:51:13 iteration: 3755 loss: 0.0078 lr: 0.005
2019-03-25 18:51:29 iteration: 3760 loss: 0.0064 lr: 0.005
2019-03-25 18:51:45 iteration: 3765 loss: 0.0073 lr: 0.005
2019-03-25 18:52:04 iteration: 3770 loss: 0.0065 lr: 0.005
2019-03-25 18:53:23 iteration: 3775 loss: 0.0046 lr: 0.005
2019-03-25 18:54:01 iteration: 3780 loss: 0.0060 lr: 0.005
2019-03-25 18:55:48 iteration: 3785 loss: 0.0037 lr: 0.005
2019-03-25 18:56:09 iteration: 3790 loss: 0.0052 lr: 0.005
2019-03-25 18:56:29 iteration: 3795 loss: 0.0048 lr: 0.005
2019-03-25 18:56:48 iteration: 3800 loss: 0.0053 lr: 0.005
2019-03-25 18:57:04 iteration: 3805 loss: 0.0063 lr: 0.005
2019-03-25 18:58:10 iteration: 3810 loss: 0.0047 lr: 0.005
2019-03-25 18:59:22 iteration: 3815 loss: 0.0044 lr: 0.005
2019-03-25 18:59:40 iteration: 3820 loss: 0.0070 lr: 0.005
2019-03-25 19:00:01 iteration: 3825 loss: 0.0051 lr: 0.005
2019-03-25 19:00:14 iteration: 3830 loss: 0.0055 lr: 0.005
2019-03-25 19:00:27 iteration: 3835 loss: 0.0060 lr: 0.005
2019-03-25 19:01:42 iteration: 3840 loss: 0.0054 lr: 0.005
2019-03-25 19:02:26 iteration: 3845 loss: 0.0087 lr: 0.005
2019-03-25 19:02:38 iteration: 3850 loss: 0.0079 lr: 0.005
2019-03-25 19:02:57 iteration: 3855 loss: 0.0062 lr: 0.005
2019-03-25 19:03:31 iteration: 3860 loss: 0.0043 lr: 0.005
2019-03-25 19:04:07 iteration: 3865 loss: 0.0048 lr: 0.005
2019-03-25 19:04:34 iteration: 3870 loss: 0.0059 lr: 0.005
2019-03-25 19:05:18 iteration: 3875 loss: 0.0065 lr: 0.005
2019-03-25 19:05:54 iteration: 3880 loss: 0.0057 lr: 0.005
2019-03-25 19:07:03 iteration: 3885 loss: 0.0047 lr: 0.005
2019-03-25 19:07:43 iteration: 3890 loss: 0.0051 lr: 0.005
2019-03-25 19:08:19 iteration: 3895 loss: 0.0046 lr: 0.005
2019-03-25 19:08:57 iteration: 3900 loss: 0.0042 lr: 0.005
2019-03-25 19:09:43 iteration: 3905 loss: 0.0037 lr: 0.005
2019-03-25 19:10:05 iteration: 3910 loss: 0.0044 lr: 0.005
2019-03-25 19:10:25 iteration: 3915 loss: 0.0082 lr: 0.005
2019-03-25 19:11:03 iteration: 3920 loss: 0.0048 lr: 0.005
2019-03-25 19:11:35 iteration: 3925 loss: 0.0057 lr: 0.005
2019-03-25 19:11:50 iteration: 3930 loss: 0.0059 lr: 0.005
2019-03-25 19:12:32 iteration: 3935 loss: 0.0049 lr: 0.005
2019-03-25 19:12:46 iteration: 3940 loss: 0.0058 lr: 0.005
2019-03-25 19:13:32 iteration: 3945 loss: 0.0069 lr: 0.005
2019-03-25 19:14:18 iteration: 3950 loss: 0.0054 lr: 0.005
2019-03-25 19:15:16 iteration: 3955 loss: 0.0047 lr: 0.005
2019-03-25 19:15:43 iteration: 3960 loss: 0.0069 lr: 0.005
2019-03-25 19:16:52 iteration: 3965 loss: 0.0038 lr: 0.005
2019-03-25 19:17:13 iteration: 3970 loss: 0.0054 lr: 0.005
2019-03-25 19:18:08 iteration: 3975 loss: 0.0046 lr: 0.005
2019-03-25 19:18:34 iteration: 3980 loss: 0.0044 lr: 0.005
2019-03-25 19:19:20 iteration: 3985 loss: 0.0041 lr: 0.005
2019-03-25 19:19:51 iteration: 3990 loss: 0.0049 lr: 0.005
2019-03-25 19:20:07 iteration: 3995 loss: 0.0067 lr: 0.005
2019-03-25 19:21:01 iteration: 4000 loss: 0.0045 lr: 0.005
2019-03-25 19:22:29 iteration: 4005 loss: 0.0049 lr: 0.005
2019-03-25 19:22:55 iteration: 4010 loss: 0.0053 lr: 0.005
2019-03-25 19:23:40 iteration: 4015 loss: 0.0058 lr: 0.005
2019-03-25 19:23:58 iteration: 4020 loss: 0.0053 lr: 0.005
2019-03-25 19:24:11 iteration: 4025 loss: 0.0056 lr: 0.005
2019-03-25 19:24:23 iteration: 4030 loss: 0.0087 lr: 0.005
2019-03-25 19:24:50 iteration: 4035 loss: 0.0063 lr: 0.005
2019-03-25 19:25:07 iteration: 4040 loss: 0.0052 lr: 0.005
2019-03-25 19:25:31 iteration: 4045 loss: 0.0061 lr: 0.005
2019-03-25 19:26:23 iteration: 4050 loss: 0.0073 lr: 0.005
2019-03-25 19:27:23 iteration: 4055 loss: 0.0041 lr: 0.005
2019-03-25 19:28:37 iteration: 4060 loss: 0.0029 lr: 0.005
2019-03-25 19:29:57 iteration: 4065 loss: 0.0043 lr: 0.005
2019-03-25 19:30:35 iteration: 4070 loss: 0.0041 lr: 0.005
2019-03-25 19:31:00 iteration: 4075 loss: 0.0064 lr: 0.005
2019-03-25 19:31:37 iteration: 4080 loss: 0.0060 lr: 0.005
2019-03-25 19:32:24 iteration: 4085 loss: 0.0070 lr: 0.005
2019-03-25 19:32:53 iteration: 4090 loss: 0.0041 lr: 0.005
2019-03-25 19:33:43 iteration: 4095 loss: 0.0054 lr: 0.005
2019-03-25 19:33:58 iteration: 4100 loss: 0.0094 lr: 0.005
2019-03-25 19:34:45 iteration: 4105 loss: 0.0055 lr: 0.005
2019-03-25 19:35:03 iteration: 4110 loss: 0.0099 lr: 0.005
2019-03-25 19:35:35 iteration: 4115 loss: 0.0062 lr: 0.005
2019-03-25 19:36:28 iteration: 4120 loss: 0.0042 lr: 0.005
2019-03-25 19:37:21 iteration: 4125 loss: 0.0042 lr: 0.005
2019-03-25 19:38:20 iteration: 4130 loss: 0.0044 lr: 0.005
2019-03-25 19:39:29 iteration: 4135 loss: 0.0046 lr: 0.005
2019-03-25 19:39:46 iteration: 4140 loss: 0.0091 lr: 0.005
2019-03-25 19:40:09 iteration: 4145 loss: 0.0050 lr: 0.005
2019-03-25 19:40:54 iteration: 4150 loss: 0.0051 lr: 0.005
2019-03-25 19:41:27 iteration: 4155 loss: 0.0043 lr: 0.005
2019-03-25 19:42:50 iteration: 4160 loss: 0.0047 lr: 0.005
2019-03-25 19:43:10 iteration: 4165 loss: 0.0048 lr: 0.005
2019-03-25 19:43:37 iteration: 4170 loss: 0.0053 lr: 0.005
2019-03-25 19:43:58 iteration: 4175 loss: 0.0061 lr: 0.005
2019-03-25 19:44:36 iteration: 4180 loss: 0.0053 lr: 0.005
2019-03-25 19:45:30 iteration: 4185 loss: 0.0045 lr: 0.005
2019-03-25 19:46:08 iteration: 4190 loss: 0.0055 lr: 0.005
2019-03-25 19:47:00 iteration: 4195 loss: 0.0052 lr: 0.005
2019-03-25 19:47:22 iteration: 4200 loss: 0.0041 lr: 0.005
2019-03-25 19:48:29 iteration: 4205 loss: 0.0043 lr: 0.005
2019-03-25 19:49:02 iteration: 4210 loss: 0.0050 lr: 0.005
2019-03-25 19:49:24 iteration: 4215 loss: 0.0051 lr: 0.005
2019-03-25 19:49:53 iteration: 4220 loss: 0.0056 lr: 0.005
2019-03-25 19:50:37 iteration: 4225 loss: 0.0038 lr: 0.005
2019-03-25 19:50:52 iteration: 4230 loss: 0.0056 lr: 0.005
2019-03-25 19:51:23 iteration: 4235 loss: 0.0055 lr: 0.005
2019-03-25 19:51:58 iteration: 4240 loss: 0.0047 lr: 0.005
2019-03-25 19:52:44 iteration: 4245 loss: 0.0059 lr: 0.005
2019-03-25 19:53:01 iteration: 4250 loss: 0.0058 lr: 0.005
2019-03-25 19:54:10 iteration: 4255 loss: 0.0049 lr: 0.005
2019-03-25 19:54:34 iteration: 4260 loss: 0.0037 lr: 0.005
2019-03-25 19:55:22 iteration: 4265 loss: 0.0059 lr: 0.005
2019-03-25 19:55:48 iteration: 4270 loss: 0.0065 lr: 0.005
2019-03-25 19:56:54 iteration: 4275 loss: 0.0104 lr: 0.005
2019-03-25 19:57:28 iteration: 4280 loss: 0.0035 lr: 0.005
2019-03-25 19:57:42 iteration: 4285 loss: 0.0057 lr: 0.005
2019-03-25 19:58:04 iteration: 4290 loss: 0.0057 lr: 0.005
2019-03-25 19:58:49 iteration: 4295 loss: 0.0053 lr: 0.005
2019-03-25 19:59:09 iteration: 4300 loss: 0.0064 lr: 0.005
2019-03-25 19:59:45 iteration: 4305 loss: 0.0045 lr: 0.005
2019-03-25 20:00:08 iteration: 4310 loss: 0.0049 lr: 0.005
2019-03-25 20:00:45 iteration: 4315 loss: 0.0038 lr: 0.005
2019-03-25 20:01:27 iteration: 4320 loss: 0.0057 lr: 0.005
2019-03-25 20:02:24 iteration: 4325 loss: 0.0034 lr: 0.005
2019-03-25 20:02:57 iteration: 4330 loss: 0.0072 lr: 0.005
2019-03-25 20:03:48 iteration: 4335 loss: 0.0076 lr: 0.005
2019-03-25 20:04:47 iteration: 4340 loss: 0.0045 lr: 0.005
2019-03-25 20:05:16 iteration: 4345 loss: 0.0041 lr: 0.005
2019-03-25 20:06:19 iteration: 4350 loss: 0.0039 lr: 0.005
2019-03-25 20:07:29 iteration: 4355 loss: 0.0063 lr: 0.005
2019-03-25 20:08:20 iteration: 4360 loss: 0.0067 lr: 0.005
2019-03-25 20:08:42 iteration: 4365 loss: 0.0045 lr: 0.005
2019-03-25 20:09:15 iteration: 4370 loss: 0.0039 lr: 0.005
2019-03-25 20:09:32 iteration: 4375 loss: 0.0048 lr: 0.005
2019-03-25 20:10:35 iteration: 4380 loss: 0.0044 lr: 0.005
2019-03-25 20:10:52 iteration: 4385 loss: 0.0054 lr: 0.005
2019-03-25 20:12:33 iteration: 4390 loss: 0.0042 lr: 0.005
2019-03-25 20:12:58 iteration: 4395 loss: 0.0097 lr: 0.005
2019-03-25 20:13:46 iteration: 4400 loss: 0.0061 lr: 0.005
2019-03-25 20:14:03 iteration: 4405 loss: 0.0057 lr: 0.005
2019-03-25 20:14:16 iteration: 4410 loss: 0.0049 lr: 0.005
2019-03-25 20:14:45 iteration: 4415 loss: 0.0049 lr: 0.005
2019-03-25 20:15:19 iteration: 4420 loss: 0.0052 lr: 0.005
2019-03-25 20:15:39 iteration: 4425 loss: 0.0059 lr: 0.005
2019-03-25 20:16:33 iteration: 4430 loss: 0.0044 lr: 0.005
2019-03-25 20:16:58 iteration: 4435 loss: 0.0048 lr: 0.005
2019-03-25 20:17:39 iteration: 4440 loss: 0.0037 lr: 0.005
2019-03-25 20:18:16 iteration: 4445 loss: 0.0050 lr: 0.005
2019-03-25 20:18:45 iteration: 4450 loss: 0.0050 lr: 0.005
2019-03-25 20:19:28 iteration: 4455 loss: 0.0053 lr: 0.005
2019-03-25 20:20:20 iteration: 4460 loss: 0.0071 lr: 0.005
2019-03-25 20:20:55 iteration: 4465 loss: 0.0068 lr: 0.005
2019-03-25 20:21:15 iteration: 4470 loss: 0.0057 lr: 0.005
2019-03-25 20:21:37 iteration: 4475 loss: 0.0056 lr: 0.005
2019-03-25 20:22:05 iteration: 4480 loss: 0.0055 lr: 0.005
2019-03-25 20:22:38 iteration: 4485 loss: 0.0053 lr: 0.005
2019-03-25 20:23:07 iteration: 4490 loss: 0.0057 lr: 0.005
2019-03-25 20:23:43 iteration: 4495 loss: 0.0059 lr: 0.005
2019-03-25 20:24:54 iteration: 4500 loss: 0.0057 lr: 0.005
2019-03-25 20:25:25 iteration: 4505 loss: 0.0050 lr: 0.005
2019-03-25 20:26:14 iteration: 4510 loss: 0.0045 lr: 0.005
2019-03-25 20:26:27 iteration: 4515 loss: 0.0079 lr: 0.005
2019-03-25 20:26:50 iteration: 4520 loss: 0.0051 lr: 0.005
2019-03-25 20:27:33 iteration: 4525 loss: 0.0047 lr: 0.005
2019-03-25 20:28:24 iteration: 4530 loss: 0.0041 lr: 0.005
2019-03-25 20:29:29 iteration: 4535 loss: 0.0068 lr: 0.005
2019-03-25 20:30:14 iteration: 4540 loss: 0.0039 lr: 0.005
2019-03-25 20:31:25 iteration: 4545 loss: 0.0069 lr: 0.005
2019-03-25 20:31:36 iteration: 4550 loss: 0.0074 lr: 0.005
2019-03-25 20:32:16 iteration: 4555 loss: 0.0059 lr: 0.005
2019-03-25 20:32:38 iteration: 4560 loss: 0.0042 lr: 0.005
2019-03-25 20:33:04 iteration: 4565 loss: 0.0052 lr: 0.005
2019-03-25 20:34:02 iteration: 4570 loss: 0.0060 lr: 0.005
2019-03-25 20:35:15 iteration: 4575 loss: 0.0046 lr: 0.005
2019-03-25 20:35:32 iteration: 4580 loss: 0.0085 lr: 0.005
2019-03-25 20:36:02 iteration: 4585 loss: 0.0047 lr: 0.005
2019-03-25 20:36:15 iteration: 4590 loss: 0.0055 lr: 0.005
2019-03-25 20:37:04 iteration: 4595 loss: 0.0033 lr: 0.005
2019-03-25 20:37:26 iteration: 4600 loss: 0.0047 lr: 0.005
2019-03-25 20:37:43 iteration: 4605 loss: 0.0078 lr: 0.005
2019-03-25 20:38:43 iteration: 4610 loss: 0.0042 lr: 0.005
2019-03-25 20:39:59 iteration: 4615 loss: 0.0038 lr: 0.005
2019-03-25 20:40:30 iteration: 4620 loss: 0.0050 lr: 0.005
2019-03-25 20:40:57 iteration: 4625 loss: 0.0063 lr: 0.005
2019-03-25 20:41:41 iteration: 4630 loss: 0.0047 lr: 0.005
2019-03-25 20:42:43 iteration: 4635 loss: 0.0046 lr: 0.005
2019-03-25 20:43:03 iteration: 4640 loss: 0.0060 lr: 0.005
2019-03-25 20:43:23 iteration: 4645 loss: 0.0056 lr: 0.005
2019-03-25 20:43:46 iteration: 4650 loss: 0.0046 lr: 0.005
2019-03-25 20:44:42 iteration: 4655 loss: 0.0029 lr: 0.005
2019-03-25 20:45:26 iteration: 4660 loss: 0.0039 lr: 0.005
2019-03-25 20:46:19 iteration: 4665 loss: 0.0046 lr: 0.005
2019-03-25 20:47:00 iteration: 4670 loss: 0.0069 lr: 0.005
2019-03-25 20:47:13 iteration: 4675 loss: 0.0043 lr: 0.005
2019-03-25 20:47:36 iteration: 4680 loss: 0.0055 lr: 0.005
2019-03-25 20:48:20 iteration: 4685 loss: 0.0055 lr: 0.005
2019-03-25 20:49:32 iteration: 4690 loss: 0.0038 lr: 0.005
2019-03-25 20:49:52 iteration: 4695 loss: 0.0046 lr: 0.005
2019-03-25 20:50:14 iteration: 4700 loss: 0.0049 lr: 0.005
2019-03-25 20:50:57 iteration: 4705 loss: 0.0050 lr: 0.005
2019-03-25 20:51:17 iteration: 4710 loss: 0.0054 lr: 0.005
2019-03-25 20:51:37 iteration: 4715 loss: 0.0057 lr: 0.005
2019-03-25 20:51:56 iteration: 4720 loss: 0.0062 lr: 0.005
2019-03-25 20:52:31 iteration: 4725 loss: 0.0043 lr: 0.005
2019-03-25 20:52:55 iteration: 4730 loss: 0.0090 lr: 0.005
2019-03-25 20:53:14 iteration: 4735 loss: 0.0057 lr: 0.005
2019-03-25 20:54:28 iteration: 4740 loss: 0.0029 lr: 0.005
2019-03-25 20:55:42 iteration: 4745 loss: 0.0037 lr: 0.005
2019-03-25 20:56:12 iteration: 4750 loss: 0.0042 lr: 0.005
2019-03-25 20:56:39 iteration: 4755 loss: 0.0045 lr: 0.005
2019-03-25 20:59:08 iteration: 4760 loss: 0.0039 lr: 0.005
2019-03-25 20:59:53 iteration: 4765 loss: 0.0050 lr: 0.005
2019-03-25 21:00:29 iteration: 4770 loss: 0.0046 lr: 0.005
2019-03-25 21:00:50 iteration: 4775 loss: 0.0050 lr: 0.005
2019-03-25 21:01:57 iteration: 4780 loss: 0.0031 lr: 0.005
2019-03-25 21:03:15 iteration: 4785 loss: 0.0040 lr: 0.005
2019-03-25 21:04:23 iteration: 4790 loss: 0.0052 lr: 0.005
2019-03-25 21:04:44 iteration: 4795 loss: 0.0067 lr: 0.005
2019-03-25 21:05:50 iteration: 4800 loss: 0.0038 lr: 0.005
2019-03-25 21:06:18 iteration: 4805 loss: 0.0053 lr: 0.005
2019-03-25 21:06:33 iteration: 4810 loss: 0.0052 lr: 0.005
2019-03-25 21:06:58 iteration: 4815 loss: 0.0066 lr: 0.005
2019-03-25 21:07:38 iteration: 4820 loss: 0.0059 lr: 0.005
2019-03-25 21:08:12 iteration: 4825 loss: 0.0046 lr: 0.005
2019-03-25 21:09:19 iteration: 4830 loss: 0.0044 lr: 0.005
2019-03-25 21:09:30 iteration: 4835 loss: 0.0079 lr: 0.005
2019-03-25 21:10:13 iteration: 4840 loss: 0.0060 lr: 0.005
2019-03-25 21:10:27 iteration: 4845 loss: 0.0066 lr: 0.005
2019-03-25 21:10:45 iteration: 4850 loss: 0.0053 lr: 0.005
2019-03-25 21:11:58 iteration: 4855 loss: 0.0034 lr: 0.005
2019-03-25 21:12:27 iteration: 4860 loss: 0.0042 lr: 0.005
2019-03-25 21:13:15 iteration: 4865 loss: 0.0053 lr: 0.005
2019-03-25 21:13:30 iteration: 4870 loss: 0.0059 lr: 0.005
2019-03-25 21:14:20 iteration: 4875 loss: 0.0044 lr: 0.005
2019-03-25 21:15:18 iteration: 4880 loss: 0.0046 lr: 0.005
2019-03-25 21:15:42 iteration: 4885 loss: 0.0051 lr: 0.005
2019-03-25 21:16:18 iteration: 4890 loss: 0.0073 lr: 0.005
2019-03-25 21:18:04 iteration: 4895 loss: 0.0056 lr: 0.005
2019-03-25 21:19:17 iteration: 4900 loss: 0.0070 lr: 0.005
2019-03-25 21:20:20 iteration: 4905 loss: 0.0046 lr: 0.005
2019-03-25 21:21:21 iteration: 4910 loss: 0.0058 lr: 0.005
2019-03-25 21:22:04 iteration: 4915 loss: 0.0058 lr: 0.005
2019-03-25 21:22:39 iteration: 4920 loss: 0.0043 lr: 0.005
2019-03-25 21:23:46 iteration: 4925 loss: 0.0044 lr: 0.005
2019-03-25 21:24:11 iteration: 4930 loss: 0.0048 lr: 0.005
2019-03-25 21:24:55 iteration: 4935 loss: 0.0057 lr: 0.005
2019-03-25 21:25:18 iteration: 4940 loss: 0.0062 lr: 0.005
2019-03-25 21:26:02 iteration: 4945 loss: 0.0065 lr: 0.005
2019-03-25 21:26:31 iteration: 4950 loss: 0.0102 lr: 0.005
2019-03-25 21:27:10 iteration: 4955 loss: 0.0046 lr: 0.005
2019-03-25 21:27:35 iteration: 4960 loss: 0.0052 lr: 0.005
2019-03-25 21:28:31 iteration: 4965 loss: 0.0036 lr: 0.005
2019-03-25 21:29:34 iteration: 4970 loss: 0.0049 lr: 0.005
2019-03-25 21:30:14 iteration: 4975 loss: 0.0053 lr: 0.005
2019-03-25 21:30:32 iteration: 4980 loss: 0.0054 lr: 0.005
2019-03-25 21:31:06 iteration: 4985 loss: 0.0046 lr: 0.005
2019-03-25 21:32:27 iteration: 4990 loss: 0.0046 lr: 0.005
2019-03-25 21:33:28 iteration: 4995 loss: 0.0044 lr: 0.005
2019-03-25 21:34:00 iteration: 5000 loss: 0.0051 lr: 0.005
2019-03-25 21:34:19 iteration: 5005 loss: 0.0050 lr: 0.005
2019-03-25 21:34:49 iteration: 5010 loss: 0.0043 lr: 0.005
2019-03-25 21:35:03 iteration: 5015 loss: 0.0071 lr: 0.005
2019-03-25 21:35:33 iteration: 5020 loss: 0.0042 lr: 0.005
2019-03-25 21:37:05 iteration: 5025 loss: 0.0044 lr: 0.005
2019-03-25 21:37:47 iteration: 5030 loss: 0.0042 lr: 0.005
2019-03-25 21:39:05 iteration: 5035 loss: 0.0053 lr: 0.005
2019-03-25 21:39:28 iteration: 5040 loss: 0.0074 lr: 0.005
2019-03-25 21:40:07 iteration: 5045 loss: 0.0044 lr: 0.005
2019-03-25 21:40:56 iteration: 5050 loss: 0.0051 lr: 0.005
2019-03-25 21:41:50 iteration: 5055 loss: 0.0048 lr: 0.005
2019-03-25 21:43:41 iteration: 5060 loss: 0.0034 lr: 0.005
2019-03-25 21:44:30 iteration: 5065 loss: 0.0049 lr: 0.005
2019-03-25 21:45:27 iteration: 5070 loss: 0.0056 lr: 0.005
2019-03-25 21:46:06 iteration: 5075 loss: 0.0057 lr: 0.005
2019-03-25 21:47:18 iteration: 5080 loss: 0.0041 lr: 0.005
2019-03-25 21:48:01 iteration: 5085 loss: 0.0045 lr: 0.005
2019-03-25 21:49:08 iteration: 5090 loss: 0.0044 lr: 0.005
2019-03-25 21:49:35 iteration: 5095 loss: 0.0047 lr: 0.005
2019-03-25 21:51:08 iteration: 5100 loss: 0.0035 lr: 0.005
2019-03-25 21:51:46 iteration: 5105 loss: 0.0060 lr: 0.005
2019-03-25 21:52:22 iteration: 5110 loss: 0.0046 lr: 0.005
2019-03-25 21:52:50 iteration: 5115 loss: 0.0052 lr: 0.005
2019-03-25 21:53:06 iteration: 5120 loss: 0.0059 lr: 0.005
2019-03-25 21:53:33 iteration: 5125 loss: 0.0042 lr: 0.005
2019-03-25 21:54:31 iteration: 5130 loss: 0.0039 lr: 0.005
2019-03-25 21:54:51 iteration: 5135 loss: 0.0075 lr: 0.005
2019-03-25 21:55:38 iteration: 5140 loss: 0.0050 lr: 0.005
2019-03-25 21:56:20 iteration: 5145 loss: 0.0072 lr: 0.005
2019-03-25 21:56:41 iteration: 5150 loss: 0.0082 lr: 0.005
2019-03-25 21:57:14 iteration: 5155 loss: 0.0042 lr: 0.005
2019-03-25 21:58:17 iteration: 5160 loss: 0.0066 lr: 0.005
2019-03-25 21:59:10 iteration: 5165 loss: 0.0046 lr: 0.005
2019-03-25 21:59:42 iteration: 5170 loss: 0.0062 lr: 0.005
2019-03-25 22:00:12 iteration: 5175 loss: 0.0047 lr: 0.005
2019-03-25 22:01:31 iteration: 5180 loss: 0.0044 lr: 0.005
2019-03-25 22:02:14 iteration: 5185 loss: 0.0047 lr: 0.005
2019-03-25 22:02:59 iteration: 5190 loss: 0.0048 lr: 0.005
2019-03-25 22:03:21 iteration: 5195 loss: 0.0061 lr: 0.005
2019-03-25 22:03:39 iteration: 5200 loss: 0.0076 lr: 0.005
2019-03-25 22:04:14 iteration: 5205 loss: 0.0043 lr: 0.005
2019-03-25 22:04:35 iteration: 5210 loss: 0.0058 lr: 0.005
2019-03-25 22:05:14 iteration: 5215 loss: 0.0061 lr: 0.005
2019-03-25 22:05:44 iteration: 5220 loss: 0.0057 lr: 0.005
2019-03-25 22:06:08 iteration: 5225 loss: 0.0074 lr: 0.005
2019-03-25 22:06:37 iteration: 5230 loss: 0.0053 lr: 0.005
2019-03-25 22:06:58 iteration: 5235 loss: 0.0049 lr: 0.005
2019-03-25 22:07:33 iteration: 5240 loss: 0.0053 lr: 0.005
2019-03-25 22:08:09 iteration: 5245 loss: 0.0049 lr: 0.005
2019-03-25 22:08:30 iteration: 5250 loss: 0.0054 lr: 0.005
2019-03-25 22:08:54 iteration: 5255 loss: 0.0051 lr: 0.005
2019-03-25 22:10:02 iteration: 5260 loss: 0.0034 lr: 0.005
2019-03-25 22:10:25 iteration: 5265 loss: 0.0058 lr: 0.005
2019-03-25 22:11:19 iteration: 5270 loss: 0.0041 lr: 0.005
2019-03-25 22:12:00 iteration: 5275 loss: 0.0046 lr: 0.005
2019-03-25 22:12:23 iteration: 5280 loss: 0.0043 lr: 0.005
2019-03-25 22:12:47 iteration: 5285 loss: 0.0041 lr: 0.005
2019-03-25 22:13:03 iteration: 5290 loss: 0.0098 lr: 0.005
2019-03-25 22:13:22 iteration: 5295 loss: 0.0034 lr: 0.005
2019-03-25 22:13:39 iteration: 5300 loss: 0.0045 lr: 0.005
2019-03-25 22:14:24 iteration: 5305 loss: 0.0056 lr: 0.005
2019-03-25 22:14:57 iteration: 5310 loss: 0.0046 lr: 0.005
2019-03-25 22:15:42 iteration: 5315 loss: 0.0036 lr: 0.005
2019-03-25 22:16:06 iteration: 5320 loss: 0.0054 lr: 0.005
2019-03-25 22:16:49 iteration: 5325 loss: 0.0046 lr: 0.005
2019-03-25 22:17:11 iteration: 5330 loss: 0.0073 lr: 0.005
2019-03-25 22:17:44 iteration: 5335 loss: 0.0058 lr: 0.005
2019-03-25 22:18:21 iteration: 5340 loss: 0.0045 lr: 0.005
2019-03-25 22:18:40 iteration: 5345 loss: 0.0055 lr: 0.005
2019-03-25 22:18:53 iteration: 5350 loss: 0.0049 lr: 0.005
2019-03-25 22:19:04 iteration: 5355 loss: 0.0062 lr: 0.005
2019-03-25 22:20:04 iteration: 5360 loss: 0.0038 lr: 0.005
2019-03-25 22:20:30 iteration: 5365 loss: 0.0041 lr: 0.005
2019-03-25 22:21:06 iteration: 5370 loss: 0.0053 lr: 0.005
2019-03-25 22:21:55 iteration: 5375 loss: 0.0053 lr: 0.005
2019-03-25 22:22:32 iteration: 5380 loss: 0.0060 lr: 0.005
2019-03-25 22:23:15 iteration: 5385 loss: 0.0032 lr: 0.005
2019-03-25 22:24:00 iteration: 5390 loss: 0.0059 lr: 0.005
2019-03-25 22:25:18 iteration: 5395 loss: 0.0041 lr: 0.005
2019-03-25 22:26:22 iteration: 5400 loss: 0.0032 lr: 0.005
2019-03-25 22:26:32 iteration: 5405 loss: 0.0056 lr: 0.005
2019-03-25 22:27:55 iteration: 5410 loss: 0.0040 lr: 0.005
2019-03-25 22:28:20 iteration: 5415 loss: 0.0069 lr: 0.005
2019-03-25 22:28:47 iteration: 5420 loss: 0.0073 lr: 0.005
2019-03-25 22:29:25 iteration: 5425 loss: 0.0065 lr: 0.005
2019-03-25 22:29:49 iteration: 5430 loss: 0.0051 lr: 0.005
2019-03-25 22:30:19 iteration: 5435 loss: 0.0052 lr: 0.005
2019-03-25 22:31:06 iteration: 5440 loss: 0.0041 lr: 0.005
2019-03-25 22:32:15 iteration: 5445 loss: 0.0035 lr: 0.005
2019-03-25 22:32:30 iteration: 5450 loss: 0.0047 lr: 0.005
2019-03-25 22:33:06 iteration: 5455 loss: 0.0044 lr: 0.005
2019-03-25 22:33:36 iteration: 5460 loss: 0.0047 lr: 0.005
2019-03-25 22:33:51 iteration: 5465 loss: 0.0067 lr: 0.005
2019-03-25 22:34:28 iteration: 5470 loss: 0.0046 lr: 0.005
2019-03-25 22:35:09 iteration: 5475 loss: 0.0054 lr: 0.005
2019-03-25 22:35:22 iteration: 5480 loss: 0.0060 lr: 0.005
2019-03-25 22:36:56 iteration: 5485 loss: 0.0053 lr: 0.005
2019-03-25 22:37:28 iteration: 5490 loss: 0.0050 lr: 0.005
2019-03-25 22:38:48 iteration: 5495 loss: 0.0050 lr: 0.005
2019-03-25 22:39:37 iteration: 5500 loss: 0.0058 lr: 0.005
2019-03-25 22:40:32 iteration: 5505 loss: 0.0041 lr: 0.005
2019-03-25 22:40:45 iteration: 5510 loss: 0.0061 lr: 0.005
2019-03-25 22:40:58 iteration: 5515 loss: 0.0055 lr: 0.005
2019-03-25 22:41:39 iteration: 5520 loss: 0.0042 lr: 0.005
2019-03-25 22:42:03 iteration: 5525 loss: 0.0042 lr: 0.005
2019-03-25 22:43:01 iteration: 5530 loss: 0.0053 lr: 0.005
2019-03-25 22:43:45 iteration: 5535 loss: 0.0042 lr: 0.005
2019-03-25 22:44:28 iteration: 5540 loss: 0.0037 lr: 0.005
2019-03-25 22:45:51 iteration: 5545 loss: 0.0037 lr: 0.005
2019-03-25 22:46:13 iteration: 5550 loss: 0.0039 lr: 0.005
2019-03-25 22:46:33 iteration: 5555 loss: 0.0059 lr: 0.005
2019-03-25 22:46:46 iteration: 5560 loss: 0.0067 lr: 0.005
2019-03-25 22:47:20 iteration: 5565 loss: 0.0047 lr: 0.005
2019-03-25 22:47:48 iteration: 5570 loss: 0.0056 lr: 0.005
2019-03-25 22:48:18 iteration: 5575 loss: 0.0044 lr: 0.005
2019-03-25 22:48:32 iteration: 5580 loss: 0.0069 lr: 0.005
2019-03-25 22:48:48 iteration: 5585 loss: 0.0051 lr: 0.005
2019-03-25 22:49:45 iteration: 5590 loss: 0.0088 lr: 0.005
2019-03-25 22:50:01 iteration: 5595 loss: 0.0058 lr: 0.005
2019-03-25 22:50:15 iteration: 5600 loss: 0.0103 lr: 0.005
2019-03-25 22:51:17 iteration: 5605 loss: 0.0044 lr: 0.005
2019-03-25 22:52:29 iteration: 5610 loss: 0.0040 lr: 0.005
2019-03-25 22:53:01 iteration: 5615 loss: 0.0050 lr: 0.005
2019-03-25 22:54:23 iteration: 5620 loss: 0.0048 lr: 0.005
2019-03-25 22:54:49 iteration: 5625 loss: 0.0048 lr: 0.005
2019-03-25 22:55:52 iteration: 5630 loss: 0.0032 lr: 0.005
2019-03-25 22:56:14 iteration: 5635 loss: 0.0063 lr: 0.005
2019-03-25 22:56:27 iteration: 5640 loss: 0.0049 lr: 0.005
2019-03-25 22:57:08 iteration: 5645 loss: 0.0052 lr: 0.005
2019-03-25 22:57:30 iteration: 5650 loss: 0.0058 lr: 0.005
2019-03-25 22:57:39 iteration: 5655 loss: 0.0070 lr: 0.005
2019-03-25 22:58:58 iteration: 5660 loss: 0.0039 lr: 0.005
2019-03-25 22:59:16 iteration: 5665 loss: 0.0064 lr: 0.005
2019-03-25 23:00:03 iteration: 5670 loss: 0.0044 lr: 0.005
2019-03-25 23:01:08 iteration: 5675 loss: 0.0040 lr: 0.005
2019-03-25 23:01:22 iteration: 5680 loss: 0.0062 lr: 0.005
2019-03-25 23:01:42 iteration: 5685 loss: 0.0048 lr: 0.005
2019-03-25 23:02:28 iteration: 5690 loss: 0.0040 lr: 0.005
2019-03-25 23:03:37 iteration: 5695 loss: 0.0046 lr: 0.005
2019-03-25 23:04:37 iteration: 5700 loss: 0.0043 lr: 0.005
2019-03-25 23:05:19 iteration: 5705 loss: 0.0061 lr: 0.005
2019-03-25 23:05:54 iteration: 5710 loss: 0.0054 lr: 0.005
2019-03-25 23:07:34 iteration: 5715 loss: 0.0032 lr: 0.005
2019-03-25 23:08:43 iteration: 5720 loss: 0.0048 lr: 0.005
2019-03-25 23:09:10 iteration: 5725 loss: 0.0059 lr: 0.005
2019-03-25 23:10:31 iteration: 5730 loss: 0.0036 lr: 0.005
2019-03-25 23:11:00 iteration: 5735 loss: 0.0068 lr: 0.005
2019-03-25 23:12:10 iteration: 5740 loss: 0.0042 lr: 0.005
2019-03-25 23:13:01 iteration: 5745 loss: 0.0085 lr: 0.005
2019-03-25 23:13:49 iteration: 5750 loss: 0.0042 lr: 0.005
2019-03-25 23:14:02 iteration: 5755 loss: 0.0064 lr: 0.005
2019-03-25 23:14:44 iteration: 5760 loss: 0.0043 lr: 0.005
2019-03-25 23:14:58 iteration: 5765 loss: 0.0056 lr: 0.005
2019-03-25 23:16:24 iteration: 5770 loss: 0.0037 lr: 0.005
2019-03-25 23:17:05 iteration: 5775 loss: 0.0048 lr: 0.005
2019-03-25 23:17:32 iteration: 5780 loss: 0.0060 lr: 0.005
2019-03-25 23:18:05 iteration: 5785 loss: 0.0047 lr: 0.005
2019-03-25 23:19:36 iteration: 5790 loss: 0.0051 lr: 0.005
2019-03-25 23:20:15 iteration: 5795 loss: 0.0040 lr: 0.005
2019-03-25 23:20:42 iteration: 5800 loss: 0.0064 lr: 0.005
2019-03-25 23:21:33 iteration: 5805 loss: 0.0044 lr: 0.005
2019-03-25 23:22:04 iteration: 5810 loss: 0.0052 lr: 0.005
2019-03-25 23:22:16 iteration: 5815 loss: 0.0076 lr: 0.005
2019-03-25 23:22:44 iteration: 5820 loss: 0.0041 lr: 0.005
2019-03-25 23:23:00 iteration: 5825 loss: 0.0064 lr: 0.005
2019-03-25 23:24:12 iteration: 5830 loss: 0.0040 lr: 0.005
2019-03-25 23:24:36 iteration: 5835 loss: 0.0055 lr: 0.005
2019-03-25 23:25:00 iteration: 5840 loss: 0.0045 lr: 0.005
2019-03-25 23:25:21 iteration: 5845 loss: 0.0102 lr: 0.005
2019-03-25 23:25:39 iteration: 5850 loss: 0.0040 lr: 0.005
2019-03-25 23:26:13 iteration: 5855 loss: 0.0038 lr: 0.005
2019-03-25 23:26:42 iteration: 5860 loss: 0.0041 lr: 0.005
2019-03-25 23:27:34 iteration: 5865 loss: 0.0051 lr: 0.005
2019-03-25 23:27:55 iteration: 5870 loss: 0.0060 lr: 0.005
2019-03-25 23:28:38 iteration: 5875 loss: 0.0045 lr: 0.005
2019-03-25 23:29:50 iteration: 5880 loss: 0.0039 lr: 0.005
2019-03-25 23:30:38 iteration: 5885 loss: 0.0043 lr: 0.005
2019-03-25 23:31:03 iteration: 5890 loss: 0.0059 lr: 0.005
2019-03-25 23:31:26 iteration: 5895 loss: 0.0038 lr: 0.005
2019-03-25 23:32:17 iteration: 5900 loss: 0.0046 lr: 0.005
2019-03-25 23:33:05 iteration: 5905 loss: 0.0040 lr: 0.005
2019-03-25 23:33:40 iteration: 5910 loss: 0.0043 lr: 0.005
2019-03-25 23:35:18 iteration: 5915 loss: 0.0045 lr: 0.005
2019-03-25 23:35:55 iteration: 5920 loss: 0.0051 lr: 0.005
2019-03-25 23:36:23 iteration: 5925 loss: 0.0034 lr: 0.005
2019-03-25 23:36:48 iteration: 5930 loss: 0.0037 lr: 0.005
2019-03-25 23:37:08 iteration: 5935 loss: 0.0055 lr: 0.005
2019-03-25 23:37:57 iteration: 5940 loss: 0.0043 lr: 0.005
2019-03-25 23:38:06 iteration: 5945 loss: 0.0057 lr: 0.005
2019-03-25 23:39:55 iteration: 5950 loss: 0.0043 lr: 0.005
2019-03-25 23:40:23 iteration: 5955 loss: 0.0054 lr: 0.005
2019-03-25 23:40:38 iteration: 5960 loss: 0.0071 lr: 0.005
2019-03-25 23:40:56 iteration: 5965 loss: 0.0053 lr: 0.005
2019-03-25 23:41:43 iteration: 5970 loss: 0.0070 lr: 0.005
2019-03-25 23:42:26 iteration: 5975 loss: 0.0055 lr: 0.005
2019-03-25 23:42:47 iteration: 5980 loss: 0.0050 lr: 0.005
2019-03-25 23:43:00 iteration: 5985 loss: 0.0057 lr: 0.005
2019-03-25 23:43:08 iteration: 5990 loss: 0.0075 lr: 0.005
2019-03-25 23:44:24 iteration: 5995 loss: 0.0053 lr: 0.005
2019-03-25 23:44:51 iteration: 6000 loss: 0.0046 lr: 0.005
2019-03-25 23:45:30 iteration: 6005 loss: 0.0067 lr: 0.005
2019-03-25 23:45:56 iteration: 6010 loss: 0.0051 lr: 0.005
2019-03-25 23:46:15 iteration: 6015 loss: 0.0065 lr: 0.005
2019-03-25 23:46:30 iteration: 6020 loss: 0.0054 lr: 0.005
2019-03-25 23:47:45 iteration: 6025 loss: 0.0060 lr: 0.005
2019-03-25 23:48:02 iteration: 6030 loss: 0.0047 lr: 0.005
2019-03-25 23:48:40 iteration: 6035 loss: 0.0053 lr: 0.005
2019-03-25 23:49:41 iteration: 6040 loss: 0.0042 lr: 0.005
2019-03-25 23:50:52 iteration: 6045 loss: 0.0043 lr: 0.005
2019-03-25 23:51:53 iteration: 6050 loss: 0.0040 lr: 0.005
2019-03-25 23:52:20 iteration: 6055 loss: 0.0041 lr: 0.005
2019-03-25 23:52:31 iteration: 6060 loss: 0.0070 lr: 0.005
2019-03-25 23:52:55 iteration: 6065 loss: 0.0033 lr: 0.005
2019-03-25 23:53:20 iteration: 6070 loss: 0.0042 lr: 0.005
2019-03-25 23:53:39 iteration: 6075 loss: 0.0053 lr: 0.005
2019-03-25 23:54:03 iteration: 6080 loss: 0.0048 lr: 0.005
2019-03-25 23:54:15 iteration: 6085 loss: 0.0054 lr: 0.005
2019-03-25 23:55:04 iteration: 6090 loss: 0.0044 lr: 0.005
2019-03-25 23:56:24 iteration: 6095 loss: 0.0048 lr: 0.005
2019-03-25 23:57:38 iteration: 6100 loss: 0.0046 lr: 0.005
2019-03-25 23:58:14 iteration: 6105 loss: 0.0052 lr: 0.005
2019-03-25 23:59:15 iteration: 6110 loss: 0.0066 lr: 0.005
2019-03-25 23:59:56 iteration: 6115 loss: 0.0035 lr: 0.005
2019-03-26 00:00:22 iteration: 6120 loss: 0.0048 lr: 0.005
2019-03-26 00:00:50 iteration: 6125 loss: 0.0036 lr: 0.005
2019-03-26 00:01:44 iteration: 6130 loss: 0.0036 lr: 0.005
2019-03-26 00:03:03 iteration: 6135 loss: 0.0034 lr: 0.005
2019-03-26 00:04:06 iteration: 6140 loss: 0.0048 lr: 0.005
2019-03-26 00:04:27 iteration: 6145 loss: 0.0048 lr: 0.005
2019-03-26 00:04:41 iteration: 6150 loss: 0.0058 lr: 0.005
2019-03-26 00:05:09 iteration: 6155 loss: 0.0058 lr: 0.005
2019-03-26 00:05:54 iteration: 6160 loss: 0.0063 lr: 0.005
2019-03-26 00:06:36 iteration: 6165 loss: 0.0051 lr: 0.005
2019-03-26 00:07:09 iteration: 6170 loss: 0.0050 lr: 0.005
2019-03-26 00:07:24 iteration: 6175 loss: 0.0052 lr: 0.005
2019-03-26 00:08:13 iteration: 6180 loss: 0.0047 lr: 0.005
2019-03-26 00:09:17 iteration: 6185 loss: 0.0036 lr: 0.005
2019-03-26 00:09:37 iteration: 6190 loss: 0.0052 lr: 0.005
2019-03-26 00:09:53 iteration: 6195 loss: 0.0074 lr: 0.005
2019-03-26 00:10:24 iteration: 6200 loss: 0.0040 lr: 0.005
2019-03-26 00:10:40 iteration: 6205 loss: 0.0055 lr: 0.005
2019-03-26 00:11:22 iteration: 6210 loss: 0.0048 lr: 0.005
2019-03-26 00:12:03 iteration: 6215 loss: 0.0038 lr: 0.005
2019-03-26 00:13:36 iteration: 6220 loss: 0.0041 lr: 0.005
2019-03-26 00:13:55 iteration: 6225 loss: 0.0044 lr: 0.005
2019-03-26 00:15:16 iteration: 6230 loss: 0.0042 lr: 0.005
2019-03-26 00:15:46 iteration: 6235 loss: 0.0058 lr: 0.005
2019-03-26 00:16:14 iteration: 6240 loss: 0.0035 lr: 0.005
2019-03-26 00:16:27 iteration: 6245 loss: 0.0055 lr: 0.005
2019-03-26 00:17:05 iteration: 6250 loss: 0.0051 lr: 0.005
2019-03-26 00:17:50 iteration: 6255 loss: 0.0041 lr: 0.005
2019-03-26 00:18:31 iteration: 6260 loss: 0.0046 lr: 0.005
2019-03-26 00:18:48 iteration: 6265 loss: 0.0055 lr: 0.005
2019-03-26 00:19:06 iteration: 6270 loss: 0.0047 lr: 0.005
2019-03-26 00:19:30 iteration: 6275 loss: 0.0079 lr: 0.005
2019-03-26 00:20:39 iteration: 6280 loss: 0.0041 lr: 0.005
2019-03-26 00:21:25 iteration: 6285 loss: 0.0052 lr: 0.005
2019-03-26 00:22:50 iteration: 6290 loss: 0.0050 lr: 0.005
2019-03-26 00:23:04 iteration: 6295 loss: 0.0061 lr: 0.005
2019-03-26 00:23:51 iteration: 6300 loss: 0.0026 lr: 0.005
2019-03-26 00:24:06 iteration: 6305 loss: 0.0059 lr: 0.005
2019-03-26 00:24:20 iteration: 6310 loss: 0.0053 lr: 0.005
2019-03-26 00:24:43 iteration: 6315 loss: 0.0041 lr: 0.005
2019-03-26 00:25:06 iteration: 6320 loss: 0.0063 lr: 0.005
2019-03-26 00:25:59 iteration: 6325 loss: 0.0052 lr: 0.005
2019-03-26 00:26:37 iteration: 6330 loss: 0.0037 lr: 0.005
2019-03-26 00:27:16 iteration: 6335 loss: 0.0048 lr: 0.005
2019-03-26 00:27:53 iteration: 6340 loss: 0.0037 lr: 0.005
2019-03-26 00:28:29 iteration: 6345 loss: 0.0045 lr: 0.005
2019-03-26 00:29:03 iteration: 6350 loss: 0.0060 lr: 0.005
2019-03-26 00:30:02 iteration: 6355 loss: 0.0050 lr: 0.005
2019-03-26 00:30:28 iteration: 6360 loss: 0.0074 lr: 0.005
2019-03-26 00:31:00 iteration: 6365 loss: 0.0051 lr: 0.005
2019-03-26 00:31:17 iteration: 6370 loss: 0.0049 lr: 0.005
2019-03-26 00:31:59 iteration: 6375 loss: 0.0043 lr: 0.005
2019-03-26 00:32:25 iteration: 6380 loss: 0.0039 lr: 0.005
2019-03-26 00:32:48 iteration: 6385 loss: 0.0045 lr: 0.005
2019-03-26 00:33:10 iteration: 6390 loss: 0.0042 lr: 0.005
2019-03-26 00:33:38 iteration: 6395 loss: 0.0042 lr: 0.005
2019-03-26 00:34:14 iteration: 6400 loss: 0.0054 lr: 0.005
2019-03-26 00:34:40 iteration: 6405 loss: 0.0053 lr: 0.005
2019-03-26 00:35:04 iteration: 6410 loss: 0.0056 lr: 0.005
2019-03-26 00:35:27 iteration: 6415 loss: 0.0075 lr: 0.005
2019-03-26 00:35:37 iteration: 6420 loss: 0.0070 lr: 0.005
2019-03-26 00:36:09 iteration: 6425 loss: 0.0053 lr: 0.005
2019-03-26 00:36:42 iteration: 6430 loss: 0.0041 lr: 0.005
2019-03-26 00:36:59 iteration: 6435 loss: 0.0067 lr: 0.005
2019-03-26 00:37:46 iteration: 6440 loss: 0.0053 lr: 0.005
2019-03-26 00:38:14 iteration: 6445 loss: 0.0040 lr: 0.005
2019-03-26 00:39:01 iteration: 6450 loss: 0.0054 lr: 0.005
2019-03-26 00:40:24 iteration: 6455 loss: 0.0029 lr: 0.005
2019-03-26 00:41:02 iteration: 6460 loss: 0.0048 lr: 0.005
2019-03-26 00:41:24 iteration: 6465 loss: 0.0054 lr: 0.005
2019-03-26 00:43:19 iteration: 6470 loss: 0.0036 lr: 0.005
2019-03-26 00:43:33 iteration: 6475 loss: 0.0056 lr: 0.005
2019-03-26 00:44:49 iteration: 6480 loss: 0.0035 lr: 0.005
2019-03-26 00:45:12 iteration: 6485 loss: 0.0043 lr: 0.005
2019-03-26 00:46:25 iteration: 6490 loss: 0.0047 lr: 0.005
2019-03-26 00:47:10 iteration: 6495 loss: 0.0050 lr: 0.005
2019-03-26 00:47:35 iteration: 6500 loss: 0.0044 lr: 0.005
2019-03-26 00:48:32 iteration: 6505 loss: 0.0049 lr: 0.005
2019-03-26 00:49:12 iteration: 6510 loss: 0.0068 lr: 0.005
2019-03-26 00:49:51 iteration: 6515 loss: 0.0050 lr: 0.005
2019-03-26 00:50:34 iteration: 6520 loss: 0.0054 lr: 0.005
2019-03-26 00:51:16 iteration: 6525 loss: 0.0045 lr: 0.005
2019-03-26 00:51:53 iteration: 6530 loss: 0.0048 lr: 0.005
2019-03-26 00:52:08 iteration: 6535 loss: 0.0043 lr: 0.005
2019-03-26 00:52:37 iteration: 6540 loss: 0.0052 lr: 0.005
2019-03-26 00:52:54 iteration: 6545 loss: 0.0061 lr: 0.005
2019-03-26 00:53:25 iteration: 6550 loss: 0.0035 lr: 0.005
2019-03-26 00:53:57 iteration: 6555 loss: 0.0035 lr: 0.005
2019-03-26 00:54:35 iteration: 6560 loss: 0.0046 lr: 0.005
2019-03-26 00:54:47 iteration: 6565 loss: 0.0055 lr: 0.005
2019-03-26 00:55:03 iteration: 6570 loss: 0.0068 lr: 0.005
2019-03-26 00:56:05 iteration: 6575 loss: 0.0034 lr: 0.005
2019-03-26 00:57:05 iteration: 6580 loss: 0.0043 lr: 0.005
2019-03-26 00:57:16 iteration: 6585 loss: 0.0063 lr: 0.005
2019-03-26 00:57:38 iteration: 6590 loss: 0.0048 lr: 0.005
2019-03-26 00:58:21 iteration: 6595 loss: 0.0044 lr: 0.005
2019-03-26 00:59:15 iteration: 6600 loss: 0.0042 lr: 0.005
2019-03-26 00:59:34 iteration: 6605 loss: 0.0055 lr: 0.005
2019-03-26 01:00:33 iteration: 6610 loss: 0.0031 lr: 0.005
2019-03-26 01:01:06 iteration: 6615 loss: 0.0044 lr: 0.005
2019-03-26 01:01:43 iteration: 6620 loss: 0.0054 lr: 0.005
2019-03-26 01:02:16 iteration: 6625 loss: 0.0041 lr: 0.005
2019-03-26 01:02:47 iteration: 6630 loss: 0.0057 lr: 0.005
2019-03-26 01:03:28 iteration: 6635 loss: 0.0082 lr: 0.005
2019-03-26 01:03:58 iteration: 6640 loss: 0.0049 lr: 0.005
2019-03-26 01:05:00 iteration: 6645 loss: 0.0054 lr: 0.005
2019-03-26 01:06:09 iteration: 6650 loss: 0.0026 lr: 0.005
2019-03-26 01:06:23 iteration: 6655 loss: 0.0084 lr: 0.005
2019-03-26 01:06:55 iteration: 6660 loss: 0.0036 lr: 0.005
2019-03-26 01:07:10 iteration: 6665 loss: 0.0051 lr: 0.005
2019-03-26 01:08:37 iteration: 6670 loss: 0.0034 lr: 0.005
2019-03-26 01:08:56 iteration: 6675 loss: 0.0055 lr: 0.005
2019-03-26 01:09:32 iteration: 6680 loss: 0.0059 lr: 0.005
2019-03-26 01:09:50 iteration: 6685 loss: 0.0060 lr: 0.005
2019-03-26 01:10:03 iteration: 6690 loss: 0.0050 lr: 0.005
2019-03-26 01:10:47 iteration: 6695 loss: 0.0045 lr: 0.005
2019-03-26 01:11:37 iteration: 6700 loss: 0.0084 lr: 0.005
2019-03-26 01:12:36 iteration: 6705 loss: 0.0039 lr: 0.005
2019-03-26 01:13:06 iteration: 6710 loss: 0.0048 lr: 0.005
2019-03-26 01:14:00 iteration: 6715 loss: 0.0081 lr: 0.005
2019-03-26 01:15:08 iteration: 6720 loss: 0.0050 lr: 0.005
2019-03-26 01:15:57 iteration: 6725 loss: 0.0048 lr: 0.005
2019-03-26 01:16:29 iteration: 6730 loss: 0.0051 lr: 0.005
2019-03-26 01:16:52 iteration: 6735 loss: 0.0046 lr: 0.005
2019-03-26 01:17:04 iteration: 6740 loss: 0.0050 lr: 0.005
2019-03-26 01:17:47 iteration: 6745 loss: 0.0053 lr: 0.005
2019-03-26 01:18:05 iteration: 6750 loss: 0.0053 lr: 0.005
2019-03-26 01:19:06 iteration: 6755 loss: 0.0051 lr: 0.005
2019-03-26 01:19:28 iteration: 6760 loss: 0.0042 lr: 0.005
2019-03-26 01:20:15 iteration: 6765 loss: 0.0062 lr: 0.005
2019-03-26 01:20:54 iteration: 6770 loss: 0.0038 lr: 0.005
2019-03-26 01:22:21 iteration: 6775 loss: 0.0036 lr: 0.005
2019-03-26 01:23:02 iteration: 6780 loss: 0.0046 lr: 0.005
2019-03-26 01:24:05 iteration: 6785 loss: 0.0045 lr: 0.005
2019-03-26 01:24:56 iteration: 6790 loss: 0.0045 lr: 0.005
2019-03-26 01:25:36 iteration: 6795 loss: 0.0050 lr: 0.005
2019-03-26 01:25:53 iteration: 6800 loss: 0.0047 lr: 0.005
2019-03-26 01:26:27 iteration: 6805 loss: 0.0059 lr: 0.005
2019-03-26 01:26:45 iteration: 6810 loss: 0.0052 lr: 0.005
2019-03-26 01:26:59 iteration: 6815 loss: 0.0051 lr: 0.005
2019-03-26 01:27:32 iteration: 6820 loss: 0.0052 lr: 0.005
2019-03-26 01:28:16 iteration: 6825 loss: 0.0046 lr: 0.005
2019-03-26 01:28:33 iteration: 6830 loss: 0.0048 lr: 0.005
2019-03-26 01:28:51 iteration: 6835 loss: 0.0046 lr: 0.005
2019-03-26 01:29:04 iteration: 6840 loss: 0.0048 lr: 0.005
2019-03-26 01:29:49 iteration: 6845 loss: 0.0045 lr: 0.005
2019-03-26 01:30:42 iteration: 6850 loss: 0.0052 lr: 0.005
2019-03-26 01:31:22 iteration: 6855 loss: 0.0051 lr: 0.005
2019-03-26 01:32:15 iteration: 6860 loss: 0.0028 lr: 0.005
2019-03-26 01:33:17 iteration: 6865 loss: 0.0040 lr: 0.005
2019-03-26 01:33:41 iteration: 6870 loss: 0.0058 lr: 0.005
2019-03-26 01:34:16 iteration: 6875 loss: 0.0075 lr: 0.005
2019-03-26 01:34:54 iteration: 6880 loss: 0.0047 lr: 0.005
2019-03-26 01:35:13 iteration: 6885 loss: 0.0073 lr: 0.005
2019-03-26 01:35:37 iteration: 6890 loss: 0.0045 lr: 0.005
2019-03-26 01:36:48 iteration: 6895 loss: 0.0060 lr: 0.005
2019-03-26 01:37:02 iteration: 6900 loss: 0.0058 lr: 0.005
2019-03-26 01:37:11 iteration: 6905 loss: 0.0058 lr: 0.005
2019-03-26 01:37:43 iteration: 6910 loss: 0.0055 lr: 0.005
2019-03-26 01:38:45 iteration: 6915 loss: 0.0030 lr: 0.005
2019-03-26 01:39:47 iteration: 6920 loss: 0.0049 lr: 0.005
2019-03-26 01:40:26 iteration: 6925 loss: 0.0080 lr: 0.005
2019-03-26 01:40:47 iteration: 6930 loss: 0.0075 lr: 0.005
2019-03-26 01:41:31 iteration: 6935 loss: 0.0059 lr: 0.005
2019-03-26 01:42:01 iteration: 6940 loss: 0.0044 lr: 0.005
2019-03-26 01:42:56 iteration: 6945 loss: 0.0063 lr: 0.005
2019-03-26 01:43:34 iteration: 6950 loss: 0.0043 lr: 0.005
2019-03-26 01:44:21 iteration: 6955 loss: 0.0043 lr: 0.005
2019-03-26 01:44:48 iteration: 6960 loss: 0.0054 lr: 0.005
2019-03-26 01:45:39 iteration: 6965 loss: 0.0034 lr: 0.005
2019-03-26 01:46:33 iteration: 6970 loss: 0.0039 lr: 0.005
2019-03-26 01:46:56 iteration: 6975 loss: 0.0058 lr: 0.005
2019-03-26 01:47:13 iteration: 6980 loss: 0.0054 lr: 0.005
2019-03-26 01:47:27 iteration: 6985 loss: 0.0065 lr: 0.005
2019-03-26 01:48:09 iteration: 6990 loss: 0.0045 lr: 0.005
2019-03-26 01:48:56 iteration: 6995 loss: 0.0059 lr: 0.005
2019-03-26 01:49:13 iteration: 7000 loss: 0.0051 lr: 0.005
2019-03-26 01:49:31 iteration: 7005 loss: 0.0047 lr: 0.005
2019-03-26 01:49:49 iteration: 7010 loss: 0.0094 lr: 0.005
2019-03-26 01:50:28 iteration: 7015 loss: 0.0041 lr: 0.005
2019-03-26 01:51:04 iteration: 7020 loss: 0.0049 lr: 0.005
2019-03-26 01:51:33 iteration: 7025 loss: 0.0045 lr: 0.005
2019-03-26 01:52:15 iteration: 7030 loss: 0.0034 lr: 0.005
2019-03-26 01:53:10 iteration: 7035 loss: 0.0040 lr: 0.005
2019-03-26 01:53:35 iteration: 7040 loss: 0.0046 lr: 0.005
2019-03-26 01:53:52 iteration: 7045 loss: 0.0030 lr: 0.005
2019-03-26 01:54:14 iteration: 7050 loss: 0.0080 lr: 0.005
2019-03-26 01:55:26 iteration: 7055 loss: 0.0040 lr: 0.005
2019-03-26 01:55:54 iteration: 7060 loss: 0.0047 lr: 0.005
2019-03-26 01:57:09 iteration: 7065 loss: 0.0047 lr: 0.005
2019-03-26 01:58:04 iteration: 7070 loss: 0.0086 lr: 0.005
2019-03-26 01:58:39 iteration: 7075 loss: 0.0043 lr: 0.005
2019-03-26 01:59:50 iteration: 7080 loss: 0.0038 lr: 0.005
2019-03-26 02:00:44 iteration: 7085 loss: 0.0032 lr: 0.005
2019-03-26 02:01:36 iteration: 7090 loss: 0.0047 lr: 0.005
2019-03-26 02:02:29 iteration: 7095 loss: 0.0039 lr: 0.005
2019-03-26 02:03:13 iteration: 7100 loss: 0.0060 lr: 0.005
2019-03-26 02:03:33 iteration: 7105 loss: 0.0069 lr: 0.005
2019-03-26 02:03:53 iteration: 7110 loss: 0.0045 lr: 0.005
2019-03-26 02:04:06 iteration: 7115 loss: 0.0057 lr: 0.005
2019-03-26 02:04:50 iteration: 7120 loss: 0.0078 lr: 0.005
2019-03-26 02:05:34 iteration: 7125 loss: 0.0053 lr: 0.005
2019-03-26 02:05:56 iteration: 7130 loss: 0.0043 lr: 0.005
2019-03-26 02:06:30 iteration: 7135 loss: 0.0049 lr: 0.005
2019-03-26 02:07:12 iteration: 7140 loss: 0.0053 lr: 0.005
2019-03-26 02:07:34 iteration: 7145 loss: 0.0045 lr: 0.005
2019-03-26 02:08:15 iteration: 7150 loss: 0.0038 lr: 0.005
2019-03-26 02:09:19 iteration: 7155 loss: 0.0033 lr: 0.005
2019-03-26 02:09:36 iteration: 7160 loss: 0.0072 lr: 0.005
2019-03-26 02:09:52 iteration: 7165 loss: 0.0054 lr: 0.005
2019-03-26 02:11:34 iteration: 7170 loss: 0.0045 lr: 0.005
2019-03-26 02:11:55 iteration: 7175 loss: 0.0048 lr: 0.005
2019-03-26 02:13:07 iteration: 7180 loss: 0.0039 lr: 0.005
2019-03-26 02:13:37 iteration: 7185 loss: 0.0042 lr: 0.005
2019-03-26 02:13:49 iteration: 7190 loss: 0.0106 lr: 0.005
2019-03-26 02:14:02 iteration: 7195 loss: 0.0042 lr: 0.005
2019-03-26 02:14:25 iteration: 7200 loss: 0.0071 lr: 0.005
2019-03-26 02:14:43 iteration: 7205 loss: 0.0062 lr: 0.005
2019-03-26 02:15:20 iteration: 7210 loss: 0.0042 lr: 0.005
2019-03-26 02:15:47 iteration: 7215 loss: 0.0057 lr: 0.005
2019-03-26 02:16:30 iteration: 7220 loss: 0.0063 lr: 0.005
2019-03-26 02:16:54 iteration: 7225 loss: 0.0048 lr: 0.005
2019-03-26 02:17:26 iteration: 7230 loss: 0.0056 lr: 0.005
2019-03-26 02:18:00 iteration: 7235 loss: 0.0044 lr: 0.005
2019-03-26 02:18:27 iteration: 7240 loss: 0.0047 lr: 0.005
2019-03-26 02:18:40 iteration: 7245 loss: 0.0044 lr: 0.005
2019-03-26 02:19:12 iteration: 7250 loss: 0.0046 lr: 0.005
2019-03-26 02:20:16 iteration: 7255 loss: 0.0038 lr: 0.005
2019-03-26 02:21:01 iteration: 7260 loss: 0.0035 lr: 0.005
2019-03-26 02:21:19 iteration: 7265 loss: 0.0039 lr: 0.005
2019-03-26 02:22:09 iteration: 7270 loss: 0.0035 lr: 0.005
2019-03-26 02:22:19 iteration: 7275 loss: 0.0112 lr: 0.005
2019-03-26 02:22:32 iteration: 7280 loss: 0.0052 lr: 0.005
2019-03-26 02:22:48 iteration: 7285 loss: 0.0060 lr: 0.005
2019-03-26 02:23:24 iteration: 7290 loss: 0.0043 lr: 0.005
2019-03-26 02:24:05 iteration: 7295 loss: 0.0038 lr: 0.005
2019-03-26 02:25:02 iteration: 7300 loss: 0.0040 lr: 0.005
2019-03-26 02:25:40 iteration: 7305 loss: 0.0049 lr: 0.005
2019-03-26 02:25:53 iteration: 7310 loss: 0.0076 lr: 0.005
2019-03-26 02:26:30 iteration: 7315 loss: 0.0039 lr: 0.005
2019-03-26 02:26:54 iteration: 7320 loss: 0.0039 lr: 0.005
2019-03-26 02:27:04 iteration: 7325 loss: 0.0051 lr: 0.005
2019-03-26 02:28:15 iteration: 7330 loss: 0.0045 lr: 0.005
2019-03-26 02:28:59 iteration: 7335 loss: 0.0042 lr: 0.005
2019-03-26 02:29:45 iteration: 7340 loss: 0.0038 lr: 0.005
2019-03-26 02:30:15 iteration: 7345 loss: 0.0049 lr: 0.005
2019-03-26 02:31:06 iteration: 7350 loss: 0.0056 lr: 0.005
2019-03-26 02:31:30 iteration: 7355 loss: 0.0045 lr: 0.005
2019-03-26 02:31:59 iteration: 7360 loss: 0.0042 lr: 0.005
2019-03-26 02:32:24 iteration: 7365 loss: 0.0039 lr: 0.005
2019-03-26 02:33:21 iteration: 7370 loss: 0.0038 lr: 0.005
2019-03-26 02:33:36 iteration: 7375 loss: 0.0054 lr: 0.005
2019-03-26 02:33:53 iteration: 7380 loss: 0.0058 lr: 0.005
2019-03-26 02:34:12 iteration: 7385 loss: 0.0046 lr: 0.005
2019-03-26 02:34:54 iteration: 7390 loss: 0.0072 lr: 0.005
2019-03-26 02:35:12 iteration: 7395 loss: 0.0040 lr: 0.005
2019-03-26 02:35:54 iteration: 7400 loss: 0.0047 lr: 0.005
2019-03-26 02:36:21 iteration: 7405 loss: 0.0031 lr: 0.005
2019-03-26 02:36:56 iteration: 7410 loss: 0.0057 lr: 0.005
2019-03-26 02:37:55 iteration: 7415 loss: 0.0063 lr: 0.005
2019-03-26 02:38:16 iteration: 7420 loss: 0.0059 lr: 0.005
2019-03-26 02:38:31 iteration: 7425 loss: 0.0049 lr: 0.005
2019-03-26 02:39:08 iteration: 7430 loss: 0.0050 lr: 0.005
2019-03-26 02:39:37 iteration: 7435 loss: 0.0037 lr: 0.005
2019-03-26 02:40:56 iteration: 7440 loss: 0.0032 lr: 0.005
2019-03-26 02:41:11 iteration: 7445 loss: 0.0069 lr: 0.005
2019-03-26 02:41:44 iteration: 7450 loss: 0.0044 lr: 0.005
2019-03-26 02:42:00 iteration: 7455 loss: 0.0053 lr: 0.005
2019-03-26 02:42:19 iteration: 7460 loss: 0.0058 lr: 0.005
2019-03-26 02:42:46 iteration: 7465 loss: 0.0039 lr: 0.005
2019-03-26 02:43:09 iteration: 7470 loss: 0.0041 lr: 0.005
2019-03-26 02:44:33 iteration: 7475 loss: 0.0039 lr: 0.005
2019-03-26 02:44:52 iteration: 7480 loss: 0.0045 lr: 0.005
2019-03-26 02:45:25 iteration: 7485 loss: 0.0043 lr: 0.005
2019-03-26 02:46:00 iteration: 7490 loss: 0.0058 lr: 0.005
2019-03-26 02:47:50 iteration: 7495 loss: 0.0038 lr: 0.005
2019-03-26 02:48:54 iteration: 7500 loss: 0.0058 lr: 0.005
2019-03-26 02:49:09 iteration: 7505 loss: 0.0069 lr: 0.005
2019-03-26 02:49:20 iteration: 7510 loss: 0.0050 lr: 0.005
2019-03-26 02:49:52 iteration: 7515 loss: 0.0041 lr: 0.005
2019-03-26 02:50:12 iteration: 7520 loss: 0.0064 lr: 0.005
2019-03-26 02:50:35 iteration: 7525 loss: 0.0051 lr: 0.005
2019-03-26 02:50:47 iteration: 7530 loss: 0.0047 lr: 0.005
2019-03-26 02:51:39 iteration: 7535 loss: 0.0043 lr: 0.005
2019-03-26 02:52:15 iteration: 7540 loss: 0.0032 lr: 0.005
2019-03-26 02:52:59 iteration: 7545 loss: 0.0035 lr: 0.005
2019-03-26 02:53:42 iteration: 7550 loss: 0.0052 lr: 0.005
2019-03-26 02:54:50 iteration: 7555 loss: 0.0034 lr: 0.005
2019-03-26 02:55:10 iteration: 7560 loss: 0.0079 lr: 0.005
2019-03-26 02:56:07 iteration: 7565 loss: 0.0046 lr: 0.005
2019-03-26 02:57:22 iteration: 7570 loss: 0.0052 lr: 0.005
2019-03-26 02:58:24 iteration: 7575 loss: 0.0040 lr: 0.005
2019-03-26 02:59:00 iteration: 7580 loss: 0.0048 lr: 0.005
2019-03-26 02:59:21 iteration: 7585 loss: 0.0053 lr: 0.005
2019-03-26 03:00:09 iteration: 7590 loss: 0.0040 lr: 0.005
2019-03-26 03:00:57 iteration: 7595 loss: 0.0047 lr: 0.005
2019-03-26 03:01:20 iteration: 7600 loss: 0.0049 lr: 0.005
2019-03-26 03:01:35 iteration: 7605 loss: 0.0055 lr: 0.005
2019-03-26 03:02:16 iteration: 7610 loss: 0.0066 lr: 0.005
2019-03-26 03:03:01 iteration: 7615 loss: 0.0044 lr: 0.005
2019-03-26 03:03:57 iteration: 7620 loss: 0.0044 lr: 0.005
2019-03-26 03:04:49 iteration: 7625 loss: 0.0041 lr: 0.005
2019-03-26 03:05:17 iteration: 7630 loss: 0.0045 lr: 0.005
2019-03-26 03:05:37 iteration: 7635 loss: 0.0068 lr: 0.005
2019-03-26 03:05:53 iteration: 7640 loss: 0.0068 lr: 0.005
2019-03-26 03:06:54 iteration: 7645 loss: 0.0091 lr: 0.005
2019-03-26 03:07:10 iteration: 7650 loss: 0.0066 lr: 0.005
2019-03-26 03:07:59 iteration: 7655 loss: 0.0038 lr: 0.005
2019-03-26 03:08:12 iteration: 7660 loss: 0.0055 lr: 0.005
2019-03-26 03:08:46 iteration: 7665 loss: 0.0037 lr: 0.005
2019-03-26 03:10:05 iteration: 7670 loss: 0.0055 lr: 0.005
2019-03-26 03:10:21 iteration: 7675 loss: 0.0042 lr: 0.005
2019-03-26 03:11:14 iteration: 7680 loss: 0.0042 lr: 0.005
2019-03-26 03:12:04 iteration: 7685 loss: 0.0036 lr: 0.005
2019-03-26 03:12:21 iteration: 7690 loss: 0.0081 lr: 0.005
2019-03-26 03:13:20 iteration: 7695 loss: 0.0039 lr: 0.005
2019-03-26 03:14:13 iteration: 7700 loss: 0.0045 lr: 0.005
2019-03-26 03:14:49 iteration: 7705 loss: 0.0044 lr: 0.005
2019-03-26 03:15:20 iteration: 7710 loss: 0.0061 lr: 0.005
2019-03-26 03:15:37 iteration: 7715 loss: 0.0049 lr: 0.005
2019-03-26 03:15:54 iteration: 7720 loss: 0.0043 lr: 0.005
2019-03-26 03:16:20 iteration: 7725 loss: 0.0088 lr: 0.005
2019-03-26 03:16:39 iteration: 7730 loss: 0.0092 lr: 0.005
2019-03-26 03:17:21 iteration: 7735 loss: 0.0054 lr: 0.005
2019-03-26 03:18:09 iteration: 7740 loss: 0.0046 lr: 0.005
2019-03-26 03:18:22 iteration: 7745 loss: 0.0085 lr: 0.005
2019-03-26 03:19:12 iteration: 7750 loss: 0.0048 lr: 0.005
2019-03-26 03:19:41 iteration: 7755 loss: 0.0048 lr: 0.005
2019-03-26 03:21:04 iteration: 7760 loss: 0.0036 lr: 0.005
2019-03-26 03:21:29 iteration: 7765 loss: 0.0050 lr: 0.005
2019-03-26 03:21:43 iteration: 7770 loss: 0.0052 lr: 0.005
2019-03-26 03:22:40 iteration: 7775 loss: 0.0045 lr: 0.005
2019-03-26 03:22:54 iteration: 7780 loss: 0.0055 lr: 0.005
2019-03-26 03:23:34 iteration: 7785 loss: 0.0040 lr: 0.005
2019-03-26 03:24:20 iteration: 7790 loss: 0.0061 lr: 0.005
2019-03-26 03:25:02 iteration: 7795 loss: 0.0038 lr: 0.005
2019-03-26 03:25:21 iteration: 7800 loss: 0.0051 lr: 0.005
2019-03-26 03:26:14 iteration: 7805 loss: 0.0064 lr: 0.005
2019-03-26 03:26:46 iteration: 7810 loss: 0.0046 lr: 0.005
2019-03-26 03:27:03 iteration: 7815 loss: 0.0058 lr: 0.005
2019-03-26 03:27:47 iteration: 7820 loss: 0.0041 lr: 0.005
2019-03-26 03:28:26 iteration: 7825 loss: 0.0044 lr: 0.005
2019-03-26 03:28:41 iteration: 7830 loss: 0.0046 lr: 0.005
2019-03-26 03:28:58 iteration: 7835 loss: 0.0042 lr: 0.005
2019-03-26 03:29:06 iteration: 7840 loss: 0.0080 lr: 0.005
2019-03-26 03:29:19 iteration: 7845 loss: 0.0044 lr: 0.005
2019-03-26 03:30:03 iteration: 7850 loss: 0.0040 lr: 0.005
2019-03-26 03:30:31 iteration: 7855 loss: 0.0058 lr: 0.005
2019-03-26 03:30:46 iteration: 7860 loss: 0.0067 lr: 0.005
2019-03-26 03:31:23 iteration: 7865 loss: 0.0073 lr: 0.005
2019-03-26 03:32:01 iteration: 7870 loss: 0.0030 lr: 0.005
2019-03-26 03:32:14 iteration: 7875 loss: 0.0048 lr: 0.005
2019-03-26 03:32:35 iteration: 7880 loss: 0.0050 lr: 0.005
2019-03-26 03:33:18 iteration: 7885 loss: 0.0060 lr: 0.005
2019-03-26 03:34:29 iteration: 7890 loss: 0.0037 lr: 0.005
2019-03-26 03:35:19 iteration: 7895 loss: 0.0054 lr: 0.005
2019-03-26 03:36:04 iteration: 7900 loss: 0.0056 lr: 0.005
2019-03-26 03:36:28 iteration: 7905 loss: 0.0037 lr: 0.005
2019-03-26 03:37:28 iteration: 7910 loss: 0.0035 lr: 0.005
2019-03-26 03:38:14 iteration: 7915 loss: 0.0049 lr: 0.005
2019-03-26 03:38:27 iteration: 7920 loss: 0.0046 lr: 0.005
2019-03-26 03:38:43 iteration: 7925 loss: 0.0052 lr: 0.005
2019-03-26 03:39:37 iteration: 7930 loss: 0.0049 lr: 0.005
2019-03-26 03:40:15 iteration: 7935 loss: 0.0038 lr: 0.005
2019-03-26 03:40:49 iteration: 7940 loss: 0.0053 lr: 0.005
2019-03-26 03:41:54 iteration: 7945 loss: 0.0053 lr: 0.005
2019-03-26 03:42:06 iteration: 7950 loss: 0.0059 lr: 0.005
2019-03-26 03:43:07 iteration: 7955 loss: 0.0044 lr: 0.005
2019-03-26 03:43:51 iteration: 7960 loss: 0.0052 lr: 0.005
2019-03-26 03:44:52 iteration: 7965 loss: 0.0037 lr: 0.005
2019-03-26 03:45:49 iteration: 7970 loss: 0.0046 lr: 0.005
2019-03-26 03:46:01 iteration: 7975 loss: 0.0047 lr: 0.005
2019-03-26 03:46:33 iteration: 7980 loss: 0.0050 lr: 0.005
2019-03-26 03:47:05 iteration: 7985 loss: 0.0046 lr: 0.005
2019-03-26 03:47:58 iteration: 7990 loss: 0.0045 lr: 0.005
2019-03-26 03:48:23 iteration: 7995 loss: 0.0076 lr: 0.005
2019-03-26 03:48:46 iteration: 8000 loss: 0.0056 lr: 0.005
2019-03-26 03:49:31 iteration: 8005 loss: 0.0042 lr: 0.005
2019-03-26 03:50:43 iteration: 8010 loss: 0.0052 lr: 0.005
2019-03-26 03:51:10 iteration: 8015 loss: 0.0049 lr: 0.005
2019-03-26 03:52:01 iteration: 8020 loss: 0.0052 lr: 0.005
2019-03-26 03:52:31 iteration: 8025 loss: 0.0074 lr: 0.005
2019-03-26 03:52:56 iteration: 8030 loss: 0.0048 lr: 0.005
2019-03-26 03:53:43 iteration: 8035 loss: 0.0048 lr: 0.005
2019-03-26 03:54:21 iteration: 8040 loss: 0.0042 lr: 0.005
2019-03-26 03:54:44 iteration: 8045 loss: 0.0046 lr: 0.005
2019-03-26 03:54:58 iteration: 8050 loss: 0.0033 lr: 0.005
2019-03-26 03:55:58 iteration: 8055 loss: 0.0056 lr: 0.005
2019-03-26 03:56:21 iteration: 8060 loss: 0.0038 lr: 0.005
2019-03-26 03:56:41 iteration: 8065 loss: 0.0043 lr: 0.005
2019-03-26 03:57:36 iteration: 8070 loss: 0.0041 lr: 0.005
2019-03-26 03:57:51 iteration: 8075 loss: 0.0055 lr: 0.005
2019-03-26 03:59:16 iteration: 8080 loss: 0.0048 lr: 0.005
2019-03-26 04:00:24 iteration: 8085 loss: 0.0042 lr: 0.005
2019-03-26 04:00:43 iteration: 8090 loss: 0.0045 lr: 0.005
2019-03-26 04:00:59 iteration: 8095 loss: 0.0052 lr: 0.005
2019-03-26 04:01:52 iteration: 8100 loss: 0.0047 lr: 0.005
2019-03-26 04:02:53 iteration: 8105 loss: 0.0045 lr: 0.005
2019-03-26 04:03:11 iteration: 8110 loss: 0.0062 lr: 0.005
2019-03-26 04:03:57 iteration: 8115 loss: 0.0051 lr: 0.005
2019-03-26 04:04:51 iteration: 8120 loss: 0.0048 lr: 0.005
2019-03-26 04:05:06 iteration: 8125 loss: 0.0065 lr: 0.005
2019-03-26 04:06:08 iteration: 8130 loss: 0.0054 lr: 0.005
2019-03-26 04:06:56 iteration: 8135 loss: 0.0039 lr: 0.005
2019-03-26 04:07:31 iteration: 8140 loss: 0.0061 lr: 0.005
2019-03-26 04:07:56 iteration: 8145 loss: 0.0056 lr: 0.005
2019-03-26 04:08:43 iteration: 8150 loss: 0.0044 lr: 0.005
2019-03-26 04:09:12 iteration: 8155 loss: 0.0045 lr: 0.005
2019-03-26 04:10:16 iteration: 8160 loss: 0.0045 lr: 0.005
2019-03-26 04:11:06 iteration: 8165 loss: 0.0044 lr: 0.005
2019-03-26 04:11:37 iteration: 8170 loss: 0.0045 lr: 0.005
2019-03-26 04:12:00 iteration: 8175 loss: 0.0056 lr: 0.005
2019-03-26 04:12:46 iteration: 8180 loss: 0.0052 lr: 0.005
2019-03-26 04:13:07 iteration: 8185 loss: 0.0059 lr: 0.005
2019-03-26 04:13:39 iteration: 8190 loss: 0.0047 lr: 0.005
2019-03-26 04:14:00 iteration: 8195 loss: 0.0061 lr: 0.005
2019-03-26 04:14:14 iteration: 8200 loss: 0.0057 lr: 0.005
2019-03-26 04:14:38 iteration: 8205 loss: 0.0074 lr: 0.005
2019-03-26 04:15:01 iteration: 8210 loss: 0.0049 lr: 0.005
2019-03-26 04:15:54 iteration: 8215 loss: 0.0044 lr: 0.005
2019-03-26 04:16:20 iteration: 8220 loss: 0.0041 lr: 0.005
2019-03-26 04:16:50 iteration: 8225 loss: 0.0046 lr: 0.005
2019-03-26 04:17:27 iteration: 8230 loss: 0.0047 lr: 0.005
2019-03-26 04:18:02 iteration: 8235 loss: 0.0040 lr: 0.005
2019-03-26 04:19:49 iteration: 8240 loss: 0.0027 lr: 0.005
2019-03-26 04:20:08 iteration: 8245 loss: 0.0070 lr: 0.005
2019-03-26 04:20:43 iteration: 8250 loss: 0.0046 lr: 0.005
2019-03-26 04:21:41 iteration: 8255 loss: 0.0050 lr: 0.005
2019-03-26 04:22:02 iteration: 8260 loss: 0.0051 lr: 0.005
2019-03-26 04:22:34 iteration: 8265 loss: 0.0071 lr: 0.005
2019-03-26 04:22:49 iteration: 8270 loss: 0.0059 lr: 0.005
2019-03-26 04:23:03 iteration: 8275 loss: 0.0054 lr: 0.005
2019-03-26 04:23:20 iteration: 8280 loss: 0.0042 lr: 0.005
2019-03-26 04:23:42 iteration: 8285 loss: 0.0047 lr: 0.005
2019-03-26 04:24:01 iteration: 8290 loss: 0.0049 lr: 0.005
2019-03-26 04:24:13 iteration: 8295 loss: 0.0049 lr: 0.005
2019-03-26 04:24:28 iteration: 8300 loss: 0.0054 lr: 0.005
2019-03-26 04:25:49 iteration: 8305 loss: 0.0049 lr: 0.005
2019-03-26 04:26:50 iteration: 8310 loss: 0.0044 lr: 0.005
2019-03-26 04:27:07 iteration: 8315 loss: 0.0062 lr: 0.005
2019-03-26 04:27:25 iteration: 8320 loss: 0.0059 lr: 0.005
2019-03-26 04:27:41 iteration: 8325 loss: 0.0056 lr: 0.005
2019-03-26 04:28:23 iteration: 8330 loss: 0.0036 lr: 0.005
2019-03-26 04:28:53 iteration: 8335 loss: 0.0063 lr: 0.005
2019-03-26 04:29:01 iteration: 8340 loss: 0.0060 lr: 0.005
2019-03-26 04:30:05 iteration: 8345 loss: 0.0043 lr: 0.005
2019-03-26 04:30:43 iteration: 8350 loss: 0.0039 lr: 0.005
2019-03-26 04:30:56 iteration: 8355 loss: 0.0057 lr: 0.005
2019-03-26 04:31:42 iteration: 8360 loss: 0.0048 lr: 0.005
2019-03-26 04:32:23 iteration: 8365 loss: 0.0036 lr: 0.005
2019-03-26 04:32:56 iteration: 8370 loss: 0.0048 lr: 0.005
2019-03-26 04:33:44 iteration: 8375 loss: 0.0052 lr: 0.005
2019-03-26 04:34:26 iteration: 8380 loss: 0.0051 lr: 0.005
2019-03-26 04:35:06 iteration: 8385 loss: 0.0038 lr: 0.005
2019-03-26 04:35:32 iteration: 8390 loss: 0.0050 lr: 0.005
2019-03-26 04:36:31 iteration: 8395 loss: 0.0044 lr: 0.005
2019-03-26 04:37:39 iteration: 8400 loss: 0.0041 lr: 0.005
2019-03-26 04:38:46 iteration: 8405 loss: 0.0035 lr: 0.005
2019-03-26 04:39:04 iteration: 8410 loss: 0.0047 lr: 0.005
2019-03-26 04:39:29 iteration: 8415 loss: 0.0044 lr: 0.005
2019-03-26 04:40:03 iteration: 8420 loss: 0.0046 lr: 0.005
2019-03-26 04:40:31 iteration: 8425 loss: 0.0038 lr: 0.005
2019-03-26 04:41:23 iteration: 8430 loss: 0.0039 lr: 0.005
2019-03-26 04:41:58 iteration: 8435 loss: 0.0040 lr: 0.005
2019-03-26 04:42:40 iteration: 8440 loss: 0.0042 lr: 0.005
2019-03-26 04:42:59 iteration: 8445 loss: 0.0037 lr: 0.005
2019-03-26 04:44:31 iteration: 8450 loss: 0.0035 lr: 0.005
2019-03-26 04:44:59 iteration: 8455 loss: 0.0046 lr: 0.005
2019-03-26 04:45:18 iteration: 8460 loss: 0.0045 lr: 0.005
2019-03-26 04:45:54 iteration: 8465 loss: 0.0039 lr: 0.005
2019-03-26 04:46:16 iteration: 8470 loss: 0.0059 lr: 0.005
2019-03-26 04:46:41 iteration: 8475 loss: 0.0047 lr: 0.005
2019-03-26 04:47:22 iteration: 8480 loss: 0.0051 lr: 0.005
2019-03-26 04:48:19 iteration: 8485 loss: 0.0046 lr: 0.005
2019-03-26 04:48:37 iteration: 8490 loss: 0.0050 lr: 0.005
2019-03-26 04:48:49 iteration: 8495 loss: 0.0050 lr: 0.005
2019-03-26 04:49:19 iteration: 8500 loss: 0.0075 lr: 0.005
2019-03-26 04:50:04 iteration: 8505 loss: 0.0055 lr: 0.005
2019-03-26 04:50:53 iteration: 8510 loss: 0.0054 lr: 0.005
2019-03-26 04:51:17 iteration: 8515 loss: 0.0063 lr: 0.005
2019-03-26 04:51:49 iteration: 8520 loss: 0.0051 lr: 0.005
2019-03-26 04:52:21 iteration: 8525 loss: 0.0048 lr: 0.005
2019-03-26 04:53:19 iteration: 8530 loss: 0.0035 lr: 0.005
2019-03-26 04:53:41 iteration: 8535 loss: 0.0050 lr: 0.005
2019-03-26 04:54:31 iteration: 8540 loss: 0.0049 lr: 0.005
2019-03-26 04:55:18 iteration: 8545 loss: 0.0085 lr: 0.005
2019-03-26 04:55:44 iteration: 8550 loss: 0.0040 lr: 0.005
2019-03-26 04:55:57 iteration: 8555 loss: 0.0055 lr: 0.005
2019-03-26 04:56:27 iteration: 8560 loss: 0.0038 lr: 0.005
2019-03-26 04:56:38 iteration: 8565 loss: 0.0056 lr: 0.005
2019-03-26 04:57:38 iteration: 8570 loss: 0.0043 lr: 0.005
2019-03-26 04:58:17 iteration: 8575 loss: 0.0039 lr: 0.005
2019-03-26 04:58:44 iteration: 8580 loss: 0.0040 lr: 0.005
2019-03-26 04:59:30 iteration: 8585 loss: 0.0057 lr: 0.005
2019-03-26 05:00:06 iteration: 8590 loss: 0.0058 lr: 0.005
2019-03-26 05:00:54 iteration: 8595 loss: 0.0106 lr: 0.005
2019-03-26 05:01:44 iteration: 8600 loss: 0.0041 lr: 0.005
2019-03-26 05:02:10 iteration: 8605 loss: 0.0028 lr: 0.005
2019-03-26 05:02:28 iteration: 8610 loss: 0.0041 lr: 0.005
2019-03-26 05:02:45 iteration: 8615 loss: 0.0053 lr: 0.005
2019-03-26 05:02:55 iteration: 8620 loss: 0.0068 lr: 0.005
2019-03-26 05:03:21 iteration: 8625 loss: 0.0043 lr: 0.005
2019-03-26 05:04:09 iteration: 8630 loss: 0.0043 lr: 0.005
2019-03-26 05:04:55 iteration: 8635 loss: 0.0042 lr: 0.005
2019-03-26 05:06:04 iteration: 8640 loss: 0.0049 lr: 0.005
2019-03-26 05:06:56 iteration: 8645 loss: 0.0033 lr: 0.005
2019-03-26 05:07:19 iteration: 8650 loss: 0.0042 lr: 0.005
2019-03-26 05:08:18 iteration: 8655 loss: 0.0040 lr: 0.005
2019-03-26 05:09:02 iteration: 8660 loss: 0.0040 lr: 0.005
2019-03-26 05:09:55 iteration: 8665 loss: 0.0038 lr: 0.005
2019-03-26 05:11:01 iteration: 8670 loss: 0.0044 lr: 0.005
2019-03-26 05:11:18 iteration: 8675 loss: 0.0072 lr: 0.005
2019-03-26 05:11:58 iteration: 8680 loss: 0.0042 lr: 0.005
2019-03-26 05:13:03 iteration: 8685 loss: 0.0043 lr: 0.005
2019-03-26 05:13:48 iteration: 8690 loss: 0.0048 lr: 0.005
2019-03-26 05:14:36 iteration: 8695 loss: 0.0048 lr: 0.005
2019-03-26 05:15:04 iteration: 8700 loss: 0.0033 lr: 0.005
2019-03-26 05:15:28 iteration: 8705 loss: 0.0054 lr: 0.005
2019-03-26 05:15:51 iteration: 8710 loss: 0.0050 lr: 0.005
2019-03-26 05:16:12 iteration: 8715 loss: 0.0079 lr: 0.005
2019-03-26 05:16:43 iteration: 8720 loss: 0.0066 lr: 0.005
2019-03-26 05:17:31 iteration: 8725 loss: 0.0041 lr: 0.005
2019-03-26 05:17:54 iteration: 8730 loss: 0.0044 lr: 0.005
2019-03-26 05:18:20 iteration: 8735 loss: 0.0057 lr: 0.005
2019-03-26 05:19:30 iteration: 8740 loss: 0.0038 lr: 0.005
2019-03-26 05:20:07 iteration: 8745 loss: 0.0043 lr: 0.005
2019-03-26 05:20:20 iteration: 8750 loss: 0.0061 lr: 0.005
2019-03-26 05:20:59 iteration: 8755 loss: 0.0077 lr: 0.005
2019-03-26 05:21:38 iteration: 8760 loss: 0.0036 lr: 0.005
2019-03-26 05:21:48 iteration: 8765 loss: 0.0049 lr: 0.005
2019-03-26 05:23:09 iteration: 8770 loss: 0.0047 lr: 0.005
2019-03-26 05:23:51 iteration: 8775 loss: 0.0045 lr: 0.005
2019-03-26 05:24:53 iteration: 8780 loss: 0.0036 lr: 0.005
2019-03-26 05:25:25 iteration: 8785 loss: 0.0049 lr: 0.005
2019-03-26 05:25:40 iteration: 8790 loss: 0.0045 lr: 0.005
2019-03-26 05:25:56 iteration: 8795 loss: 0.0036 lr: 0.005
2019-03-26 05:26:42 iteration: 8800 loss: 0.0057 lr: 0.005
2019-03-26 05:27:32 iteration: 8805 loss: 0.0038 lr: 0.005
2019-03-26 05:28:04 iteration: 8810 loss: 0.0044 lr: 0.005
2019-03-26 05:28:30 iteration: 8815 loss: 0.0050 lr: 0.005
2019-03-26 05:29:20 iteration: 8820 loss: 0.0037 lr: 0.005
2019-03-26 05:30:28 iteration: 8825 loss: 0.0055 lr: 0.005
2019-03-26 05:30:48 iteration: 8830 loss: 0.0060 lr: 0.005
2019-03-26 05:31:38 iteration: 8835 loss: 0.0045 lr: 0.005
2019-03-26 05:32:06 iteration: 8840 loss: 0.0046 lr: 0.005
2019-03-26 05:32:23 iteration: 8845 loss: 0.0051 lr: 0.005
2019-03-26 05:32:41 iteration: 8850 loss: 0.0060 lr: 0.005
2019-03-26 05:33:17 iteration: 8855 loss: 0.0053 lr: 0.005
2019-03-26 05:34:18 iteration: 8860 loss: 0.0062 lr: 0.005
2019-03-26 05:34:52 iteration: 8865 loss: 0.0034 lr: 0.005
2019-03-26 05:35:22 iteration: 8870 loss: 0.0049 lr: 0.005
2019-03-26 05:35:53 iteration: 8875 loss: 0.0044 lr: 0.005
2019-03-26 05:36:15 iteration: 8880 loss: 0.0037 lr: 0.005
2019-03-26 05:36:33 iteration: 8885 loss: 0.0055 lr: 0.005
2019-03-26 05:37:28 iteration: 8890 loss: 0.0037 lr: 0.005
2019-03-26 05:37:42 iteration: 8895 loss: 0.0056 lr: 0.005
2019-03-26 05:38:37 iteration: 8900 loss: 0.0038 lr: 0.005
2019-03-26 05:38:47 iteration: 8905 loss: 0.0050 lr: 0.005
2019-03-26 05:39:21 iteration: 8910 loss: 0.0051 lr: 0.005
2019-03-26 05:39:44 iteration: 8915 loss: 0.0046 lr: 0.005
2019-03-26 05:40:03 iteration: 8920 loss: 0.0058 lr: 0.005
2019-03-26 05:40:30 iteration: 8925 loss: 0.0052 lr: 0.005
2019-03-26 05:41:24 iteration: 8930 loss: 0.0046 lr: 0.005
2019-03-26 05:42:16 iteration: 8935 loss: 0.0047 lr: 0.005
2019-03-26 05:43:23 iteration: 8940 loss: 0.0048 lr: 0.005
2019-03-26 05:44:23 iteration: 8945 loss: 0.0044 lr: 0.005
2019-03-26 05:45:08 iteration: 8950 loss: 0.0044 lr: 0.005
2019-03-26 05:45:48 iteration: 8955 loss: 0.0045 lr: 0.005
2019-03-26 05:46:36 iteration: 8960 loss: 0.0041 lr: 0.005
2019-03-26 05:47:38 iteration: 8965 loss: 0.0045 lr: 0.005
2019-03-26 05:48:09 iteration: 8970 loss: 0.0045 lr: 0.005
2019-03-26 05:48:26 iteration: 8975 loss: 0.0046 lr: 0.005
2019-03-26 05:49:02 iteration: 8980 loss: 0.0046 lr: 0.005
2019-03-26 05:49:42 iteration: 8985 loss: 0.0046 lr: 0.005
2019-03-26 05:50:23 iteration: 8990 loss: 0.0055 lr: 0.005
2019-03-26 05:50:44 iteration: 8995 loss: 0.0113 lr: 0.005
2019-03-26 05:51:42 iteration: 9000 loss: 0.0047 lr: 0.005
2019-03-26 05:52:48 iteration: 9005 loss: 0.0054 lr: 0.005
2019-03-26 05:53:15 iteration: 9010 loss: 0.0037 lr: 0.005
2019-03-26 05:53:55 iteration: 9015 loss: 0.0047 lr: 0.005
2019-03-26 05:54:41 iteration: 9020 loss: 0.0041 lr: 0.005
2019-03-26 05:54:59 iteration: 9025 loss: 0.0055 lr: 0.005
2019-03-26 05:55:12 iteration: 9030 loss: 0.0045 lr: 0.005
2019-03-26 05:55:53 iteration: 9035 loss: 0.0046 lr: 0.005
2019-03-26 05:56:07 iteration: 9040 loss: 0.0057 lr: 0.005
2019-03-26 05:56:25 iteration: 9045 loss: 0.0060 lr: 0.005
2019-03-26 05:57:07 iteration: 9050 loss: 0.0041 lr: 0.005
2019-03-26 05:58:08 iteration: 9055 loss: 0.0050 lr: 0.005
2019-03-26 05:59:20 iteration: 9060 loss: 0.0033 lr: 0.005
2019-03-26 05:59:37 iteration: 9065 loss: 0.0086 lr: 0.005
2019-03-26 05:59:54 iteration: 9070 loss: 0.0044 lr: 0.005
2019-03-26 06:00:46 iteration: 9075 loss: 0.0047 lr: 0.005
2019-03-26 06:01:02 iteration: 9080 loss: 0.0047 lr: 0.005
2019-03-26 06:01:14 iteration: 9085 loss: 0.0051 lr: 0.005
2019-03-26 06:02:04 iteration: 9090 loss: 0.0040 lr: 0.005
2019-03-26 06:02:59 iteration: 9095 loss: 0.0035 lr: 0.005
2019-03-26 06:03:16 iteration: 9100 loss: 0.0050 lr: 0.005
2019-03-26 06:04:00 iteration: 9105 loss: 0.0071 lr: 0.005
2019-03-26 06:04:14 iteration: 9110 loss: 0.0043 lr: 0.005
2019-03-26 06:05:03 iteration: 9115 loss: 0.0037 lr: 0.005
2019-03-26 06:06:01 iteration: 9120 loss: 0.0058 lr: 0.005
2019-03-26 06:06:21 iteration: 9125 loss: 0.0052 lr: 0.005
2019-03-26 06:06:40 iteration: 9130 loss: 0.0048 lr: 0.005
2019-03-26 06:07:47 iteration: 9135 loss: 0.0043 lr: 0.005
2019-03-26 06:08:45 iteration: 9140 loss: 0.0035 lr: 0.005
2019-03-26 06:09:12 iteration: 9145 loss: 0.0044 lr: 0.005
2019-03-26 06:10:13 iteration: 9150 loss: 0.0039 lr: 0.005
2019-03-26 06:10:43 iteration: 9155 loss: 0.0048 lr: 0.005
2019-03-26 06:11:15 iteration: 9160 loss: 0.0056 lr: 0.005
2019-03-26 06:12:01 iteration: 9165 loss: 0.0065 lr: 0.005
2019-03-26 06:13:04 iteration: 9170 loss: 0.0027 lr: 0.005
2019-03-26 06:14:15 iteration: 9175 loss: 0.0050 lr: 0.005
2019-03-26 06:14:40 iteration: 9180 loss: 0.0090 lr: 0.005
2019-03-26 06:15:52 iteration: 9185 loss: 0.0033 lr: 0.005
2019-03-26 06:16:55 iteration: 9190 loss: 0.0049 lr: 0.005
2019-03-26 06:18:02 iteration: 9195 loss: 0.0034 lr: 0.005
2019-03-26 06:18:49 iteration: 9200 loss: 0.0042 lr: 0.005
2019-03-26 06:19:16 iteration: 9205 loss: 0.0051 lr: 0.005
2019-03-26 06:19:48 iteration: 9210 loss: 0.0041 lr: 0.005
2019-03-26 06:20:13 iteration: 9215 loss: 0.0055 lr: 0.005
2019-03-26 06:20:49 iteration: 9220 loss: 0.0049 lr: 0.005
2019-03-26 06:22:02 iteration: 9225 loss: 0.0032 lr: 0.005
2019-03-26 06:22:21 iteration: 9230 loss: 0.0037 lr: 0.005
2019-03-26 06:22:51 iteration: 9235 loss: 0.0038 lr: 0.005
2019-03-26 06:23:18 iteration: 9240 loss: 0.0044 lr: 0.005
2019-03-26 06:24:33 iteration: 9245 loss: 0.0037 lr: 0.005
2019-03-26 06:25:26 iteration: 9250 loss: 0.0056 lr: 0.005
2019-03-26 06:25:50 iteration: 9255 loss: 0.0054 lr: 0.005
2019-03-26 06:26:41 iteration: 9260 loss: 0.0038 lr: 0.005
2019-03-26 06:27:25 iteration: 9265 loss: 0.0053 lr: 0.005
2019-03-26 06:28:20 iteration: 9270 loss: 0.0040 lr: 0.005
2019-03-26 06:28:44 iteration: 9275 loss: 0.0043 lr: 0.005
2019-03-26 06:29:55 iteration: 9280 loss: 0.0044 lr: 0.005
2019-03-26 06:30:55 iteration: 9285 loss: 0.0033 lr: 0.005
2019-03-26 06:31:43 iteration: 9290 loss: 0.0051 lr: 0.005
2019-03-26 06:32:06 iteration: 9295 loss: 0.0042 lr: 0.005
2019-03-26 06:32:48 iteration: 9300 loss: 0.0044 lr: 0.005
2019-03-26 06:33:33 iteration: 9305 loss: 0.0045 lr: 0.005
2019-03-26 06:34:00 iteration: 9310 loss: 0.0063 lr: 0.005
2019-03-26 06:34:24 iteration: 9315 loss: 0.0043 lr: 0.005
2019-03-26 06:35:08 iteration: 9320 loss: 0.0074 lr: 0.005
2019-03-26 06:35:32 iteration: 9325 loss: 0.0069 lr: 0.005
2019-03-26 06:36:46 iteration: 9330 loss: 0.0039 lr: 0.005
2019-03-26 06:37:03 iteration: 9335 loss: 0.0042 lr: 0.005
2019-03-26 06:37:43 iteration: 9340 loss: 0.0045 lr: 0.005
2019-03-26 06:38:02 iteration: 9345 loss: 0.0038 lr: 0.005
2019-03-26 06:38:16 iteration: 9350 loss: 0.0047 lr: 0.005
2019-03-26 06:38:30 iteration: 9355 loss: 0.0065 lr: 0.005
2019-03-26 06:38:56 iteration: 9360 loss: 0.0043 lr: 0.005
2019-03-26 06:39:19 iteration: 9365 loss: 0.0047 lr: 0.005
2019-03-26 06:40:41 iteration: 9370 loss: 0.0035 lr: 0.005
2019-03-26 06:41:47 iteration: 9375 loss: 0.0029 lr: 0.005
2019-03-26 06:42:46 iteration: 9380 loss: 0.0050 lr: 0.005
2019-03-26 06:43:09 iteration: 9385 loss: 0.0041 lr: 0.005
2019-03-26 06:43:43 iteration: 9390 loss: 0.0056 lr: 0.005
2019-03-26 06:43:58 iteration: 9395 loss: 0.0067 lr: 0.005
2019-03-26 06:44:29 iteration: 9400 loss: 0.0031 lr: 0.005
2019-03-26 06:44:46 iteration: 9405 loss: 0.0062 lr: 0.005
2019-03-26 06:45:09 iteration: 9410 loss: 0.0047 lr: 0.005
2019-03-26 06:45:52 iteration: 9415 loss: 0.0045 lr: 0.005
2019-03-26 06:46:45 iteration: 9420 loss: 0.0034 lr: 0.005
2019-03-26 06:47:07 iteration: 9425 loss: 0.0042 lr: 0.005
2019-03-26 06:47:24 iteration: 9430 loss: 0.0048 lr: 0.005
2019-03-26 06:48:25 iteration: 9435 loss: 0.0050 lr: 0.005
2019-03-26 06:48:58 iteration: 9440 loss: 0.0050 lr: 0.005
2019-03-26 06:49:11 iteration: 9445 loss: 0.0048 lr: 0.005
2019-03-26 06:49:29 iteration: 9450 loss: 0.0059 lr: 0.005
2019-03-26 06:50:02 iteration: 9455 loss: 0.0022 lr: 0.005
2019-03-26 06:50:41 iteration: 9460 loss: 0.0041 lr: 0.005
2019-03-26 06:51:33 iteration: 9465 loss: 0.0033 lr: 0.005
2019-03-26 06:52:40 iteration: 9470 loss: 0.0052 lr: 0.005
2019-03-26 06:54:07 iteration: 9475 loss: 0.0036 lr: 0.005
2019-03-26 06:55:08 iteration: 9480 loss: 0.0037 lr: 0.005
2019-03-26 06:56:11 iteration: 9485 loss: 0.0053 lr: 0.005
2019-03-26 06:56:36 iteration: 9490 loss: 0.0037 lr: 0.005
2019-03-26 06:56:45 iteration: 9495 loss: 0.0054 lr: 0.005
2019-03-26 06:57:14 iteration: 9500 loss: 0.0054 lr: 0.005
2019-03-26 06:57:25 iteration: 9505 loss: 0.0067 lr: 0.005
2019-03-26 06:58:11 iteration: 9510 loss: 0.0057 lr: 0.005
2019-03-26 06:58:32 iteration: 9515 loss: 0.0055 lr: 0.005
2019-03-26 06:58:53 iteration: 9520 loss: 0.0049 lr: 0.005
2019-03-26 06:59:14 iteration: 9525 loss: 0.0036 lr: 0.005
2019-03-26 06:59:38 iteration: 9530 loss: 0.0067 lr: 0.005
2019-03-26 07:00:20 iteration: 9535 loss: 0.0030 lr: 0.005
2019-03-26 07:01:16 iteration: 9540 loss: 0.0052 lr: 0.005
2019-03-26 07:01:33 iteration: 9545 loss: 0.0040 lr: 0.005
2019-03-26 07:02:05 iteration: 9550 loss: 0.0070 lr: 0.005
2019-03-26 07:02:29 iteration: 9555 loss: 0.0050 lr: 0.005
2019-03-26 07:02:45 iteration: 9560 loss: 0.0058 lr: 0.005
2019-03-26 07:03:37 iteration: 9565 loss: 0.0036 lr: 0.005
2019-03-26 07:04:26 iteration: 9570 loss: 0.0053 lr: 0.005
2019-03-26 07:04:40 iteration: 9575 loss: 0.0052 lr: 0.005
2019-03-26 07:04:58 iteration: 9580 loss: 0.0072 lr: 0.005
2019-03-26 07:06:00 iteration: 9585 loss: 0.0032 lr: 0.005
2019-03-26 07:06:42 iteration: 9590 loss: 0.0064 lr: 0.005
2019-03-26 07:08:15 iteration: 9595 loss: 0.0042 lr: 0.005
2019-03-26 07:08:35 iteration: 9600 loss: 0.0069 lr: 0.005
2019-03-26 07:09:52 iteration: 9605 loss: 0.0045 lr: 0.005
2019-03-26 07:10:11 iteration: 9610 loss: 0.0053 lr: 0.005
2019-03-26 07:10:38 iteration: 9615 loss: 0.0049 lr: 0.005
2019-03-26 07:11:42 iteration: 9620 loss: 0.0045 lr: 0.005
2019-03-26 07:12:32 iteration: 9625 loss: 0.0041 lr: 0.005
2019-03-26 07:12:45 iteration: 9630 loss: 0.0073 lr: 0.005
2019-03-26 07:13:00 iteration: 9635 loss: 0.0056 lr: 0.005
2019-03-26 07:13:31 iteration: 9640 loss: 0.0035 lr: 0.005
2019-03-26 07:13:45 iteration: 9645 loss: 0.0045 lr: 0.005
2019-03-26 07:14:31 iteration: 9650 loss: 0.0044 lr: 0.005
2019-03-26 07:15:17 iteration: 9655 loss: 0.0050 lr: 0.005
2019-03-26 07:15:31 iteration: 9660 loss: 0.0053 lr: 0.005
2019-03-26 07:16:10 iteration: 9665 loss: 0.0041 lr: 0.005
2019-03-26 07:16:23 iteration: 9670 loss: 0.0062 lr: 0.005
2019-03-26 07:16:47 iteration: 9675 loss: 0.0054 lr: 0.005
2019-03-26 07:17:35 iteration: 9680 loss: 0.0049 lr: 0.005
2019-03-26 07:18:19 iteration: 9685 loss: 0.0040 lr: 0.005
2019-03-26 07:19:02 iteration: 9690 loss: 0.0039 lr: 0.005
2019-03-26 07:19:20 iteration: 9695 loss: 0.0044 lr: 0.005
2019-03-26 07:20:08 iteration: 9700 loss: 0.0032 lr: 0.005
2019-03-26 07:20:38 iteration: 9705 loss: 0.0046 lr: 0.005
2019-03-26 07:20:51 iteration: 9710 loss: 0.0057 lr: 0.005
2019-03-26 07:21:05 iteration: 9715 loss: 0.0054 lr: 0.005
2019-03-26 07:21:45 iteration: 9720 loss: 0.0060 lr: 0.005
2019-03-26 07:22:01 iteration: 9725 loss: 0.0077 lr: 0.005
2019-03-26 07:22:46 iteration: 9730 loss: 0.0032 lr: 0.005
2019-03-26 07:23:10 iteration: 9735 loss: 0.0037 lr: 0.005
2019-03-26 07:23:41 iteration: 9740 loss: 0.0047 lr: 0.005
2019-03-26 07:24:19 iteration: 9745 loss: 0.0041 lr: 0.005
2019-03-26 07:24:33 iteration: 9750 loss: 0.0047 lr: 0.005
2019-03-26 07:24:51 iteration: 9755 loss: 0.0042 lr: 0.005
2019-03-26 07:25:38 iteration: 9760 loss: 0.0043 lr: 0.005
2019-03-26 07:25:55 iteration: 9765 loss: 0.0039 lr: 0.005
2019-03-26 07:26:46 iteration: 9770 loss: 0.0045 lr: 0.005
2019-03-26 07:27:23 iteration: 9775 loss: 0.0039 lr: 0.005
2019-03-26 07:28:00 iteration: 9780 loss: 0.0040 lr: 0.005
2019-03-26 07:28:51 iteration: 9785 loss: 0.0035 lr: 0.005
2019-03-26 07:29:03 iteration: 9790 loss: 0.0050 lr: 0.005
2019-03-26 07:29:52 iteration: 9795 loss: 0.0024 lr: 0.005
2019-03-26 07:30:40 iteration: 9800 loss: 0.0039 lr: 0.005
2019-03-26 07:31:53 iteration: 9805 loss: 0.0042 lr: 0.005
2019-03-26 07:33:12 iteration: 9810 loss: 0.0047 lr: 0.005
2019-03-26 07:33:32 iteration: 9815 loss: 0.0042 lr: 0.005
2019-03-26 07:34:24 iteration: 9820 loss: 0.0053 lr: 0.005
2019-03-26 07:34:37 iteration: 9825 loss: 0.0055 lr: 0.005
2019-03-26 07:35:18 iteration: 9830 loss: 0.0041 lr: 0.005
2019-03-26 07:36:18 iteration: 9835 loss: 0.0059 lr: 0.005
2019-03-26 07:36:32 iteration: 9840 loss: 0.0046 lr: 0.005
2019-03-26 07:37:29 iteration: 9845 loss: 0.0038 lr: 0.005
2019-03-26 07:38:12 iteration: 9850 loss: 0.0046 lr: 0.005
2019-03-26 07:39:15 iteration: 9855 loss: 0.0050 lr: 0.005
2019-03-26 07:39:28 iteration: 9860 loss: 0.0054 lr: 0.005
2019-03-26 07:40:23 iteration: 9865 loss: 0.0043 lr: 0.005
2019-03-26 07:40:36 iteration: 9870 loss: 0.0045 lr: 0.005
2019-03-26 07:41:38 iteration: 9875 loss: 0.0044 lr: 0.005
2019-03-26 07:42:00 iteration: 9880 loss: 0.0054 lr: 0.005
2019-03-26 07:42:17 iteration: 9885 loss: 0.0066 lr: 0.005
2019-03-26 07:43:39 iteration: 9890 loss: 0.0033 lr: 0.005
2019-03-26 07:43:56 iteration: 9895 loss: 0.0043 lr: 0.005
2019-03-26 07:44:14 iteration: 9900 loss: 0.0061 lr: 0.005
2019-03-26 07:45:41 iteration: 9905 loss: 0.0031 lr: 0.005
2019-03-26 07:46:00 iteration: 9910 loss: 0.0077 lr: 0.005
2019-03-26 07:46:25 iteration: 9915 loss: 0.0036 lr: 0.005
2019-03-26 07:47:27 iteration: 9920 loss: 0.0031 lr: 0.005
2019-03-26 07:47:45 iteration: 9925 loss: 0.0061 lr: 0.005
2019-03-26 07:48:27 iteration: 9930 loss: 0.0081 lr: 0.005
2019-03-26 07:49:36 iteration: 9935 loss: 0.0047 lr: 0.005
2019-03-26 07:51:10 iteration: 9940 loss: 0.0027 lr: 0.005
2019-03-26 07:52:49 iteration: 9945 loss: 0.0033 lr: 0.005
2019-03-26 07:53:44 iteration: 9950 loss: 0.0038 lr: 0.005
2019-03-26 07:54:56 iteration: 9955 loss: 0.0056 lr: 0.005
2019-03-26 07:55:43 iteration: 9960 loss: 0.0047 lr: 0.005
2019-03-26 07:56:05 iteration: 9965 loss: 0.0054 lr: 0.005
2019-03-26 07:56:29 iteration: 9970 loss: 0.0045 lr: 0.005
2019-03-26 07:57:19 iteration: 9975 loss: 0.0073 lr: 0.005
2019-03-26 07:57:57 iteration: 9980 loss: 0.0039 lr: 0.005
2019-03-26 07:59:02 iteration: 9985 loss: 0.0054 lr: 0.005
2019-03-26 07:59:17 iteration: 9990 loss: 0.0045 lr: 0.005
2019-03-26 07:59:41 iteration: 9995 loss: 0.0050 lr: 0.005
2019-03-26 08:00:29 iteration: 10000 loss: 0.0040 lr: 0.005
2019-03-26 08:01:12 iteration: 10005 loss: 0.0039 lr: 0.02
2019-03-26 08:01:57 iteration: 10010 loss: 0.0048 lr: 0.02
2019-03-26 08:02:18 iteration: 10015 loss: 0.0053 lr: 0.02
2019-03-26 08:02:47 iteration: 10020 loss: 0.0062 lr: 0.02
2019-03-26 08:03:04 iteration: 10025 loss: 0.0063 lr: 0.02
2019-03-26 08:03:55 iteration: 10030 loss: 0.0058 lr: 0.02
2019-03-26 08:04:25 iteration: 10035 loss: 0.0073 lr: 0.02
2019-03-26 08:04:41 iteration: 10040 loss: 0.0079 lr: 0.02
2019-03-26 08:04:57 iteration: 10045 loss: 0.0067 lr: 0.02
2019-03-26 08:05:08 iteration: 10050 loss: 0.0055 lr: 0.02
2019-03-26 08:05:21 iteration: 10055 loss: 0.0098 lr: 0.02
2019-03-26 08:06:42 iteration: 10060 loss: 0.0055 lr: 0.02
2019-03-26 08:07:29 iteration: 10065 loss: 0.0062 lr: 0.02
2019-03-26 08:08:40 iteration: 10070 loss: 0.0051 lr: 0.02
2019-03-26 08:09:18 iteration: 10075 loss: 0.0057 lr: 0.02
2019-03-26 08:09:39 iteration: 10080 loss: 0.0055 lr: 0.02
2019-03-26 08:09:56 iteration: 10085 loss: 0.0045 lr: 0.02
2019-03-26 08:10:25 iteration: 10090 loss: 0.0057 lr: 0.02
2019-03-26 08:11:12 iteration: 10095 loss: 0.0065 lr: 0.02
2019-03-26 08:11:25 iteration: 10100 loss: 0.0107 lr: 0.02
2019-03-26 08:11:38 iteration: 10105 loss: 0.0053 lr: 0.02
2019-03-26 08:12:28 iteration: 10110 loss: 0.0057 lr: 0.02
2019-03-26 08:12:49 iteration: 10115 loss: 0.0051 lr: 0.02
2019-03-26 08:13:03 iteration: 10120 loss: 0.0084 lr: 0.02
2019-03-26 08:13:48 iteration: 10125 loss: 0.0063 lr: 0.02
2019-03-26 08:14:09 iteration: 10130 loss: 0.0078 lr: 0.02
2019-03-26 08:14:33 iteration: 10135 loss: 0.0079 lr: 0.02
2019-03-26 08:15:41 iteration: 10140 loss: 0.0052 lr: 0.02
2019-03-26 08:15:53 iteration: 10145 loss: 0.0071 lr: 0.02
2019-03-26 08:16:16 iteration: 10150 loss: 0.0068 lr: 0.02
2019-03-26 08:16:28 iteration: 10155 loss: 0.0061 lr: 0.02
2019-03-26 08:17:06 iteration: 10160 loss: 0.0069 lr: 0.02
2019-03-26 08:17:41 iteration: 10165 loss: 0.0074 lr: 0.02
2019-03-26 08:18:06 iteration: 10170 loss: 0.0059 lr: 0.02
2019-03-26 08:18:22 iteration: 10175 loss: 0.0094 lr: 0.02
2019-03-26 08:19:10 iteration: 10180 loss: 0.0063 lr: 0.02
2019-03-26 08:19:42 iteration: 10185 loss: 0.0064 lr: 0.02
2019-03-26 08:20:53 iteration: 10190 loss: 0.0041 lr: 0.02
2019-03-26 08:21:28 iteration: 10195 loss: 0.0054 lr: 0.02
2019-03-26 08:21:54 iteration: 10200 loss: 0.0055 lr: 0.02
2019-03-26 08:22:10 iteration: 10205 loss: 0.0053 lr: 0.02
2019-03-26 08:23:26 iteration: 10210 loss: 0.0058 lr: 0.02
2019-03-26 08:23:48 iteration: 10215 loss: 0.0055 lr: 0.02
2019-03-26 08:24:33 iteration: 10220 loss: 0.0045 lr: 0.02
2019-03-26 08:24:59 iteration: 10225 loss: 0.0067 lr: 0.02
2019-03-26 08:26:05 iteration: 10230 loss: 0.0053 lr: 0.02
2019-03-26 08:27:02 iteration: 10235 loss: 0.0067 lr: 0.02
2019-03-26 08:27:45 iteration: 10240 loss: 0.0041 lr: 0.02
2019-03-26 08:29:18 iteration: 10245 loss: 0.0062 lr: 0.02
2019-03-26 08:30:28 iteration: 10250 loss: 0.0060 lr: 0.02
2019-03-26 08:31:25 iteration: 10255 loss: 0.0054 lr: 0.02
2019-03-26 08:32:05 iteration: 10260 loss: 0.0041 lr: 0.02
2019-03-26 08:32:37 iteration: 10265 loss: 0.0042 lr: 0.02
2019-03-26 08:33:19 iteration: 10270 loss: 0.0049 lr: 0.02
2019-03-26 08:33:48 iteration: 10275 loss: 0.0084 lr: 0.02
2019-03-26 08:34:00 iteration: 10280 loss: 0.0069 lr: 0.02
2019-03-26 08:34:17 iteration: 10285 loss: 0.0065 lr: 0.02
2019-03-26 08:34:59 iteration: 10290 loss: 0.0056 lr: 0.02
2019-03-26 08:35:24 iteration: 10295 loss: 0.0047 lr: 0.02
2019-03-26 08:36:02 iteration: 10300 loss: 0.0055 lr: 0.02
2019-03-26 08:36:52 iteration: 10305 loss: 0.0084 lr: 0.02
2019-03-26 08:37:10 iteration: 10310 loss: 0.0051 lr: 0.02
2019-03-26 08:37:20 iteration: 10315 loss: 0.0068 lr: 0.02
2019-03-26 08:38:20 iteration: 10320 loss: 0.0047 lr: 0.02
2019-03-26 08:38:43 iteration: 10325 loss: 0.0060 lr: 0.02
2019-03-26 08:39:23 iteration: 10330 loss: 0.0119 lr: 0.02
2019-03-26 08:39:39 iteration: 10335 loss: 0.0073 lr: 0.02
2019-03-26 08:40:20 iteration: 10340 loss: 0.0080 lr: 0.02
2019-03-26 08:40:59 iteration: 10345 loss: 0.0052 lr: 0.02
2019-03-26 08:41:37 iteration: 10350 loss: 0.0064 lr: 0.02
2019-03-26 08:42:03 iteration: 10355 loss: 0.0081 lr: 0.02
2019-03-26 08:42:57 iteration: 10360 loss: 0.0063 lr: 0.02
2019-03-26 08:43:25 iteration: 10365 loss: 0.0083 lr: 0.02
2019-03-26 08:44:16 iteration: 10370 loss: 0.0061 lr: 0.02
2019-03-26 08:44:36 iteration: 10375 loss: 0.0062 lr: 0.02
2019-03-26 08:46:14 iteration: 10380 loss: 0.0053 lr: 0.02
2019-03-26 08:47:12 iteration: 10385 loss: 0.0089 lr: 0.02
2019-03-26 08:47:50 iteration: 10390 loss: 0.0045 lr: 0.02
2019-03-26 08:48:17 iteration: 10395 loss: 0.0040 lr: 0.02
2019-03-26 08:50:02 iteration: 10400 loss: 0.0063 lr: 0.02
2019-03-26 08:50:53 iteration: 10405 loss: 0.0060 lr: 0.02
2019-03-26 08:51:46 iteration: 10410 loss: 0.0058 lr: 0.02
2019-03-26 08:52:25 iteration: 10415 loss: 0.0062 lr: 0.02
2019-03-26 08:52:37 iteration: 10420 loss: 0.0067 lr: 0.02
2019-03-26 08:52:57 iteration: 10425 loss: 0.0053 lr: 0.02
2019-03-26 08:53:55 iteration: 10430 loss: 0.0048 lr: 0.02
2019-03-26 08:54:35 iteration: 10435 loss: 0.0049 lr: 0.02
2019-03-26 08:54:57 iteration: 10440 loss: 0.0045 lr: 0.02
2019-03-26 08:55:42 iteration: 10445 loss: 0.0055 lr: 0.02
2019-03-26 08:56:38 iteration: 10450 loss: 0.0051 lr: 0.02
2019-03-26 08:57:02 iteration: 10455 loss: 0.0052 lr: 0.02
2019-03-26 08:57:19 iteration: 10460 loss: 0.0060 lr: 0.02
2019-03-26 08:57:37 iteration: 10465 loss: 0.0063 lr: 0.02
2019-03-26 08:57:57 iteration: 10470 loss: 0.0066 lr: 0.02
2019-03-26 08:59:01 iteration: 10475 loss: 0.0033 lr: 0.02
2019-03-26 08:59:56 iteration: 10480 loss: 0.0062 lr: 0.02
2019-03-26 09:00:41 iteration: 10485 loss: 0.0076 lr: 0.02
2019-03-26 09:01:24 iteration: 10490 loss: 0.0058 lr: 0.02
2019-03-26 09:02:41 iteration: 10495 loss: 0.0040 lr: 0.02
2019-03-26 09:03:19 iteration: 10500 loss: 0.0053 lr: 0.02
2019-03-26 09:03:50 iteration: 10505 loss: 0.0056 lr: 0.02
2019-03-26 09:04:35 iteration: 10510 loss: 0.0052 lr: 0.02
2019-03-26 09:05:08 iteration: 10515 loss: 0.0058 lr: 0.02
2019-03-26 09:05:48 iteration: 10520 loss: 0.0050 lr: 0.02
2019-03-26 09:06:05 iteration: 10525 loss: 0.0057 lr: 0.02
2019-03-26 09:06:33 iteration: 10530 loss: 0.0049 lr: 0.02
2019-03-26 09:07:49 iteration: 10535 loss: 0.0062 lr: 0.02
2019-03-26 09:08:40 iteration: 10540 loss: 0.0058 lr: 0.02
2019-03-26 09:09:37 iteration: 10545 loss: 0.0055 lr: 0.02
2019-03-26 09:10:00 iteration: 10550 loss: 0.0076 lr: 0.02
2019-03-26 09:10:17 iteration: 10555 loss: 0.0111 lr: 0.02
2019-03-26 09:11:10 iteration: 10560 loss: 0.0061 lr: 0.02
2019-03-26 09:11:41 iteration: 10565 loss: 0.0062 lr: 0.02
2019-03-26 09:12:58 iteration: 10570 loss: 0.0043 lr: 0.02
2019-03-26 09:13:53 iteration: 10575 loss: 0.0057 lr: 0.02
2019-03-26 09:14:31 iteration: 10580 loss: 0.0051 lr: 0.02
2019-03-26 09:14:51 iteration: 10585 loss: 0.0064 lr: 0.02
2019-03-26 09:15:39 iteration: 10590 loss: 0.0064 lr: 0.02
2019-03-26 09:16:56 iteration: 10595 loss: 0.0067 lr: 0.02
2019-03-26 09:18:21 iteration: 10600 loss: 0.0108 lr: 0.02
2019-03-26 09:18:36 iteration: 10605 loss: 0.0093 lr: 0.02
2019-03-26 09:19:09 iteration: 10610 loss: 0.0060 lr: 0.02
2019-03-26 09:19:48 iteration: 10615 loss: 0.0087 lr: 0.02
2019-03-26 09:20:14 iteration: 10620 loss: 0.0071 lr: 0.02
2019-03-26 09:21:36 iteration: 10625 loss: 0.0048 lr: 0.02
2019-03-26 09:22:18 iteration: 10630 loss: 0.0057 lr: 0.02
2019-03-26 09:22:35 iteration: 10635 loss: 0.0085 lr: 0.02
2019-03-26 09:22:49 iteration: 10640 loss: 0.0056 lr: 0.02
2019-03-26 09:24:12 iteration: 10645 loss: 0.0057 lr: 0.02
2019-03-26 09:24:30 iteration: 10650 loss: 0.0066 lr: 0.02
2019-03-26 09:25:24 iteration: 10655 loss: 0.0046 lr: 0.02
2019-03-26 09:25:41 iteration: 10660 loss: 0.0043 lr: 0.02
2019-03-26 09:27:04 iteration: 10665 loss: 0.0054 lr: 0.02
2019-03-26 09:27:52 iteration: 10670 loss: 0.0061 lr: 0.02
2019-03-26 09:28:36 iteration: 10675 loss: 0.0060 lr: 0.02
2019-03-26 09:29:44 iteration: 10680 loss: 0.0071 lr: 0.02
2019-03-26 09:30:17 iteration: 10685 loss: 0.0091 lr: 0.02
2019-03-26 09:30:38 iteration: 10690 loss: 0.0065 lr: 0.02
2019-03-26 09:31:14 iteration: 10695 loss: 0.0055 lr: 0.02
2019-03-26 09:32:18 iteration: 10700 loss: 0.0081 lr: 0.02
2019-03-26 09:33:04 iteration: 10705 loss: 0.0080 lr: 0.02
2019-03-26 09:34:47 iteration: 10710 loss: 0.0049 lr: 0.02
2019-03-26 09:35:02 iteration: 10715 loss: 0.0073 lr: 0.02
2019-03-26 09:36:11 iteration: 10720 loss: 0.0060 lr: 0.02
2019-03-26 09:36:59 iteration: 10725 loss: 0.0054 lr: 0.02
2019-03-26 09:37:33 iteration: 10730 loss: 0.0071 lr: 0.02
2019-03-26 09:38:35 iteration: 10735 loss: 0.0050 lr: 0.02
2019-03-26 09:38:49 iteration: 10740 loss: 0.0061 lr: 0.02
2019-03-26 09:40:04 iteration: 10745 loss: 0.0058 lr: 0.02
2019-03-26 09:40:27 iteration: 10750 loss: 0.0051 lr: 0.02
2019-03-26 09:40:53 iteration: 10755 loss: 0.0057 lr: 0.02
2019-03-26 09:41:23 iteration: 10760 loss: 0.0061 lr: 0.02
2019-03-26 09:42:07 iteration: 10765 loss: 0.0055 lr: 0.02
2019-03-26 09:42:18 iteration: 10770 loss: 0.0052 lr: 0.02
2019-03-26 09:42:56 iteration: 10775 loss: 0.0053 lr: 0.02
2019-03-26 09:43:13 iteration: 10780 loss: 0.0057 lr: 0.02
2019-03-26 09:43:56 iteration: 10785 loss: 0.0066 lr: 0.02
2019-03-26 09:44:50 iteration: 10790 loss: 0.0054 lr: 0.02
2019-03-26 09:45:08 iteration: 10795 loss: 0.0064 lr: 0.02
2019-03-26 09:46:04 iteration: 10800 loss: 0.0070 lr: 0.02
2019-03-26 09:46:42 iteration: 10805 loss: 0.0058 lr: 0.02
2019-03-26 09:47:41 iteration: 10810 loss: 0.0062 lr: 0.02
2019-03-26 09:48:20 iteration: 10815 loss: 0.0052 lr: 0.02
2019-03-26 09:48:45 iteration: 10820 loss: 0.0077 lr: 0.02
2019-03-26 09:49:14 iteration: 10825 loss: 0.0060 lr: 0.02
2019-03-26 09:50:00 iteration: 10830 loss: 0.0049 lr: 0.02
2019-03-26 09:50:30 iteration: 10835 loss: 0.0069 lr: 0.02
2019-03-26 09:50:51 iteration: 10840 loss: 0.0083 lr: 0.02
2019-03-26 09:51:21 iteration: 10845 loss: 0.0059 lr: 0.02
2019-03-26 09:52:13 iteration: 10850 loss: 0.0045 lr: 0.02
2019-03-26 09:53:15 iteration: 10855 loss: 0.0055 lr: 0.02
2019-03-26 09:54:08 iteration: 10860 loss: 0.0087 lr: 0.02
2019-03-26 09:54:33 iteration: 10865 loss: 0.0069 lr: 0.02
2019-03-26 09:56:00 iteration: 10870 loss: 0.0056 lr: 0.02
2019-03-26 09:56:22 iteration: 10875 loss: 0.0051 lr: 0.02
2019-03-26 09:56:40 iteration: 10880 loss: 0.0073 lr: 0.02
2019-03-26 09:57:36 iteration: 10885 loss: 0.0057 lr: 0.02
2019-03-26 09:58:44 iteration: 10890 loss: 0.0062 lr: 0.02
2019-03-26 09:59:28 iteration: 10895 loss: 0.0050 lr: 0.02
2019-03-26 10:00:27 iteration: 10900 loss: 0.0059 lr: 0.02
2019-03-26 10:00:48 iteration: 10905 loss: 0.0071 lr: 0.02
2019-03-26 10:01:04 iteration: 10910 loss: 0.0058 lr: 0.02
2019-03-26 10:01:32 iteration: 10915 loss: 0.0052 lr: 0.02
2019-03-26 10:02:09 iteration: 10920 loss: 0.0054 lr: 0.02
2019-03-26 10:03:01 iteration: 10925 loss: 0.0101 lr: 0.02
2019-03-26 10:04:06 iteration: 10930 loss: 0.0058 lr: 0.02
2019-03-26 10:04:32 iteration: 10935 loss: 0.0076 lr: 0.02
2019-03-26 10:05:08 iteration: 10940 loss: 0.0053 lr: 0.02
2019-03-26 10:05:58 iteration: 10945 loss: 0.0066 lr: 0.02
2019-03-26 10:07:26 iteration: 10950 loss: 0.0055 lr: 0.02
2019-03-26 10:07:57 iteration: 10955 loss: 0.0043 lr: 0.02
2019-03-26 10:08:25 iteration: 10960 loss: 0.0096 lr: 0.02
2019-03-26 10:08:48 iteration: 10965 loss: 0.0076 lr: 0.02
2019-03-26 10:09:22 iteration: 10970 loss: 0.0053 lr: 0.02
2019-03-26 10:09:50 iteration: 10975 loss: 0.0049 lr: 0.02
2019-03-26 10:10:18 iteration: 10980 loss: 0.0056 lr: 0.02
2019-03-26 10:11:41 iteration: 10985 loss: 0.0051 lr: 0.02
2019-03-26 10:12:21 iteration: 10990 loss: 0.0054 lr: 0.02
2019-03-26 10:12:46 iteration: 10995 loss: 0.0044 lr: 0.02
2019-03-26 10:13:41 iteration: 11000 loss: 0.0046 lr: 0.02
2019-03-26 10:13:55 iteration: 11005 loss: 0.0059 lr: 0.02
2019-03-26 10:14:22 iteration: 11010 loss: 0.0057 lr: 0.02
2019-03-26 10:14:52 iteration: 11015 loss: 0.0068 lr: 0.02
2019-03-26 10:15:15 iteration: 11020 loss: 0.0059 lr: 0.02
2019-03-26 10:15:58 iteration: 11025 loss: 0.0054 lr: 0.02
2019-03-26 10:17:37 iteration: 11030 loss: 0.0050 lr: 0.02
2019-03-26 10:17:55 iteration: 11035 loss: 0.0068 lr: 0.02
2019-03-26 10:18:09 iteration: 11040 loss: 0.0072 lr: 0.02
2019-03-26 10:18:50 iteration: 11045 loss: 0.0051 lr: 0.02
2019-03-26 10:19:14 iteration: 11050 loss: 0.0057 lr: 0.02
2019-03-26 10:20:18 iteration: 11055 loss: 0.0056 lr: 0.02
2019-03-26 10:20:43 iteration: 11060 loss: 0.0077 lr: 0.02
2019-03-26 10:21:20 iteration: 11065 loss: 0.0056 lr: 0.02
2019-03-26 10:21:55 iteration: 11070 loss: 0.0060 lr: 0.02
2019-03-26 10:22:22 iteration: 11075 loss: 0.0069 lr: 0.02
2019-03-26 10:22:58 iteration: 11080 loss: 0.0059 lr: 0.02
2019-03-26 10:23:33 iteration: 11085 loss: 0.0053 lr: 0.02
2019-03-26 10:23:54 iteration: 11090 loss: 0.0074 lr: 0.02
2019-03-26 10:24:21 iteration: 11095 loss: 0.0067 lr: 0.02
2019-03-26 10:24:46 iteration: 11100 loss: 0.0081 lr: 0.02
2019-03-26 10:25:47 iteration: 11105 loss: 0.0055 lr: 0.02
2019-03-26 10:26:21 iteration: 11110 loss: 0.0052 lr: 0.02
2019-03-26 10:26:59 iteration: 11115 loss: 0.0043 lr: 0.02
2019-03-26 10:27:13 iteration: 11120 loss: 0.0066 lr: 0.02
2019-03-26 10:27:33 iteration: 11125 loss: 0.0042 lr: 0.02
2019-03-26 10:28:14 iteration: 11130 loss: 0.0063 lr: 0.02
2019-03-26 10:28:33 iteration: 11135 loss: 0.0087 lr: 0.02
2019-03-26 10:28:56 iteration: 11140 loss: 0.0051 lr: 0.02
2019-03-26 10:30:26 iteration: 11145 loss: 0.0047 lr: 0.02
2019-03-26 10:31:21 iteration: 11150 loss: 0.0063 lr: 0.02
2019-03-26 10:32:16 iteration: 11155 loss: 0.0046 lr: 0.02
2019-03-26 10:32:34 iteration: 11160 loss: 0.0080 lr: 0.02
2019-03-26 10:33:38 iteration: 11165 loss: 0.0065 lr: 0.02
2019-03-26 10:33:54 iteration: 11170 loss: 0.0074 lr: 0.02
2019-03-26 10:34:31 iteration: 11175 loss: 0.0066 lr: 0.02
2019-03-26 10:34:48 iteration: 11180 loss: 0.0070 lr: 0.02
2019-03-26 10:35:03 iteration: 11185 loss: 0.0084 lr: 0.02
2019-03-26 10:35:15 iteration: 11190 loss: 0.0062 lr: 0.02
2019-03-26 10:35:54 iteration: 11195 loss: 0.0049 lr: 0.02
2019-03-26 10:36:08 iteration: 11200 loss: 0.0052 lr: 0.02
2019-03-26 10:36:50 iteration: 11205 loss: 0.0059 lr: 0.02
2019-03-26 10:37:00 iteration: 11210 loss: 0.0064 lr: 0.02
2019-03-26 10:37:15 iteration: 11215 loss: 0.0051 lr: 0.02
2019-03-26 10:37:53 iteration: 11220 loss: 0.0053 lr: 0.02
2019-03-26 10:38:31 iteration: 11225 loss: 0.0058 lr: 0.02
2019-03-26 10:39:33 iteration: 11230 loss: 0.0046 lr: 0.02
2019-03-26 10:40:07 iteration: 11235 loss: 0.0058 lr: 0.02
2019-03-26 10:40:29 iteration: 11240 loss: 0.0049 lr: 0.02
2019-03-26 10:40:39 iteration: 11245 loss: 0.0066 lr: 0.02
2019-03-26 10:40:50 iteration: 11250 loss: 0.0064 lr: 0.02
2019-03-26 10:41:25 iteration: 11255 loss: 0.0050 lr: 0.02
2019-03-26 10:41:51 iteration: 11260 loss: 0.0080 lr: 0.02
2019-03-26 10:42:13 iteration: 11265 loss: 0.0060 lr: 0.02
2019-03-26 10:42:53 iteration: 11270 loss: 0.0056 lr: 0.02
2019-03-26 10:43:10 iteration: 11275 loss: 0.0082 lr: 0.02
2019-03-26 10:43:27 iteration: 11280 loss: 0.0053 lr: 0.02
2019-03-26 10:44:19 iteration: 11285 loss: 0.0053 lr: 0.02
2019-03-26 10:45:28 iteration: 11290 loss: 0.0038 lr: 0.02
2019-03-26 10:45:37 iteration: 11295 loss: 0.0066 lr: 0.02
2019-03-26 10:46:12 iteration: 11300 loss: 0.0047 lr: 0.02
2019-03-26 10:46:40 iteration: 11305 loss: 0.0049 lr: 0.02
2019-03-26 10:47:18 iteration: 11310 loss: 0.0045 lr: 0.02
2019-03-26 10:47:56 iteration: 11315 loss: 0.0055 lr: 0.02
2019-03-26 10:49:18 iteration: 11320 loss: 0.0061 lr: 0.02
2019-03-26 10:50:01 iteration: 11325 loss: 0.0057 lr: 0.02
2019-03-26 10:50:49 iteration: 11330 loss: 0.0039 lr: 0.02
2019-03-26 10:51:05 iteration: 11335 loss: 0.0071 lr: 0.02
2019-03-26 10:52:01 iteration: 11340 loss: 0.0076 lr: 0.02
2019-03-26 10:52:27 iteration: 11345 loss: 0.0077 lr: 0.02
2019-03-26 10:53:22 iteration: 11350 loss: 0.0047 lr: 0.02
2019-03-26 10:54:25 iteration: 11355 loss: 0.0075 lr: 0.02
2019-03-26 10:54:44 iteration: 11360 loss: 0.0049 lr: 0.02
2019-03-26 10:55:30 iteration: 11365 loss: 0.0072 lr: 0.02
2019-03-26 10:57:00 iteration: 11370 loss: 0.0029 lr: 0.02
2019-03-26 10:57:15 iteration: 11375 loss: 0.0079 lr: 0.02
2019-03-26 10:58:12 iteration: 11380 loss: 0.0059 lr: 0.02
2019-03-26 10:58:47 iteration: 11385 loss: 0.0052 lr: 0.02
2019-03-26 10:59:39 iteration: 11390 loss: 0.0070 lr: 0.02
2019-03-26 11:00:58 iteration: 11395 loss: 0.0051 lr: 0.02
2019-03-26 11:02:14 iteration: 11400 loss: 0.0036 lr: 0.02
2019-03-26 11:04:03 iteration: 11405 loss: 0.0047 lr: 0.02
2019-03-26 11:04:20 iteration: 11410 loss: 0.0045 lr: 0.02
2019-03-26 11:05:14 iteration: 11415 loss: 0.0051 lr: 0.02
2019-03-26 11:06:41 iteration: 11420 loss: 0.0056 lr: 0.02
2019-03-26 11:07:50 iteration: 11425 loss: 0.0038 lr: 0.02
2019-03-26 11:08:42 iteration: 11430 loss: 0.0059 lr: 0.02
2019-03-26 11:09:23 iteration: 11435 loss: 0.0066 lr: 0.02
2019-03-26 11:10:08 iteration: 11440 loss: 0.0044 lr: 0.02
2019-03-26 11:10:23 iteration: 11445 loss: 0.0048 lr: 0.02
2019-03-26 11:11:29 iteration: 11450 loss: 0.0055 lr: 0.02
2019-03-26 11:12:07 iteration: 11455 loss: 0.0063 lr: 0.02
2019-03-26 11:12:50 iteration: 11460 loss: 0.0055 lr: 0.02
2019-03-26 11:13:52 iteration: 11465 loss: 0.0061 lr: 0.02
2019-03-26 11:14:12 iteration: 11470 loss: 0.0063 lr: 0.02
2019-03-26 11:14:42 iteration: 11475 loss: 0.0051 lr: 0.02
2019-03-26 11:16:14 iteration: 11480 loss: 0.0050 lr: 0.02
2019-03-26 11:16:34 iteration: 11485 loss: 0.0058 lr: 0.02
2019-03-26 11:17:00 iteration: 11490 loss: 0.0060 lr: 0.02
2019-03-26 11:17:41 iteration: 11495 loss: 0.0063 lr: 0.02
2019-03-26 11:18:17 iteration: 11500 loss: 0.0054 lr: 0.02
2019-03-26 11:19:05 iteration: 11505 loss: 0.0034 lr: 0.02
2019-03-26 11:19:30 iteration: 11510 loss: 0.0057 lr: 0.02
2019-03-26 11:20:25 iteration: 11515 loss: 0.0061 lr: 0.02
2019-03-26 11:20:59 iteration: 11520 loss: 0.0051 lr: 0.02
2019-03-26 11:21:42 iteration: 11525 loss: 0.0061 lr: 0.02
2019-03-26 11:22:11 iteration: 11530 loss: 0.0049 lr: 0.02
2019-03-26 11:22:49 iteration: 11535 loss: 0.0058 lr: 0.02
2019-03-26 11:24:05 iteration: 11540 loss: 0.0052 lr: 0.02
2019-03-26 11:24:46 iteration: 11545 loss: 0.0051 lr: 0.02
2019-03-26 11:25:38 iteration: 11550 loss: 0.0043 lr: 0.02
2019-03-26 11:26:00 iteration: 11555 loss: 0.0059 lr: 0.02
2019-03-26 11:26:31 iteration: 11560 loss: 0.0061 lr: 0.02
2019-03-26 11:27:01 iteration: 11565 loss: 0.0069 lr: 0.02
2019-03-26 11:28:14 iteration: 11570 loss: 0.0050 lr: 0.02
2019-03-26 11:30:12 iteration: 11575 loss: 0.0041 lr: 0.02
2019-03-26 11:30:29 iteration: 11580 loss: 0.0071 lr: 0.02
2019-03-26 11:30:47 iteration: 11585 loss: 0.0052 lr: 0.02
2019-03-26 11:31:36 iteration: 11590 loss: 0.0055 lr: 0.02
2019-03-26 11:33:11 iteration: 11595 loss: 0.0049 lr: 0.02
2019-03-26 11:34:31 iteration: 11600 loss: 0.0049 lr: 0.02
2019-03-26 11:34:49 iteration: 11605 loss: 0.0084 lr: 0.02
2019-03-26 11:35:07 iteration: 11610 loss: 0.0063 lr: 0.02
2019-03-26 11:36:02 iteration: 11615 loss: 0.0056 lr: 0.02
2019-03-26 11:36:29 iteration: 11620 loss: 0.0070 lr: 0.02
2019-03-26 11:36:42 iteration: 11625 loss: 0.0065 lr: 0.02
2019-03-26 11:37:04 iteration: 11630 loss: 0.0047 lr: 0.02
2019-03-26 11:37:30 iteration: 11635 loss: 0.0055 lr: 0.02
2019-03-26 11:37:45 iteration: 11640 loss: 0.0063 lr: 0.02
2019-03-26 11:38:01 iteration: 11645 loss: 0.0060 lr: 0.02
2019-03-26 11:38:51 iteration: 11650 loss: 0.0053 lr: 0.02
2019-03-26 11:39:36 iteration: 11655 loss: 0.0059 lr: 0.02
2019-03-26 11:40:05 iteration: 11660 loss: 0.0069 lr: 0.02
2019-03-26 11:40:50 iteration: 11665 loss: 0.0057 lr: 0.02
2019-03-26 11:41:27 iteration: 11670 loss: 0.0045 lr: 0.02
2019-03-26 11:42:13 iteration: 11675 loss: 0.0054 lr: 0.02
2019-03-26 11:42:52 iteration: 11680 loss: 0.0053 lr: 0.02
2019-03-26 11:43:32 iteration: 11685 loss: 0.0054 lr: 0.02
2019-03-26 11:44:15 iteration: 11690 loss: 0.0101 lr: 0.02
2019-03-26 11:44:44 iteration: 11695 loss: 0.0057 lr: 0.02
2019-03-26 11:45:57 iteration: 11700 loss: 0.0062 lr: 0.02
2019-03-26 11:46:12 iteration: 11705 loss: 0.0064 lr: 0.02
2019-03-26 11:46:22 iteration: 11710 loss: 0.0049 lr: 0.02
2019-03-26 11:47:08 iteration: 11715 loss: 0.0049 lr: 0.02
2019-03-26 11:48:59 iteration: 11720 loss: 0.0049 lr: 0.02
2019-03-26 11:49:30 iteration: 11725 loss: 0.0049 lr: 0.02
2019-03-26 11:49:53 iteration: 11730 loss: 0.0051 lr: 0.02
2019-03-26 11:50:09 iteration: 11735 loss: 0.0065 lr: 0.02
2019-03-26 11:50:24 iteration: 11740 loss: 0.0070 lr: 0.02
2019-03-26 11:50:37 iteration: 11745 loss: 0.0037 lr: 0.02
2019-03-26 11:50:51 iteration: 11750 loss: 0.0059 lr: 0.02
2019-03-26 11:51:57 iteration: 11755 loss: 0.0050 lr: 0.02
2019-03-26 11:53:46 iteration: 11760 loss: 0.0048 lr: 0.02
2019-03-26 11:55:03 iteration: 11765 loss: 0.0080 lr: 0.02
2019-03-26 11:55:25 iteration: 11770 loss: 0.0069 lr: 0.02
2019-03-26 11:56:24 iteration: 11775 loss: 0.0060 lr: 0.02
2019-03-26 11:57:18 iteration: 11780 loss: 0.0063 lr: 0.02
2019-03-26 11:57:36 iteration: 11785 loss: 0.0065 lr: 0.02
2019-03-26 11:58:11 iteration: 11790 loss: 0.0048 lr: 0.02
2019-03-26 11:59:07 iteration: 11795 loss: 0.0059 lr: 0.02
2019-03-26 11:59:25 iteration: 11800 loss: 0.0067 lr: 0.02
2019-03-26 12:00:00 iteration: 11805 loss: 0.0052 lr: 0.02
2019-03-26 12:00:20 iteration: 11810 loss: 0.0055 lr: 0.02
2019-03-26 12:00:37 iteration: 11815 loss: 0.0063 lr: 0.02
2019-03-26 12:01:23 iteration: 11820 loss: 0.0070 lr: 0.02
2019-03-26 12:02:02 iteration: 11825 loss: 0.0059 lr: 0.02
2019-03-26 12:02:30 iteration: 11830 loss: 0.0062 lr: 0.02
2019-03-26 12:04:09 iteration: 11835 loss: 0.0055 lr: 0.02
2019-03-26 12:05:26 iteration: 11840 loss: 0.0057 lr: 0.02
2019-03-26 12:05:54 iteration: 11845 loss: 0.0053 lr: 0.02
2019-03-26 12:06:50 iteration: 11850 loss: 0.0056 lr: 0.02
2019-03-26 12:07:21 iteration: 11855 loss: 0.0060 lr: 0.02
2019-03-26 12:07:50 iteration: 11860 loss: 0.0043 lr: 0.02
2019-03-26 12:08:29 iteration: 11865 loss: 0.0060 lr: 0.02
2019-03-26 12:08:38 iteration: 11870 loss: 0.0072 lr: 0.02
2019-03-26 12:09:21 iteration: 11875 loss: 0.0071 lr: 0.02
2019-03-26 12:10:12 iteration: 11880 loss: 0.0060 lr: 0.02
2019-03-26 12:11:21 iteration: 11885 loss: 0.0037 lr: 0.02
2019-03-26 12:12:11 iteration: 11890 loss: 0.0037 lr: 0.02
2019-03-26 12:12:56 iteration: 11895 loss: 0.0047 lr: 0.02
2019-03-26 12:13:16 iteration: 11900 loss: 0.0060 lr: 0.02
2019-03-26 12:14:28 iteration: 11905 loss: 0.0055 lr: 0.02
2019-03-26 12:15:15 iteration: 11910 loss: 0.0063 lr: 0.02
2019-03-26 12:16:47 iteration: 11915 loss: 0.0065 lr: 0.02
2019-03-26 12:17:05 iteration: 11920 loss: 0.0082 lr: 0.02
2019-03-26 12:17:59 iteration: 11925 loss: 0.0057 lr: 0.02
2019-03-26 12:18:31 iteration: 11930 loss: 0.0065 lr: 0.02
2019-03-26 12:18:52 iteration: 11935 loss: 0.0061 lr: 0.02
2019-03-26 12:19:06 iteration: 11940 loss: 0.0062 lr: 0.02
2019-03-26 12:20:31 iteration: 11945 loss: 0.0063 lr: 0.02
2019-03-26 12:21:58 iteration: 11950 loss: 0.0045 lr: 0.02
2019-03-26 12:22:51 iteration: 11955 loss: 0.0058 lr: 0.02
2019-03-26 12:23:12 iteration: 11960 loss: 0.0048 lr: 0.02
2019-03-26 12:23:54 iteration: 11965 loss: 0.0070 lr: 0.02
2019-03-26 12:24:13 iteration: 11970 loss: 0.0064 lr: 0.02
2019-03-26 12:25:04 iteration: 11975 loss: 0.0072 lr: 0.02
2019-03-26 12:25:22 iteration: 11980 loss: 0.0061 lr: 0.02
2019-03-26 12:26:13 iteration: 11985 loss: 0.0066 lr: 0.02
2019-03-26 12:26:54 iteration: 11990 loss: 0.0063 lr: 0.02
2019-03-26 12:27:33 iteration: 11995 loss: 0.0046 lr: 0.02
2019-03-26 12:28:00 iteration: 12000 loss: 0.0044 lr: 0.02
2019-03-26 12:28:35 iteration: 12005 loss: 0.0064 lr: 0.02
2019-03-26 12:29:20 iteration: 12010 loss: 0.0055 lr: 0.02
2019-03-26 12:29:40 iteration: 12015 loss: 0.0094 lr: 0.02
2019-03-26 12:30:50 iteration: 12020 loss: 0.0039 lr: 0.02
2019-03-26 12:31:28 iteration: 12025 loss: 0.0055 lr: 0.02
2019-03-26 12:31:38 iteration: 12030 loss: 0.0054 lr: 0.02
2019-03-26 12:32:00 iteration: 12035 loss: 0.0048 lr: 0.02
2019-03-26 12:32:46 iteration: 12040 loss: 0.0056 lr: 0.02
2019-03-26 12:33:31 iteration: 12045 loss: 0.0057 lr: 0.02
2019-03-26 12:33:43 iteration: 12050 loss: 0.0059 lr: 0.02
2019-03-26 12:34:10 iteration: 12055 loss: 0.0055 lr: 0.02
2019-03-26 12:34:29 iteration: 12060 loss: 0.0054 lr: 0.02
2019-03-26 12:35:13 iteration: 12065 loss: 0.0047 lr: 0.02
2019-03-26 12:37:12 iteration: 12070 loss: 0.0049 lr: 0.02
2019-03-26 12:37:34 iteration: 12075 loss: 0.0057 lr: 0.02
2019-03-26 12:38:03 iteration: 12080 loss: 0.0062 lr: 0.02
2019-03-26 12:38:49 iteration: 12085 loss: 0.0060 lr: 0.02
2019-03-26 12:39:04 iteration: 12090 loss: 0.0071 lr: 0.02
2019-03-26 12:39:25 iteration: 12095 loss: 0.0101 lr: 0.02
2019-03-26 12:40:13 iteration: 12100 loss: 0.0060 lr: 0.02
2019-03-26 12:40:38 iteration: 12105 loss: 0.0059 lr: 0.02
2019-03-26 12:41:28 iteration: 12110 loss: 0.0066 lr: 0.02
2019-03-26 12:42:00 iteration: 12115 loss: 0.0049 lr: 0.02
2019-03-26 12:42:52 iteration: 12120 loss: 0.0062 lr: 0.02
2019-03-26 12:43:30 iteration: 12125 loss: 0.0060 lr: 0.02
2019-03-26 12:43:56 iteration: 12130 loss: 0.0057 lr: 0.02
2019-03-26 12:44:05 iteration: 12135 loss: 0.0072 lr: 0.02
2019-03-26 12:44:56 iteration: 12140 loss: 0.0054 lr: 0.02
2019-03-26 12:45:21 iteration: 12145 loss: 0.0053 lr: 0.02
2019-03-26 12:45:37 iteration: 12150 loss: 0.0071 lr: 0.02
2019-03-26 12:46:40 iteration: 12155 loss: 0.0064 lr: 0.02
2019-03-26 12:47:20 iteration: 12160 loss: 0.0064 lr: 0.02
2019-03-26 12:47:55 iteration: 12165 loss: 0.0045 lr: 0.02
2019-03-26 12:48:27 iteration: 12170 loss: 0.0054 lr: 0.02
2019-03-26 12:48:48 iteration: 12175 loss: 0.0061 lr: 0.02
2019-03-26 12:49:43 iteration: 12180 loss: 0.0046 lr: 0.02
2019-03-26 12:50:09 iteration: 12185 loss: 0.0055 lr: 0.02
2019-03-26 12:50:34 iteration: 12190 loss: 0.0076 lr: 0.02
2019-03-26 12:50:53 iteration: 12195 loss: 0.0063 lr: 0.02
2019-03-26 12:51:42 iteration: 12200 loss: 0.0061 lr: 0.02
2019-03-26 12:52:18 iteration: 12205 loss: 0.0090 lr: 0.02
2019-03-26 12:53:00 iteration: 12210 loss: 0.0070 lr: 0.02
2019-03-26 12:54:01 iteration: 12215 loss: 0.0050 lr: 0.02
2019-03-26 12:54:45 iteration: 12220 loss: 0.0048 lr: 0.02
2019-03-26 12:55:33 iteration: 12225 loss: 0.0074 lr: 0.02
2019-03-26 12:55:50 iteration: 12230 loss: 0.0050 lr: 0.02
2019-03-26 12:56:36 iteration: 12235 loss: 0.0057 lr: 0.02
2019-03-26 12:57:05 iteration: 12240 loss: 0.0047 lr: 0.02
2019-03-26 12:58:14 iteration: 12245 loss: 0.0050 lr: 0.02
2019-03-26 12:59:04 iteration: 12250 loss: 0.0038 lr: 0.02
2019-03-26 13:00:09 iteration: 12255 loss: 0.0056 lr: 0.02
2019-03-26 13:00:47 iteration: 12260 loss: 0.0059 lr: 0.02
2019-03-26 13:01:06 iteration: 12265 loss: 0.0065 lr: 0.02
2019-03-26 13:01:51 iteration: 12270 loss: 0.0051 lr: 0.02
2019-03-26 13:02:28 iteration: 12275 loss: 0.0051 lr: 0.02
2019-03-26 13:03:21 iteration: 12280 loss: 0.0040 lr: 0.02
2019-03-26 13:04:46 iteration: 12285 loss: 0.0053 lr: 0.02
2019-03-26 13:05:05 iteration: 12290 loss: 0.0070 lr: 0.02
2019-03-26 13:05:48 iteration: 12295 loss: 0.0050 lr: 0.02
2019-03-26 13:06:02 iteration: 12300 loss: 0.0066 lr: 0.02
2019-03-26 13:06:16 iteration: 12305 loss: 0.0078 lr: 0.02
2019-03-26 13:06:33 iteration: 12310 loss: 0.0049 lr: 0.02
2019-03-26 13:07:22 iteration: 12315 loss: 0.0050 lr: 0.02
2019-03-26 13:07:52 iteration: 12320 loss: 0.0054 lr: 0.02
2019-03-26 13:08:07 iteration: 12325 loss: 0.0052 lr: 0.02
2019-03-26 13:08:29 iteration: 12330 loss: 0.0082 lr: 0.02
2019-03-26 13:08:58 iteration: 12335 loss: 0.0048 lr: 0.02
2019-03-26 13:09:26 iteration: 12340 loss: 0.0049 lr: 0.02
2019-03-26 13:10:19 iteration: 12345 loss: 0.0059 lr: 0.02
2019-03-26 13:11:04 iteration: 12350 loss: 0.0051 lr: 0.02
2019-03-26 13:11:47 iteration: 12355 loss: 0.0048 lr: 0.02
2019-03-26 13:12:11 iteration: 12360 loss: 0.0059 lr: 0.02
2019-03-26 13:12:55 iteration: 12365 loss: 0.0056 lr: 0.02
2019-03-26 13:13:37 iteration: 12370 loss: 0.0042 lr: 0.02
2019-03-26 13:14:09 iteration: 12375 loss: 0.0046 lr: 0.02
2019-03-26 13:14:36 iteration: 12380 loss: 0.0061 lr: 0.02
2019-03-26 13:15:13 iteration: 12385 loss: 0.0039 lr: 0.02
2019-03-26 13:15:39 iteration: 12390 loss: 0.0050 lr: 0.02
2019-03-26 13:16:03 iteration: 12395 loss: 0.0045 lr: 0.02
2019-03-26 13:16:25 iteration: 12400 loss: 0.0066 lr: 0.02
2019-03-26 13:16:43 iteration: 12405 loss: 0.0116 lr: 0.02
2019-03-26 13:17:34 iteration: 12410 loss: 0.0044 lr: 0.02
2019-03-26 13:17:50 iteration: 12415 loss: 0.0078 lr: 0.02
2019-03-26 13:18:49 iteration: 12420 loss: 0.0034 lr: 0.02
2019-03-26 13:19:34 iteration: 12425 loss: 0.0045 lr: 0.02
2019-03-26 13:19:58 iteration: 12430 loss: 0.0070 lr: 0.02
2019-03-26 13:20:25 iteration: 12435 loss: 0.0045 lr: 0.02
2019-03-26 13:20:46 iteration: 12440 loss: 0.0059 lr: 0.02
2019-03-26 13:21:44 iteration: 12445 loss: 0.0042 lr: 0.02
2019-03-26 13:22:27 iteration: 12450 loss: 0.0061 lr: 0.02
2019-03-26 13:22:43 iteration: 12455 loss: 0.0063 lr: 0.02
2019-03-26 13:22:57 iteration: 12460 loss: 0.0071 lr: 0.02
2019-03-26 13:23:15 iteration: 12465 loss: 0.0049 lr: 0.02
2019-03-26 13:23:42 iteration: 12470 loss: 0.0050 lr: 0.02
2019-03-26 13:24:41 iteration: 12475 loss: 0.0059 lr: 0.02
2019-03-26 13:25:04 iteration: 12480 loss: 0.0059 lr: 0.02
2019-03-26 13:25:41 iteration: 12485 loss: 0.0067 lr: 0.02
2019-03-26 13:26:21 iteration: 12490 loss: 0.0055 lr: 0.02
2019-03-26 13:26:59 iteration: 12495 loss: 0.0054 lr: 0.02
2019-03-26 13:27:54 iteration: 12500 loss: 0.0044 lr: 0.02
2019-03-26 13:28:06 iteration: 12505 loss: 0.0064 lr: 0.02
2019-03-26 13:28:33 iteration: 12510 loss: 0.0034 lr: 0.02
2019-03-26 13:28:54 iteration: 12515 loss: 0.0053 lr: 0.02
2019-03-26 13:29:13 iteration: 12520 loss: 0.0058 lr: 0.02
2019-03-26 13:29:36 iteration: 12525 loss: 0.0064 lr: 0.02
2019-03-26 13:29:47 iteration: 12530 loss: 0.0077 lr: 0.02
2019-03-26 13:29:59 iteration: 12535 loss: 0.0085 lr: 0.02
2019-03-26 13:31:06 iteration: 12540 loss: 0.0051 lr: 0.02
2019-03-26 13:31:51 iteration: 12545 loss: 0.0059 lr: 0.02
2019-03-26 13:32:25 iteration: 12550 loss: 0.0062 lr: 0.02
2019-03-26 13:33:46 iteration: 12555 loss: 0.0058 lr: 0.02
2019-03-26 13:35:19 iteration: 12560 loss: 0.0051 lr: 0.02
2019-03-26 13:36:11 iteration: 12565 loss: 0.0058 lr: 0.02
2019-03-26 13:37:12 iteration: 12570 loss: 0.0065 lr: 0.02
2019-03-26 13:37:25 iteration: 12575 loss: 0.0069 lr: 0.02
2019-03-26 13:38:18 iteration: 12580 loss: 0.0052 lr: 0.02
2019-03-26 13:38:46 iteration: 12585 loss: 0.0048 lr: 0.02
2019-03-26 13:40:02 iteration: 12590 loss: 0.0050 lr: 0.02
2019-03-26 13:40:49 iteration: 12595 loss: 0.0060 lr: 0.02
2019-03-26 13:41:20 iteration: 12600 loss: 0.0044 lr: 0.02
2019-03-26 13:42:05 iteration: 12605 loss: 0.0050 lr: 0.02
2019-03-26 13:42:34 iteration: 12610 loss: 0.0057 lr: 0.02
2019-03-26 13:42:54 iteration: 12615 loss: 0.0056 lr: 0.02
2019-03-26 13:43:22 iteration: 12620 loss: 0.0061 lr: 0.02
2019-03-26 13:44:06 iteration: 12625 loss: 0.0065 lr: 0.02
2019-03-26 13:44:17 iteration: 12630 loss: 0.0064 lr: 0.02
2019-03-26 13:44:29 iteration: 12635 loss: 0.0053 lr: 0.02
2019-03-26 13:45:17 iteration: 12640 loss: 0.0057 lr: 0.02
2019-03-26 13:46:34 iteration: 12645 loss: 0.0051 lr: 0.02
2019-03-26 13:46:53 iteration: 12650 loss: 0.0074 lr: 0.02
2019-03-26 13:47:56 iteration: 12655 loss: 0.0074 lr: 0.02
2019-03-26 13:49:07 iteration: 12660 loss: 0.0052 lr: 0.02
2019-03-26 13:49:28 iteration: 12665 loss: 0.0067 lr: 0.02
2019-03-26 13:50:18 iteration: 12670 loss: 0.0048 lr: 0.02
2019-03-26 13:51:15 iteration: 12675 loss: 0.0039 lr: 0.02
2019-03-26 13:52:01 iteration: 12680 loss: 0.0040 lr: 0.02
2019-03-26 13:52:32 iteration: 12685 loss: 0.0056 lr: 0.02
2019-03-26 13:53:33 iteration: 12690 loss: 0.0040 lr: 0.02
2019-03-26 13:54:18 iteration: 12695 loss: 0.0048 lr: 0.02
2019-03-26 13:54:40 iteration: 12700 loss: 0.0053 lr: 0.02
2019-03-26 13:55:16 iteration: 12705 loss: 0.0046 lr: 0.02
2019-03-26 13:55:53 iteration: 12710 loss: 0.0051 lr: 0.02
2019-03-26 13:56:38 iteration: 12715 loss: 0.0045 lr: 0.02
2019-03-26 13:56:59 iteration: 12720 loss: 0.0054 lr: 0.02
2019-03-26 13:57:35 iteration: 12725 loss: 0.0044 lr: 0.02
2019-03-26 13:57:50 iteration: 12730 loss: 0.0057 lr: 0.02
2019-03-26 13:58:11 iteration: 12735 loss: 0.0051 lr: 0.02
2019-03-26 13:59:04 iteration: 12740 loss: 0.0066 lr: 0.02
2019-03-26 14:00:06 iteration: 12745 loss: 0.0043 lr: 0.02
2019-03-26 14:00:45 iteration: 12750 loss: 0.0053 lr: 0.02
2019-03-26 14:01:45 iteration: 12755 loss: 0.0044 lr: 0.02
2019-03-26 14:02:17 iteration: 12760 loss: 0.0054 lr: 0.02
2019-03-26 14:02:36 iteration: 12765 loss: 0.0069 lr: 0.02
2019-03-26 14:03:44 iteration: 12770 loss: 0.0056 lr: 0.02
2019-03-26 14:03:58 iteration: 12775 loss: 0.0079 lr: 0.02
2019-03-26 14:04:26 iteration: 12780 loss: 0.0053 lr: 0.02
2019-03-26 14:04:40 iteration: 12785 loss: 0.0065 lr: 0.02
2019-03-26 14:05:33 iteration: 12790 loss: 0.0102 lr: 0.02
2019-03-26 14:06:16 iteration: 12795 loss: 0.0070 lr: 0.02
2019-03-26 14:07:00 iteration: 12800 loss: 0.0054 lr: 0.02
2019-03-26 14:08:04 iteration: 12805 loss: 0.0051 lr: 0.02
2019-03-26 14:09:10 iteration: 12810 loss: 0.0057 lr: 0.02
2019-03-26 14:10:42 iteration: 12815 loss: 0.0056 lr: 0.02
2019-03-26 14:11:24 iteration: 12820 loss: 0.0073 lr: 0.02
2019-03-26 14:12:19 iteration: 12825 loss: 0.0054 lr: 0.02
2019-03-26 14:12:35 iteration: 12830 loss: 0.0052 lr: 0.02
2019-03-26 14:13:11 iteration: 12835 loss: 0.0046 lr: 0.02
2019-03-26 14:13:29 iteration: 12840 loss: 0.0051 lr: 0.02
2019-03-26 14:14:45 iteration: 12845 loss: 0.0048 lr: 0.02
2019-03-26 14:15:08 iteration: 12850 loss: 0.0042 lr: 0.02
2019-03-26 14:15:25 iteration: 12855 loss: 0.0070 lr: 0.02
2019-03-26 14:16:08 iteration: 12860 loss: 0.0063 lr: 0.02
2019-03-26 14:16:21 iteration: 12865 loss: 0.0063 lr: 0.02
2019-03-26 14:16:59 iteration: 12870 loss: 0.0071 lr: 0.02
2019-03-26 14:17:10 iteration: 12875 loss: 0.0055 lr: 0.02
2019-03-26 14:17:37 iteration: 12880 loss: 0.0063 lr: 0.02
2019-03-26 14:17:50 iteration: 12885 loss: 0.0122 lr: 0.02
2019-03-26 14:18:09 iteration: 12890 loss: 0.0057 lr: 0.02
2019-03-26 14:18:26 iteration: 12895 loss: 0.0059 lr: 0.02
2019-03-26 14:19:31 iteration: 12900 loss: 0.0036 lr: 0.02
2019-03-26 14:20:23 iteration: 12905 loss: 0.0043 lr: 0.02
2019-03-26 14:20:41 iteration: 12910 loss: 0.0059 lr: 0.02
2019-03-26 14:21:05 iteration: 12915 loss: 0.0049 lr: 0.02
2019-03-26 14:21:26 iteration: 12920 loss: 0.0054 lr: 0.02
2019-03-26 14:22:33 iteration: 12925 loss: 0.0042 lr: 0.02
2019-03-26 14:23:13 iteration: 12930 loss: 0.0055 lr: 0.02
2019-03-26 14:23:39 iteration: 12935 loss: 0.0053 lr: 0.02
2019-03-26 14:23:53 iteration: 12940 loss: 0.0064 lr: 0.02
2019-03-26 14:24:04 iteration: 12945 loss: 0.0071 lr: 0.02
2019-03-26 14:24:38 iteration: 12950 loss: 0.0047 lr: 0.02
2019-03-26 14:24:52 iteration: 12955 loss: 0.0053 lr: 0.02
2019-03-26 14:25:09 iteration: 12960 loss: 0.0047 lr: 0.02
2019-03-26 14:26:03 iteration: 12965 loss: 0.0061 lr: 0.02
2019-03-26 14:26:24 iteration: 12970 loss: 0.0047 lr: 0.02
2019-03-26 14:26:58 iteration: 12975 loss: 0.0080 lr: 0.02
2019-03-26 14:27:27 iteration: 12980 loss: 0.0044 lr: 0.02
2019-03-26 14:28:09 iteration: 12985 loss: 0.0046 lr: 0.02
2019-03-26 14:28:41 iteration: 12990 loss: 0.0059 lr: 0.02
2019-03-26 14:29:54 iteration: 12995 loss: 0.0057 lr: 0.02
2019-03-26 14:30:22 iteration: 13000 loss: 0.0040 lr: 0.02
2019-03-26 14:30:35 iteration: 13005 loss: 0.0054 lr: 0.02
2019-03-26 14:31:08 iteration: 13010 loss: 0.0054 lr: 0.02
2019-03-26 14:31:48 iteration: 13015 loss: 0.0058 lr: 0.02
2019-03-26 14:32:02 iteration: 13020 loss: 0.0067 lr: 0.02
2019-03-26 14:32:20 iteration: 13025 loss: 0.0059 lr: 0.02
2019-03-26 14:33:11 iteration: 13030 loss: 0.0062 lr: 0.02
2019-03-26 14:33:28 iteration: 13035 loss: 0.0051 lr: 0.02
2019-03-26 14:33:59 iteration: 13040 loss: 0.0052 lr: 0.02
2019-03-26 14:34:42 iteration: 13045 loss: 0.0065 lr: 0.02
2019-03-26 14:35:48 iteration: 13050 loss: 0.0057 lr: 0.02
2019-03-26 14:36:50 iteration: 13055 loss: 0.0051 lr: 0.02
2019-03-26 14:37:47 iteration: 13060 loss: 0.0043 lr: 0.02
2019-03-26 14:38:56 iteration: 13065 loss: 0.0058 lr: 0.02
2019-03-26 14:39:47 iteration: 13070 loss: 0.0051 lr: 0.02
2019-03-26 14:40:17 iteration: 13075 loss: 0.0066 lr: 0.02
2019-03-26 14:41:07 iteration: 13080 loss: 0.0081 lr: 0.02
2019-03-26 14:41:37 iteration: 13085 loss: 0.0049 lr: 0.02
2019-03-26 14:42:16 iteration: 13090 loss: 0.0057 lr: 0.02
2019-03-26 14:42:37 iteration: 13095 loss: 0.0061 lr: 0.02
2019-03-26 14:43:06 iteration: 13100 loss: 0.0044 lr: 0.02
2019-03-26 14:43:54 iteration: 13105 loss: 0.0051 lr: 0.02
2019-03-26 14:45:29 iteration: 13110 loss: 0.0045 lr: 0.02
2019-03-26 14:46:01 iteration: 13115 loss: 0.0076 lr: 0.02
2019-03-26 14:46:21 iteration: 13120 loss: 0.0082 lr: 0.02
2019-03-26 14:46:56 iteration: 13125 loss: 0.0079 lr: 0.02
2019-03-26 14:48:15 iteration: 13130 loss: 0.0039 lr: 0.02
2019-03-26 14:48:53 iteration: 13135 loss: 0.0066 lr: 0.02
2019-03-26 14:49:08 iteration: 13140 loss: 0.0068 lr: 0.02
2019-03-26 14:49:58 iteration: 13145 loss: 0.0048 lr: 0.02
2019-03-26 14:50:31 iteration: 13150 loss: 0.0050 lr: 0.02
2019-03-26 14:50:41 iteration: 13155 loss: 0.0069 lr: 0.02
2019-03-26 14:51:45 iteration: 13160 loss: 0.0069 lr: 0.02
2019-03-26 14:53:40 iteration: 13165 loss: 0.0046 lr: 0.02
2019-03-26 14:54:02 iteration: 13170 loss: 0.0057 lr: 0.02
2019-03-26 14:55:14 iteration: 13175 loss: 0.0058 lr: 0.02
2019-03-26 14:55:40 iteration: 13180 loss: 0.0060 lr: 0.02
2019-03-26 14:56:37 iteration: 13185 loss: 0.0049 lr: 0.02
2019-03-26 14:56:58 iteration: 13190 loss: 0.0052 lr: 0.02
2019-03-26 14:57:39 iteration: 13195 loss: 0.0064 lr: 0.02
2019-03-26 14:58:05 iteration: 13200 loss: 0.0060 lr: 0.02
2019-03-26 14:58:21 iteration: 13205 loss: 0.0065 lr: 0.02
2019-03-26 14:59:20 iteration: 13210 loss: 0.0072 lr: 0.02
2019-03-26 14:59:39 iteration: 13215 loss: 0.0059 lr: 0.02
2019-03-26 15:00:01 iteration: 13220 loss: 0.0042 lr: 0.02
2019-03-26 15:00:43 iteration: 13225 loss: 0.0055 lr: 0.02
2019-03-26 15:01:01 iteration: 13230 loss: 0.0072 lr: 0.02
2019-03-26 15:01:23 iteration: 13235 loss: 0.0051 lr: 0.02
2019-03-26 15:02:38 iteration: 13240 loss: 0.0053 lr: 0.02
2019-03-26 15:03:09 iteration: 13245 loss: 0.0046 lr: 0.02
2019-03-26 15:03:45 iteration: 13250 loss: 0.0078 lr: 0.02
2019-03-26 15:04:01 iteration: 13255 loss: 0.0054 lr: 0.02
2019-03-26 15:04:16 iteration: 13260 loss: 0.0061 lr: 0.02
2019-03-26 15:04:55 iteration: 13265 loss: 0.0051 lr: 0.02
2019-03-26 15:05:20 iteration: 13270 loss: 0.0068 lr: 0.02
2019-03-26 15:05:36 iteration: 13275 loss: 0.0045 lr: 0.02
2019-03-26 15:06:16 iteration: 13280 loss: 0.0080 lr: 0.02
2019-03-26 15:07:21 iteration: 13285 loss: 0.0050 lr: 0.02
2019-03-26 15:08:21 iteration: 13290 loss: 0.0040 lr: 0.02
2019-03-26 15:08:39 iteration: 13295 loss: 0.0053 lr: 0.02
2019-03-26 15:09:05 iteration: 13300 loss: 0.0041 lr: 0.02
2019-03-26 15:09:56 iteration: 13305 loss: 0.0051 lr: 0.02
2019-03-26 15:10:17 iteration: 13310 loss: 0.0055 lr: 0.02
2019-03-26 15:10:30 iteration: 13315 loss: 0.0062 lr: 0.02
2019-03-26 15:10:57 iteration: 13320 loss: 0.0063 lr: 0.02
2019-03-26 15:11:37 iteration: 13325 loss: 0.0050 lr: 0.02
2019-03-26 15:12:28 iteration: 13330 loss: 0.0052 lr: 0.02
2019-03-26 15:13:19 iteration: 13335 loss: 0.0058 lr: 0.02
2019-03-26 15:14:25 iteration: 13340 loss: 0.0041 lr: 0.02
2019-03-26 15:14:42 iteration: 13345 loss: 0.0048 lr: 0.02
2019-03-26 15:15:10 iteration: 13350 loss: 0.0076 lr: 0.02
2019-03-26 15:15:21 iteration: 13355 loss: 0.0067 lr: 0.02
2019-03-26 15:15:35 iteration: 13360 loss: 0.0059 lr: 0.02
2019-03-26 15:15:52 iteration: 13365 loss: 0.0057 lr: 0.02
2019-03-26 15:16:35 iteration: 13370 loss: 0.0045 lr: 0.02
2019-03-26 15:17:07 iteration: 13375 loss: 0.0051 lr: 0.02
2019-03-26 15:17:18 iteration: 13380 loss: 0.0090 lr: 0.02
2019-03-26 15:17:51 iteration: 13385 loss: 0.0094 lr: 0.02
2019-03-26 15:18:24 iteration: 13390 loss: 0.0066 lr: 0.02
2019-03-26 15:18:54 iteration: 13395 loss: 0.0046 lr: 0.02
2019-03-26 15:19:35 iteration: 13400 loss: 0.0056 lr: 0.02
2019-03-26 15:20:14 iteration: 13405 loss: 0.0054 lr: 0.02
2019-03-26 15:21:00 iteration: 13410 loss: 0.0059 lr: 0.02
2019-03-26 15:21:29 iteration: 13415 loss: 0.0050 lr: 0.02
2019-03-26 15:22:00 iteration: 13420 loss: 0.0058 lr: 0.02
2019-03-26 15:22:35 iteration: 13425 loss: 0.0076 lr: 0.02
2019-03-26 15:23:39 iteration: 13430 loss: 0.0081 lr: 0.02
2019-03-26 15:24:06 iteration: 13435 loss: 0.0055 lr: 0.02
2019-03-26 15:25:11 iteration: 13440 loss: 0.0052 lr: 0.02
2019-03-26 15:25:26 iteration: 13445 loss: 0.0066 lr: 0.02
2019-03-26 15:25:53 iteration: 13450 loss: 0.0056 lr: 0.02
2019-03-26 15:26:19 iteration: 13455 loss: 0.0057 lr: 0.02
2019-03-26 15:26:35 iteration: 13460 loss: 0.0066 lr: 0.02
2019-03-26 15:26:59 iteration: 13465 loss: 0.0054 lr: 0.02
2019-03-26 15:27:32 iteration: 13470 loss: 0.0045 lr: 0.02
2019-03-26 15:28:18 iteration: 13475 loss: 0.0036 lr: 0.02
2019-03-26 15:28:38 iteration: 13480 loss: 0.0062 lr: 0.02
2019-03-26 15:29:20 iteration: 13485 loss: 0.0038 lr: 0.02
2019-03-26 15:30:11 iteration: 13490 loss: 0.0069 lr: 0.02
2019-03-26 15:30:50 iteration: 13495 loss: 0.0104 lr: 0.02
2019-03-26 15:31:07 iteration: 13500 loss: 0.0064 lr: 0.02
2019-03-26 15:31:30 iteration: 13505 loss: 0.0059 lr: 0.02
2019-03-26 15:31:56 iteration: 13510 loss: 0.0047 lr: 0.02
2019-03-26 15:33:08 iteration: 13515 loss: 0.0050 lr: 0.02
2019-03-26 15:33:32 iteration: 13520 loss: 0.0050 lr: 0.02
2019-03-26 15:34:05 iteration: 13525 loss: 0.0050 lr: 0.02
2019-03-26 15:34:43 iteration: 13530 loss: 0.0057 lr: 0.02
2019-03-26 15:35:16 iteration: 13535 loss: 0.0042 lr: 0.02
2019-03-26 15:35:42 iteration: 13540 loss: 0.0058 lr: 0.02
2019-03-26 15:36:26 iteration: 13545 loss: 0.0075 lr: 0.02
2019-03-26 15:37:41 iteration: 13550 loss: 0.0048 lr: 0.02
2019-03-26 15:37:55 iteration: 13555 loss: 0.0065 lr: 0.02
2019-03-26 15:38:37 iteration: 13560 loss: 0.0058 lr: 0.02
2019-03-26 15:39:55 iteration: 13565 loss: 0.0054 lr: 0.02
2019-03-26 15:40:14 iteration: 13570 loss: 0.0056 lr: 0.02
2019-03-26 15:41:03 iteration: 13575 loss: 0.0054 lr: 0.02
2019-03-26 15:42:34 iteration: 13580 loss: 0.0050 lr: 0.02
2019-03-26 15:42:52 iteration: 13585 loss: 0.0074 lr: 0.02
2019-03-26 15:43:03 iteration: 13590 loss: 0.0061 lr: 0.02
2019-03-26 15:43:21 iteration: 13595 loss: 0.0061 lr: 0.02
2019-03-26 15:44:18 iteration: 13600 loss: 0.0073 lr: 0.02
2019-03-26 15:44:37 iteration: 13605 loss: 0.0062 lr: 0.02
2019-03-26 15:44:53 iteration: 13610 loss: 0.0063 lr: 0.02
2019-03-26 15:45:54 iteration: 13615 loss: 0.0049 lr: 0.02
2019-03-26 15:46:10 iteration: 13620 loss: 0.0055 lr: 0.02
2019-03-26 15:46:41 iteration: 13625 loss: 0.0052 lr: 0.02
2019-03-26 15:47:02 iteration: 13630 loss: 0.0067 lr: 0.02
2019-03-26 15:47:30 iteration: 13635 loss: 0.0078 lr: 0.02
2019-03-26 15:48:30 iteration: 13640 loss: 0.0055 lr: 0.02
2019-03-26 15:48:45 iteration: 13645 loss: 0.0071 lr: 0.02
2019-03-26 15:49:27 iteration: 13650 loss: 0.0045 lr: 0.02
2019-03-26 15:49:44 iteration: 13655 loss: 0.0059 lr: 0.02
2019-03-26 15:49:59 iteration: 13660 loss: 0.0077 lr: 0.02
2019-03-26 15:50:35 iteration: 13665 loss: 0.0048 lr: 0.02
2019-03-26 15:51:38 iteration: 13670 loss: 0.0045 lr: 0.02
2019-03-26 15:52:20 iteration: 13675 loss: 0.0056 lr: 0.02
2019-03-26 15:53:10 iteration: 13680 loss: 0.0053 lr: 0.02
2019-03-26 15:54:18 iteration: 13685 loss: 0.0056 lr: 0.02
2019-03-26 15:54:37 iteration: 13690 loss: 0.0052 lr: 0.02
2019-03-26 15:55:31 iteration: 13695 loss: 0.0077 lr: 0.02
2019-03-26 15:56:27 iteration: 13700 loss: 0.0044 lr: 0.02
2019-03-26 15:56:42 iteration: 13705 loss: 0.0069 lr: 0.02
2019-03-26 15:57:02 iteration: 13710 loss: 0.0064 lr: 0.02
2019-03-26 15:57:23 iteration: 13715 loss: 0.0089 lr: 0.02
2019-03-26 15:58:12 iteration: 13720 loss: 0.0048 lr: 0.02
2019-03-26 15:58:28 iteration: 13725 loss: 0.0056 lr: 0.02
2019-03-26 15:59:19 iteration: 13730 loss: 0.0036 lr: 0.02
2019-03-26 16:00:09 iteration: 13735 loss: 0.0058 lr: 0.02
2019-03-26 16:00:30 iteration: 13740 loss: 0.0049 lr: 0.02
2019-03-26 16:01:30 iteration: 13745 loss: 0.0053 lr: 0.02
2019-03-26 16:02:55 iteration: 13750 loss: 0.0079 lr: 0.02
2019-03-26 16:03:18 iteration: 13755 loss: 0.0053 lr: 0.02
2019-03-26 16:03:31 iteration: 13760 loss: 0.0047 lr: 0.02
2019-03-26 16:03:52 iteration: 13765 loss: 0.0043 lr: 0.02
2019-03-26 16:04:22 iteration: 13770 loss: 0.0077 lr: 0.02
2019-03-26 16:04:52 iteration: 13775 loss: 0.0056 lr: 0.02
2019-03-26 16:05:09 iteration: 13780 loss: 0.0063 lr: 0.02
2019-03-26 16:05:27 iteration: 13785 loss: 0.0048 lr: 0.02
2019-03-26 16:05:48 iteration: 13790 loss: 0.0048 lr: 0.02
2019-03-26 16:06:19 iteration: 13795 loss: 0.0077 lr: 0.02
2019-03-26 16:06:38 iteration: 13800 loss: 0.0054 lr: 0.02
2019-03-26 16:06:51 iteration: 13805 loss: 0.0049 lr: 0.02
2019-03-26 16:07:05 iteration: 13810 loss: 0.0075 lr: 0.02
2019-03-26 16:07:18 iteration: 13815 loss: 0.0104 lr: 0.02
2019-03-26 16:08:17 iteration: 13820 loss: 0.0043 lr: 0.02
2019-03-26 16:09:32 iteration: 13825 loss: 0.0069 lr: 0.02
2019-03-26 16:10:13 iteration: 13830 loss: 0.0048 lr: 0.02
2019-03-26 16:10:59 iteration: 13835 loss: 0.0058 lr: 0.02
2019-03-26 16:11:18 iteration: 13840 loss: 0.0058 lr: 0.02
2019-03-26 16:12:04 iteration: 13845 loss: 0.0042 lr: 0.02
2019-03-26 16:13:02 iteration: 13850 loss: 0.0041 lr: 0.02
2019-03-26 16:14:09 iteration: 13855 loss: 0.0044 lr: 0.02
2019-03-26 16:14:38 iteration: 13860 loss: 0.0050 lr: 0.02
2019-03-26 16:14:55 iteration: 13865 loss: 0.0087 lr: 0.02
2019-03-26 16:16:21 iteration: 13870 loss: 0.0047 lr: 0.02
2019-03-26 16:17:06 iteration: 13875 loss: 0.0044 lr: 0.02
2019-03-26 16:17:22 iteration: 13880 loss: 0.0069 lr: 0.02
2019-03-26 16:17:49 iteration: 13885 loss: 0.0061 lr: 0.02
2019-03-26 16:18:01 iteration: 13890 loss: 0.0086 lr: 0.02
2019-03-26 16:18:16 iteration: 13895 loss: 0.0049 lr: 0.02
2019-03-26 16:18:35 iteration: 13900 loss: 0.0065 lr: 0.02
2019-03-26 16:18:58 iteration: 13905 loss: 0.0069 lr: 0.02
2019-03-26 16:19:41 iteration: 13910 loss: 0.0053 lr: 0.02
2019-03-26 16:20:16 iteration: 13915 loss: 0.0058 lr: 0.02
2019-03-26 16:21:00 iteration: 13920 loss: 0.0052 lr: 0.02
2019-03-26 16:21:41 iteration: 13925 loss: 0.0042 lr: 0.02
2019-03-26 16:22:17 iteration: 13930 loss: 0.0039 lr: 0.02
2019-03-26 16:22:38 iteration: 13935 loss: 0.0049 lr: 0.02
2019-03-26 16:23:55 iteration: 13940 loss: 0.0043 lr: 0.02
2019-03-26 16:24:13 iteration: 13945 loss: 0.0063 lr: 0.02
2019-03-26 16:24:35 iteration: 13950 loss: 0.0040 lr: 0.02
2019-03-26 16:25:46 iteration: 13955 loss: 0.0047 lr: 0.02
2019-03-26 16:26:16 iteration: 13960 loss: 0.0058 lr: 0.02
2019-03-26 16:26:34 iteration: 13965 loss: 0.0061 lr: 0.02
2019-03-26 16:27:21 iteration: 13970 loss: 0.0076 lr: 0.02
2019-03-26 16:27:38 iteration: 13975 loss: 0.0070 lr: 0.02
2019-03-26 16:28:09 iteration: 13980 loss: 0.0044 lr: 0.02
2019-03-26 16:28:50 iteration: 13985 loss: 0.0070 lr: 0.02
2019-03-26 16:29:40 iteration: 13990 loss: 0.0048 lr: 0.02
2019-03-26 16:30:10 iteration: 13995 loss: 0.0070 lr: 0.02
2019-03-26 16:31:12 iteration: 14000 loss: 0.0058 lr: 0.02
2019-03-26 16:32:14 iteration: 14005 loss: 0.0048 lr: 0.02
2019-03-26 16:33:01 iteration: 14010 loss: 0.0047 lr: 0.02
2019-03-26 16:33:27 iteration: 14015 loss: 0.0052 lr: 0.02
2019-03-26 16:35:12 iteration: 14020 loss: 0.0065 lr: 0.02
2019-03-26 16:36:04 iteration: 14025 loss: 0.0063 lr: 0.02
2019-03-26 16:36:30 iteration: 14030 loss: 0.0057 lr: 0.02
2019-03-26 16:36:46 iteration: 14035 loss: 0.0054 lr: 0.02
2019-03-26 16:37:46 iteration: 14040 loss: 0.0052 lr: 0.02
2019-03-26 16:38:02 iteration: 14045 loss: 0.0049 lr: 0.02
2019-03-26 16:38:25 iteration: 14050 loss: 0.0052 lr: 0.02
2019-03-26 16:38:56 iteration: 14055 loss: 0.0041 lr: 0.02
2019-03-26 16:39:51 iteration: 14060 loss: 0.0051 lr: 0.02
2019-03-26 16:40:41 iteration: 14065 loss: 0.0042 lr: 0.02
2019-03-26 16:41:04 iteration: 14070 loss: 0.0048 lr: 0.02
2019-03-26 16:41:20 iteration: 14075 loss: 0.0054 lr: 0.02
2019-03-26 16:42:55 iteration: 14080 loss: 0.0039 lr: 0.02
2019-03-26 16:43:52 iteration: 14085 loss: 0.0049 lr: 0.02
2019-03-26 16:44:39 iteration: 14090 loss: 0.0058 lr: 0.02
2019-03-26 16:45:45 iteration: 14095 loss: 0.0059 lr: 0.02
2019-03-26 16:46:17 iteration: 14100 loss: 0.0057 lr: 0.02
2019-03-26 16:46:29 iteration: 14105 loss: 0.0071 lr: 0.02
2019-03-26 16:47:08 iteration: 14110 loss: 0.0046 lr: 0.02
2019-03-26 16:47:20 iteration: 14115 loss: 0.0084 lr: 0.02
2019-03-26 16:48:07 iteration: 14120 loss: 0.0082 lr: 0.02
2019-03-26 16:48:38 iteration: 14125 loss: 0.0057 lr: 0.02
2019-03-26 16:49:00 iteration: 14130 loss: 0.0057 lr: 0.02
2019-03-26 16:49:23 iteration: 14135 loss: 0.0052 lr: 0.02
2019-03-26 16:49:53 iteration: 14140 loss: 0.0055 lr: 0.02
2019-03-26 16:50:43 iteration: 14145 loss: 0.0054 lr: 0.02
2019-03-26 16:51:07 iteration: 14150 loss: 0.0050 lr: 0.02
2019-03-26 16:51:22 iteration: 14155 loss: 0.0043 lr: 0.02
2019-03-26 16:51:35 iteration: 14160 loss: 0.0051 lr: 0.02
2019-03-26 16:52:27 iteration: 14165 loss: 0.0042 lr: 0.02
2019-03-26 16:53:09 iteration: 14170 loss: 0.0047 lr: 0.02
2019-03-26 16:54:08 iteration: 14175 loss: 0.0055 lr: 0.02
2019-03-26 16:55:12 iteration: 14180 loss: 0.0038 lr: 0.02
2019-03-26 16:55:30 iteration: 14185 loss: 0.0068 lr: 0.02
2019-03-26 16:56:24 iteration: 14190 loss: 0.0049 lr: 0.02
2019-03-26 16:57:06 iteration: 14195 loss: 0.0059 lr: 0.02
2019-03-26 16:57:24 iteration: 14200 loss: 0.0053 lr: 0.02
2019-03-26 16:57:43 iteration: 14205 loss: 0.0052 lr: 0.02
2019-03-26 16:58:37 iteration: 14210 loss: 0.0054 lr: 0.02
2019-03-26 16:59:37 iteration: 14215 loss: 0.0062 lr: 0.02
2019-03-26 16:59:58 iteration: 14220 loss: 0.0045 lr: 0.02
2019-03-26 17:00:47 iteration: 14225 loss: 0.0051 lr: 0.02
2019-03-26 17:02:01 iteration: 14230 loss: 0.0053 lr: 0.02
2019-03-26 17:02:35 iteration: 14235 loss: 0.0046 lr: 0.02
2019-03-26 17:03:11 iteration: 14240 loss: 0.0055 lr: 0.02
2019-03-26 17:03:55 iteration: 14245 loss: 0.0049 lr: 0.02
2019-03-26 17:04:29 iteration: 14250 loss: 0.0043 lr: 0.02
2019-03-26 17:05:57 iteration: 14255 loss: 0.0039 lr: 0.02
2019-03-26 17:06:43 iteration: 14260 loss: 0.0053 lr: 0.02
2019-03-26 17:06:56 iteration: 14265 loss: 0.0051 lr: 0.02
2019-03-26 17:08:16 iteration: 14270 loss: 0.0051 lr: 0.02
2019-03-26 17:08:40 iteration: 14275 loss: 0.0043 lr: 0.02
2019-03-26 17:09:00 iteration: 14280 loss: 0.0047 lr: 0.02
2019-03-26 17:09:15 iteration: 14285 loss: 0.0083 lr: 0.02
2019-03-26 17:09:32 iteration: 14290 loss: 0.0088 lr: 0.02
2019-03-26 17:10:24 iteration: 14295 loss: 0.0053 lr: 0.02
2019-03-26 17:10:48 iteration: 14300 loss: 0.0064 lr: 0.02
2019-03-26 17:11:42 iteration: 14305 loss: 0.0051 lr: 0.02
2019-03-26 17:12:35 iteration: 14310 loss: 0.0053 lr: 0.02
2019-03-26 17:12:48 iteration: 14315 loss: 0.0068 lr: 0.02
2019-03-26 17:13:10 iteration: 14320 loss: 0.0084 lr: 0.02
2019-03-26 17:14:31 iteration: 14325 loss: 0.0059 lr: 0.02
2019-03-26 17:15:09 iteration: 14330 loss: 0.0075 lr: 0.02
2019-03-26 17:15:54 iteration: 14335 loss: 0.0073 lr: 0.02
2019-03-26 17:16:03 iteration: 14340 loss: 0.0064 lr: 0.02
2019-03-26 17:17:22 iteration: 14345 loss: 0.0050 lr: 0.02
2019-03-26 17:17:33 iteration: 14350 loss: 0.0057 lr: 0.02
2019-03-26 17:18:33 iteration: 14355 loss: 0.0042 lr: 0.02
2019-03-26 17:19:29 iteration: 14360 loss: 0.0040 lr: 0.02
2019-03-26 17:20:14 iteration: 14365 loss: 0.0054 lr: 0.02
2019-03-26 17:21:33 iteration: 14370 loss: 0.0037 lr: 0.02
2019-03-26 17:21:53 iteration: 14375 loss: 0.0081 lr: 0.02
2019-03-26 17:22:46 iteration: 14380 loss: 0.0039 lr: 0.02
2019-03-26 17:23:11 iteration: 14385 loss: 0.0054 lr: 0.02
2019-03-26 17:23:51 iteration: 14390 loss: 0.0045 lr: 0.02
2019-03-26 17:24:12 iteration: 14395 loss: 0.0069 lr: 0.02
2019-03-26 17:25:04 iteration: 14400 loss: 0.0053 lr: 0.02
2019-03-26 17:25:39 iteration: 14405 loss: 0.0051 lr: 0.02
2019-03-26 17:26:03 iteration: 14410 loss: 0.0047 lr: 0.02
2019-03-26 17:26:39 iteration: 14415 loss: 0.0082 lr: 0.02
2019-03-26 17:28:03 iteration: 14420 loss: 0.0041 lr: 0.02
2019-03-26 17:28:17 iteration: 14425 loss: 0.0074 lr: 0.02
2019-03-26 17:28:32 iteration: 14430 loss: 0.0043 lr: 0.02
2019-03-26 17:29:14 iteration: 14435 loss: 0.0050 lr: 0.02
2019-03-26 17:29:41 iteration: 14440 loss: 0.0041 lr: 0.02
2019-03-26 17:29:56 iteration: 14445 loss: 0.0060 lr: 0.02
2019-03-26 17:30:35 iteration: 14450 loss: 0.0084 lr: 0.02
2019-03-26 17:30:59 iteration: 14455 loss: 0.0072 lr: 0.02
2019-03-26 17:31:31 iteration: 14460 loss: 0.0055 lr: 0.02
2019-03-26 17:32:50 iteration: 14465 loss: 0.0046 lr: 0.02
2019-03-26 17:33:19 iteration: 14470 loss: 0.0059 lr: 0.02
2019-03-26 17:33:47 iteration: 14475 loss: 0.0037 lr: 0.02
2019-03-26 17:34:24 iteration: 14480 loss: 0.0053 lr: 0.02
2019-03-26 17:34:40 iteration: 14485 loss: 0.0051 lr: 0.02
2019-03-26 17:35:39 iteration: 14490 loss: 0.0050 lr: 0.02
2019-03-26 17:35:59 iteration: 14495 loss: 0.0078 lr: 0.02
2019-03-26 17:36:31 iteration: 14500 loss: 0.0041 lr: 0.02
2019-03-26 17:37:01 iteration: 14505 loss: 0.0058 lr: 0.02
2019-03-26 17:37:26 iteration: 14510 loss: 0.0047 lr: 0.02
2019-03-26 17:38:26 iteration: 14515 loss: 0.0038 lr: 0.02
2019-03-26 17:39:35 iteration: 14520 loss: 0.0039 lr: 0.02
2019-03-26 17:40:14 iteration: 14525 loss: 0.0048 lr: 0.02
2019-03-26 17:40:24 iteration: 14530 loss: 0.0067 lr: 0.02
2019-03-26 17:41:51 iteration: 14535 loss: 0.0048 lr: 0.02
2019-03-26 17:42:13 iteration: 14540 loss: 0.0065 lr: 0.02
2019-03-26 17:42:52 iteration: 14545 loss: 0.0055 lr: 0.02
2019-03-26 17:43:47 iteration: 14550 loss: 0.0066 lr: 0.02
2019-03-26 17:45:16 iteration: 14555 loss: 0.0048 lr: 0.02
2019-03-26 17:45:48 iteration: 14560 loss: 0.0062 lr: 0.02
2019-03-26 17:46:23 iteration: 14565 loss: 0.0050 lr: 0.02
2019-03-26 17:46:37 iteration: 14570 loss: 0.0057 lr: 0.02
2019-03-26 17:47:11 iteration: 14575 loss: 0.0076 lr: 0.02
2019-03-26 17:47:50 iteration: 14580 loss: 0.0050 lr: 0.02
2019-03-26 17:48:15 iteration: 14585 loss: 0.0049 lr: 0.02
2019-03-26 17:48:40 iteration: 14590 loss: 0.0048 lr: 0.02
2019-03-26 17:49:19 iteration: 14595 loss: 0.0046 lr: 0.02
2019-03-26 17:50:06 iteration: 14600 loss: 0.0041 lr: 0.02
2019-03-26 17:50:56 iteration: 14605 loss: 0.0076 lr: 0.02
2019-03-26 17:51:15 iteration: 14610 loss: 0.0060 lr: 0.02
2019-03-26 17:52:03 iteration: 14615 loss: 0.0054 lr: 0.02
2019-03-26 17:53:37 iteration: 14620 loss: 0.0069 lr: 0.02
2019-03-26 17:54:03 iteration: 14625 loss: 0.0046 lr: 0.02
2019-03-26 17:54:59 iteration: 14630 loss: 0.0062 lr: 0.02
2019-03-26 17:55:48 iteration: 14635 loss: 0.0052 lr: 0.02
2019-03-26 17:56:13 iteration: 14640 loss: 0.0070 lr: 0.02
2019-03-26 17:56:51 iteration: 14645 loss: 0.0044 lr: 0.02
2019-03-26 17:57:10 iteration: 14650 loss: 0.0058 lr: 0.02
2019-03-26 17:58:08 iteration: 14655 loss: 0.0063 lr: 0.02
2019-03-26 17:58:41 iteration: 14660 loss: 0.0041 lr: 0.02
2019-03-26 17:59:03 iteration: 14665 loss: 0.0042 lr: 0.02
2019-03-26 17:59:18 iteration: 14670 loss: 0.0052 lr: 0.02
2019-03-26 18:00:19 iteration: 14675 loss: 0.0039 lr: 0.02
2019-03-26 18:00:38 iteration: 14680 loss: 0.0066 lr: 0.02
2019-03-26 18:01:05 iteration: 14685 loss: 0.0041 lr: 0.02
2019-03-26 18:01:21 iteration: 14690 loss: 0.0054 lr: 0.02
2019-03-26 18:02:05 iteration: 14695 loss: 0.0047 lr: 0.02
2019-03-26 18:02:29 iteration: 14700 loss: 0.0050 lr: 0.02
2019-03-26 18:02:57 iteration: 14705 loss: 0.0059 lr: 0.02
2019-03-26 18:04:12 iteration: 14710 loss: 0.0065 lr: 0.02
2019-03-26 18:04:27 iteration: 14715 loss: 0.0064 lr: 0.02
2019-03-26 18:05:51 iteration: 14720 loss: 0.0047 lr: 0.02
2019-03-26 18:06:44 iteration: 14725 loss: 0.0047 lr: 0.02
2019-03-26 18:07:30 iteration: 14730 loss: 0.0068 lr: 0.02
2019-03-26 18:09:15 iteration: 14735 loss: 0.0043 lr: 0.02
2019-03-26 18:11:03 iteration: 14740 loss: 0.0043 lr: 0.02
2019-03-26 18:11:50 iteration: 14745 loss: 0.0052 lr: 0.02
2019-03-26 18:12:26 iteration: 14750 loss: 0.0041 lr: 0.02
2019-03-26 18:13:28 iteration: 14755 loss: 0.0037 lr: 0.02
2019-03-26 18:14:19 iteration: 14760 loss: 0.0099 lr: 0.02
2019-03-26 18:14:46 iteration: 14765 loss: 0.0067 lr: 0.02
2019-03-26 18:15:03 iteration: 14770 loss: 0.0059 lr: 0.02
2019-03-26 18:15:23 iteration: 14775 loss: 0.0052 lr: 0.02
2019-03-26 18:16:23 iteration: 14780 loss: 0.0049 lr: 0.02
2019-03-26 18:16:39 iteration: 14785 loss: 0.0053 lr: 0.02
2019-03-26 18:17:31 iteration: 14790 loss: 0.0044 lr: 0.02
2019-03-26 18:17:45 iteration: 14795 loss: 0.0056 lr: 0.02
2019-03-26 18:18:04 iteration: 14800 loss: 0.0071 lr: 0.02
2019-03-26 18:18:59 iteration: 14805 loss: 0.0042 lr: 0.02
2019-03-26 18:19:12 iteration: 14810 loss: 0.0067 lr: 0.02
2019-03-26 18:19:29 iteration: 14815 loss: 0.0073 lr: 0.02
2019-03-26 18:20:14 iteration: 14820 loss: 0.0065 lr: 0.02
2019-03-26 18:20:32 iteration: 14825 loss: 0.0045 lr: 0.02
2019-03-26 18:21:19 iteration: 14830 loss: 0.0046 lr: 0.02
2019-03-26 18:22:31 iteration: 14835 loss: 0.0044 lr: 0.02
2019-03-26 18:22:46 iteration: 14840 loss: 0.0069 lr: 0.02
2019-03-26 18:23:25 iteration: 14845 loss: 0.0050 lr: 0.02
2019-03-26 18:24:07 iteration: 14850 loss: 0.0044 lr: 0.02
2019-03-26 18:24:21 iteration: 14855 loss: 0.0055 lr: 0.02
2019-03-26 18:25:17 iteration: 14860 loss: 0.0071 lr: 0.02
2019-03-26 18:26:01 iteration: 14865 loss: 0.0083 lr: 0.02
2019-03-26 18:26:23 iteration: 14870 loss: 0.0049 lr: 0.02
2019-03-26 18:27:38 iteration: 14875 loss: 0.0049 lr: 0.02
2019-03-26 18:28:22 iteration: 14880 loss: 0.0050 lr: 0.02
2019-03-26 18:29:30 iteration: 14885 loss: 0.0046 lr: 0.02
2019-03-26 18:30:17 iteration: 14890 loss: 0.0035 lr: 0.02
2019-03-26 18:30:33 iteration: 14895 loss: 0.0039 lr: 0.02
2019-03-26 18:31:20 iteration: 14900 loss: 0.0060 lr: 0.02
2019-03-26 18:31:52 iteration: 14905 loss: 0.0063 lr: 0.02
2019-03-26 18:32:27 iteration: 14910 loss: 0.0052 lr: 0.02
2019-03-26 18:32:48 iteration: 14915 loss: 0.0100 lr: 0.02
2019-03-26 18:33:14 iteration: 14920 loss: 0.0055 lr: 0.02
2019-03-26 18:33:57 iteration: 14925 loss: 0.0037 lr: 0.02
2019-03-26 18:34:49 iteration: 14930 loss: 0.0046 lr: 0.02
2019-03-26 18:37:21 iteration: 14935 loss: 0.0043 lr: 0.02
2019-03-26 18:37:51 iteration: 14940 loss: 0.0052 lr: 0.02
2019-03-26 18:38:47 iteration: 14945 loss: 0.0060 lr: 0.02
2019-03-26 18:39:20 iteration: 14950 loss: 0.0074 lr: 0.02
2019-03-26 18:40:11 iteration: 14955 loss: 0.0051 lr: 0.02
2019-03-26 18:40:48 iteration: 14960 loss: 0.0052 lr: 0.02
2019-03-26 18:41:08 iteration: 14965 loss: 0.0054 lr: 0.02
2019-03-26 18:42:32 iteration: 14970 loss: 0.0056 lr: 0.02
2019-03-26 18:42:45 iteration: 14975 loss: 0.0059 lr: 0.02
2019-03-26 18:43:43 iteration: 14980 loss: 0.0067 lr: 0.02
2019-03-26 18:43:59 iteration: 14985 loss: 0.0069 lr: 0.02
2019-03-26 18:45:10 iteration: 14990 loss: 0.0059 lr: 0.02
2019-03-26 18:45:53 iteration: 14995 loss: 0.0053 lr: 0.02
2019-03-26 18:46:18 iteration: 15000 loss: 0.0061 lr: 0.02
2019-03-26 18:47:44 iteration: 15005 loss: 0.0063 lr: 0.02
2019-03-26 18:48:07 iteration: 15010 loss: 0.0056 lr: 0.02
2019-03-26 18:48:57 iteration: 15015 loss: 0.0065 lr: 0.02
2019-03-26 18:49:38 iteration: 15020 loss: 0.0053 lr: 0.02
2019-03-26 18:50:06 iteration: 15025 loss: 0.0054 lr: 0.02
2019-03-26 18:50:20 iteration: 15030 loss: 0.0076 lr: 0.02
2019-03-26 18:50:46 iteration: 15035 loss: 0.0049 lr: 0.02
2019-03-26 18:51:15 iteration: 15040 loss: 0.0054 lr: 0.02
2019-03-26 18:51:34 iteration: 15045 loss: 0.0061 lr: 0.02
2019-03-26 18:53:03 iteration: 15050 loss: 0.0058 lr: 0.02
2019-03-26 18:53:18 iteration: 15055 loss: 0.0062 lr: 0.02
2019-03-26 18:54:01 iteration: 15060 loss: 0.0043 lr: 0.02
2019-03-26 18:54:35 iteration: 15065 loss: 0.0055 lr: 0.02
2019-03-26 18:54:56 iteration: 15070 loss: 0.0066 lr: 0.02
2019-03-26 18:55:08 iteration: 15075 loss: 0.0046 lr: 0.02
2019-03-26 18:55:36 iteration: 15080 loss: 0.0045 lr: 0.02
2019-03-26 18:56:45 iteration: 15085 loss: 0.0048 lr: 0.02
2019-03-26 18:57:34 iteration: 15090 loss: 0.0053 lr: 0.02
2019-03-26 18:57:45 iteration: 15095 loss: 0.0071 lr: 0.02
2019-03-26 18:58:31 iteration: 15100 loss: 0.0054 lr: 0.02
2019-03-26 18:58:47 iteration: 15105 loss: 0.0073 lr: 0.02
2019-03-26 18:59:05 iteration: 15110 loss: 0.0052 lr: 0.02
2019-03-26 18:59:22 iteration: 15115 loss: 0.0048 lr: 0.02
2019-03-26 18:59:35 iteration: 15120 loss: 0.0066 lr: 0.02
2019-03-26 19:00:36 iteration: 15125 loss: 0.0053 lr: 0.02
2019-03-26 19:01:37 iteration: 15130 loss: 0.0084 lr: 0.02
2019-03-26 19:02:25 iteration: 15135 loss: 0.0050 lr: 0.02
2019-03-26 19:03:13 iteration: 15140 loss: 0.0067 lr: 0.02
2019-03-26 19:04:02 iteration: 15145 loss: 0.0079 lr: 0.02
2019-03-26 19:04:16 iteration: 15150 loss: 0.0050 lr: 0.02
2019-03-26 19:04:34 iteration: 15155 loss: 0.0063 lr: 0.02
2019-03-26 19:05:17 iteration: 15160 loss: 0.0053 lr: 0.02
2019-03-26 19:05:33 iteration: 15165 loss: 0.0048 lr: 0.02
2019-03-26 19:05:58 iteration: 15170 loss: 0.0062 lr: 0.02
2019-03-26 19:06:54 iteration: 15175 loss: 0.0063 lr: 0.02
2019-03-26 19:08:22 iteration: 15180 loss: 0.0033 lr: 0.02
2019-03-26 19:09:04 iteration: 15185 loss: 0.0048 lr: 0.02
2019-03-26 19:09:46 iteration: 15190 loss: 0.0046 lr: 0.02
2019-03-26 19:10:38 iteration: 15195 loss: 0.0037 lr: 0.02
2019-03-26 19:12:14 iteration: 15200 loss: 0.0040 lr: 0.02
2019-03-26 19:12:59 iteration: 15205 loss: 0.0061 lr: 0.02
2019-03-26 19:13:19 iteration: 15210 loss: 0.0064 lr: 0.02
2019-03-26 19:13:33 iteration: 15215 loss: 0.0081 lr: 0.02
2019-03-26 19:14:22 iteration: 15220 loss: 0.0050 lr: 0.02
2019-03-26 19:15:09 iteration: 15225 loss: 0.0041 lr: 0.02
2019-03-26 19:15:54 iteration: 15230 loss: 0.0054 lr: 0.02
2019-03-26 19:16:56 iteration: 15235 loss: 0.0077 lr: 0.02
2019-03-26 19:17:15 iteration: 15240 loss: 0.0055 lr: 0.02
2019-03-26 19:17:47 iteration: 15245 loss: 0.0048 lr: 0.02
2019-03-26 19:18:12 iteration: 15250 loss: 0.0054 lr: 0.02
2019-03-26 19:18:54 iteration: 15255 loss: 0.0061 lr: 0.02
2019-03-26 19:19:49 iteration: 15260 loss: 0.0055 lr: 0.02
2019-03-26 19:20:23 iteration: 15265 loss: 0.0076 lr: 0.02
2019-03-26 19:20:59 iteration: 15270 loss: 0.0055 lr: 0.02
2019-03-26 19:21:46 iteration: 15275 loss: 0.0045 lr: 0.02
2019-03-26 19:22:30 iteration: 15280 loss: 0.0052 lr: 0.02
2019-03-26 19:22:45 iteration: 15285 loss: 0.0058 lr: 0.02
2019-03-26 19:23:40 iteration: 15290 loss: 0.0047 lr: 0.02
2019-03-26 19:24:13 iteration: 15295 loss: 0.0054 lr: 0.02
2019-03-26 19:25:11 iteration: 15300 loss: 0.0074 lr: 0.02
2019-03-26 19:25:31 iteration: 15305 loss: 0.0056 lr: 0.02
2019-03-26 19:25:52 iteration: 15310 loss: 0.0068 lr: 0.02
2019-03-26 19:26:05 iteration: 15315 loss: 0.0057 lr: 0.02
2019-03-26 19:27:43 iteration: 15320 loss: 0.0039 lr: 0.02
2019-03-26 19:28:15 iteration: 15325 loss: 0.0057 lr: 0.02
2019-03-26 19:28:50 iteration: 15330 loss: 0.0084 lr: 0.02
2019-03-26 19:29:03 iteration: 15335 loss: 0.0050 lr: 0.02
2019-03-26 19:30:07 iteration: 15340 loss: 0.0058 lr: 0.02
2019-03-26 19:30:36 iteration: 15345 loss: 0.0048 lr: 0.02
2019-03-26 19:31:11 iteration: 15350 loss: 0.0044 lr: 0.02
2019-03-26 19:31:34 iteration: 15355 loss: 0.0050 lr: 0.02
2019-03-26 19:31:49 iteration: 15360 loss: 0.0073 lr: 0.02
2019-03-26 19:32:47 iteration: 15365 loss: 0.0043 lr: 0.02
2019-03-26 19:34:01 iteration: 15370 loss: 0.0042 lr: 0.02
2019-03-26 19:35:22 iteration: 15375 loss: 0.0049 lr: 0.02
2019-03-26 19:35:59 iteration: 15380 loss: 0.0037 lr: 0.02
2019-03-26 19:36:40 iteration: 15385 loss: 0.0045 lr: 0.02
2019-03-26 19:36:53 iteration: 15390 loss: 0.0062 lr: 0.02
2019-03-26 19:37:55 iteration: 15395 loss: 0.0075 lr: 0.02
2019-03-26 19:39:12 iteration: 15400 loss: 0.0034 lr: 0.02
2019-03-26 19:39:27 iteration: 15405 loss: 0.0058 lr: 0.02
2019-03-26 19:39:45 iteration: 15410 loss: 0.0054 lr: 0.02
2019-03-26 19:40:24 iteration: 15415 loss: 0.0041 lr: 0.02
2019-03-26 19:41:00 iteration: 15420 loss: 0.0041 lr: 0.02
2019-03-26 19:41:52 iteration: 15425 loss: 0.0061 lr: 0.02
2019-03-26 19:42:39 iteration: 15430 loss: 0.0045 lr: 0.02
2019-03-26 19:42:56 iteration: 15435 loss: 0.0043 lr: 0.02
2019-03-26 19:44:00 iteration: 15440 loss: 0.0037 lr: 0.02
2019-03-26 19:44:39 iteration: 15445 loss: 0.0043 lr: 0.02
2019-03-26 19:45:06 iteration: 15450 loss: 0.0056 lr: 0.02
2019-03-26 19:46:47 iteration: 15455 loss: 0.0045 lr: 0.02
2019-03-26 19:47:18 iteration: 15460 loss: 0.0047 lr: 0.02
2019-03-26 19:48:01 iteration: 15465 loss: 0.0041 lr: 0.02
2019-03-26 19:48:45 iteration: 15470 loss: 0.0044 lr: 0.02
2019-03-26 19:49:19 iteration: 15475 loss: 0.0065 lr: 0.02
2019-03-26 19:50:24 iteration: 15480 loss: 0.0050 lr: 0.02
2019-03-26 19:50:42 iteration: 15485 loss: 0.0047 lr: 0.02
2019-03-26 19:51:19 iteration: 15490 loss: 0.0045 lr: 0.02
2019-03-26 19:52:09 iteration: 15495 loss: 0.0046 lr: 0.02
2019-03-26 19:53:11 iteration: 15500 loss: 0.0040 lr: 0.02
2019-03-26 19:53:49 iteration: 15505 loss: 0.0054 lr: 0.02
2019-03-26 19:54:13 iteration: 15510 loss: 0.0051 lr: 0.02
2019-03-26 19:54:52 iteration: 15515 loss: 0.0050 lr: 0.02
2019-03-26 19:55:41 iteration: 15520 loss: 0.0054 lr: 0.02
2019-03-26 19:56:04 iteration: 15525 loss: 0.0063 lr: 0.02
2019-03-26 19:56:46 iteration: 15530 loss: 0.0068 lr: 0.02
2019-03-26 19:58:06 iteration: 15535 loss: 0.0042 lr: 0.02
2019-03-26 19:59:38 iteration: 15540 loss: 0.0051 lr: 0.02
2019-03-26 20:00:19 iteration: 15545 loss: 0.0044 lr: 0.02
2019-03-26 20:01:19 iteration: 15550 loss: 0.0051 lr: 0.02
2019-03-26 20:01:53 iteration: 15555 loss: 0.0050 lr: 0.02
2019-03-26 20:02:05 iteration: 15560 loss: 0.0054 lr: 0.02
2019-03-26 20:02:38 iteration: 15565 loss: 0.0043 lr: 0.02
2019-03-26 20:03:33 iteration: 15570 loss: 0.0040 lr: 0.02
2019-03-26 20:04:40 iteration: 15575 loss: 0.0076 lr: 0.02
2019-03-26 20:05:06 iteration: 15580 loss: 0.0047 lr: 0.02
2019-03-26 20:06:08 iteration: 15585 loss: 0.0056 lr: 0.02
2019-03-26 20:07:34 iteration: 15590 loss: 0.0060 lr: 0.02
2019-03-26 20:08:26 iteration: 15595 loss: 0.0053 lr: 0.02
2019-03-26 20:09:44 iteration: 15600 loss: 0.0044 lr: 0.02
2019-03-26 20:10:34 iteration: 15605 loss: 0.0045 lr: 0.02
2019-03-26 20:10:54 iteration: 15610 loss: 0.0047 lr: 0.02
2019-03-26 20:11:10 iteration: 15615 loss: 0.0070 lr: 0.02
2019-03-26 20:11:49 iteration: 15620 loss: 0.0071 lr: 0.02
2019-03-26 20:12:18 iteration: 15625 loss: 0.0050 lr: 0.02
2019-03-26 20:13:16 iteration: 15630 loss: 0.0056 lr: 0.02
2019-03-26 20:13:49 iteration: 15635 loss: 0.0058 lr: 0.02
2019-03-26 20:14:28 iteration: 15640 loss: 0.0065 lr: 0.02
2019-03-26 20:14:44 iteration: 15645 loss: 0.0057 lr: 0.02
2019-03-26 20:15:38 iteration: 15650 loss: 0.0057 lr: 0.02
2019-03-26 20:16:02 iteration: 15655 loss: 0.0062 lr: 0.02
2019-03-26 20:16:28 iteration: 15660 loss: 0.0049 lr: 0.02
2019-03-26 20:16:49 iteration: 15665 loss: 0.0064 lr: 0.02
2019-03-26 20:17:10 iteration: 15670 loss: 0.0053 lr: 0.02
2019-03-26 20:17:48 iteration: 15675 loss: 0.0051 lr: 0.02
2019-03-26 20:18:56 iteration: 15680 loss: 0.0045 lr: 0.02
2019-03-26 20:19:47 iteration: 15685 loss: 0.0057 lr: 0.02
2019-03-26 20:20:05 iteration: 15690 loss: 0.0073 lr: 0.02
2019-03-26 20:20:37 iteration: 15695 loss: 0.0049 lr: 0.02
2019-03-26 20:21:15 iteration: 15700 loss: 0.0070 lr: 0.02
2019-03-26 20:21:31 iteration: 15705 loss: 0.0047 lr: 0.02
2019-03-26 20:22:27 iteration: 15710 loss: 0.0047 lr: 0.02
2019-03-26 20:23:17 iteration: 15715 loss: 0.0058 lr: 0.02
2019-03-26 20:24:42 iteration: 15720 loss: 0.0043 lr: 0.02
2019-03-26 20:26:05 iteration: 15725 loss: 0.0039 lr: 0.02
2019-03-26 20:26:24 iteration: 15730 loss: 0.0067 lr: 0.02
2019-03-26 20:26:52 iteration: 15735 loss: 0.0050 lr: 0.02
2019-03-26 20:27:23 iteration: 15740 loss: 0.0038 lr: 0.02
2019-03-26 20:27:42 iteration: 15745 loss: 0.0044 lr: 0.02
2019-03-26 20:28:22 iteration: 15750 loss: 0.0045 lr: 0.02
2019-03-26 20:28:37 iteration: 15755 loss: 0.0061 lr: 0.02
2019-03-26 20:28:55 iteration: 15760 loss: 0.0067 lr: 0.02
2019-03-26 20:29:09 iteration: 15765 loss: 0.0083 lr: 0.02
2019-03-26 20:29:29 iteration: 15770 loss: 0.0060 lr: 0.02
2019-03-26 20:30:03 iteration: 15775 loss: 0.0056 lr: 0.02
2019-03-26 20:30:22 iteration: 15780 loss: 0.0072 lr: 0.02
2019-03-26 20:30:57 iteration: 15785 loss: 0.0035 lr: 0.02
2019-03-26 20:31:48 iteration: 15790 loss: 0.0050 lr: 0.02
2019-03-26 20:32:12 iteration: 15795 loss: 0.0050 lr: 0.02
2019-03-26 20:32:39 iteration: 15800 loss: 0.0063 lr: 0.02
2019-03-26 20:33:39 iteration: 15805 loss: 0.0042 lr: 0.02
2019-03-26 20:34:07 iteration: 15810 loss: 0.0082 lr: 0.02
2019-03-26 20:34:41 iteration: 15815 loss: 0.0052 lr: 0.02
2019-03-26 20:35:15 iteration: 15820 loss: 0.0048 lr: 0.02
2019-03-26 20:35:47 iteration: 15825 loss: 0.0048 lr: 0.02
2019-03-26 20:36:25 iteration: 15830 loss: 0.0080 lr: 0.02
2019-03-26 20:37:08 iteration: 15835 loss: 0.0040 lr: 0.02
2019-03-26 20:37:31 iteration: 15840 loss: 0.0067 lr: 0.02
2019-03-26 20:37:49 iteration: 15845 loss: 0.0046 lr: 0.02
2019-03-26 20:38:13 iteration: 15850 loss: 0.0071 lr: 0.02
2019-03-26 20:38:26 iteration: 15855 loss: 0.0063 lr: 0.02
2019-03-26 20:39:03 iteration: 15860 loss: 0.0038 lr: 0.02
2019-03-26 20:40:11 iteration: 15865 loss: 0.0062 lr: 0.02
2019-03-26 20:41:37 iteration: 15870 loss: 0.0036 lr: 0.02
2019-03-26 20:41:53 iteration: 15875 loss: 0.0072 lr: 0.02
2019-03-26 20:42:30 iteration: 15880 loss: 0.0057 lr: 0.02
2019-03-26 20:43:04 iteration: 15885 loss: 0.0059 lr: 0.02
2019-03-26 20:43:52 iteration: 15890 loss: 0.0049 lr: 0.02
2019-03-26 20:44:27 iteration: 15895 loss: 0.0097 lr: 0.02
2019-03-26 20:44:44 iteration: 15900 loss: 0.0054 lr: 0.02
2019-03-26 20:45:04 iteration: 15905 loss: 0.0063 lr: 0.02
2019-03-26 20:46:17 iteration: 15910 loss: 0.0044 lr: 0.02
2019-03-26 20:47:08 iteration: 15915 loss: 0.0074 lr: 0.02
2019-03-26 20:48:24 iteration: 15920 loss: 0.0031 lr: 0.02
2019-03-26 20:49:39 iteration: 15925 loss: 0.0031 lr: 0.02
2019-03-26 20:50:21 iteration: 15930 loss: 0.0040 lr: 0.02
2019-03-26 20:50:51 iteration: 15935 loss: 0.0055 lr: 0.02
2019-03-26 20:51:13 iteration: 15940 loss: 0.0045 lr: 0.02
2019-03-26 20:52:04 iteration: 15945 loss: 0.0046 lr: 0.02
2019-03-26 20:52:23 iteration: 15950 loss: 0.0055 lr: 0.02
2019-03-26 20:52:56 iteration: 15955 loss: 0.0044 lr: 0.02
2019-03-26 20:53:24 iteration: 15960 loss: 0.0082 lr: 0.02
2019-03-26 20:54:16 iteration: 15965 loss: 0.0051 lr: 0.02
2019-03-26 20:55:22 iteration: 15970 loss: 0.0056 lr: 0.02
2019-03-26 20:56:12 iteration: 15975 loss: 0.0051 lr: 0.02
2019-03-26 20:56:59 iteration: 15980 loss: 0.0041 lr: 0.02
2019-03-26 20:58:03 iteration: 15985 loss: 0.0044 lr: 0.02
2019-03-26 20:58:13 iteration: 15990 loss: 0.0046 lr: 0.02
2019-03-26 20:58:54 iteration: 15995 loss: 0.0041 lr: 0.02
2019-03-26 20:59:11 iteration: 16000 loss: 0.0052 lr: 0.02
2019-03-26 20:59:28 iteration: 16005 loss: 0.0069 lr: 0.02
2019-03-26 20:59:48 iteration: 16010 loss: 0.0066 lr: 0.02
2019-03-26 21:00:11 iteration: 16015 loss: 0.0055 lr: 0.02
2019-03-26 21:01:10 iteration: 16020 loss: 0.0053 lr: 0.02
2019-03-26 21:02:02 iteration: 16025 loss: 0.0051 lr: 0.02
2019-03-26 21:02:36 iteration: 16030 loss: 0.0059 lr: 0.02
2019-03-26 21:02:51 iteration: 16035 loss: 0.0054 lr: 0.02
2019-03-26 21:03:08 iteration: 16040 loss: 0.0048 lr: 0.02
2019-03-26 21:03:20 iteration: 16045 loss: 0.0057 lr: 0.02
2019-03-26 21:04:39 iteration: 16050 loss: 0.0056 lr: 0.02
2019-03-26 21:05:11 iteration: 16055 loss: 0.0047 lr: 0.02
2019-03-26 21:06:23 iteration: 16060 loss: 0.0042 lr: 0.02
2019-03-26 21:07:10 iteration: 16065 loss: 0.0069 lr: 0.02
2019-03-26 21:07:19 iteration: 16070 loss: 0.0052 lr: 0.02
2019-03-26 21:08:12 iteration: 16075 loss: 0.0054 lr: 0.02
2019-03-26 21:09:12 iteration: 16080 loss: 0.0045 lr: 0.02
2019-03-26 21:09:29 iteration: 16085 loss: 0.0048 lr: 0.02
2019-03-26 21:10:15 iteration: 16090 loss: 0.0054 lr: 0.02
2019-03-26 21:10:45 iteration: 16095 loss: 0.0042 lr: 0.02
2019-03-26 21:11:10 iteration: 16100 loss: 0.0052 lr: 0.02
2019-03-26 21:11:24 iteration: 16105 loss: 0.0065 lr: 0.02
2019-03-26 21:12:26 iteration: 16110 loss: 0.0039 lr: 0.02
2019-03-26 21:12:45 iteration: 16115 loss: 0.0053 lr: 0.02
2019-03-26 21:13:21 iteration: 16120 loss: 0.0053 lr: 0.02
2019-03-26 21:15:04 iteration: 16125 loss: 0.0060 lr: 0.02
2019-03-26 21:15:55 iteration: 16130 loss: 0.0040 lr: 0.02
2019-03-26 21:16:28 iteration: 16135 loss: 0.0064 lr: 0.02
2019-03-26 21:17:12 iteration: 16140 loss: 0.0057 lr: 0.02
2019-03-26 21:17:30 iteration: 16145 loss: 0.0056 lr: 0.02
2019-03-26 21:17:52 iteration: 16150 loss: 0.0041 lr: 0.02
2019-03-26 21:18:58 iteration: 16155 loss: 0.0054 lr: 0.02
2019-03-26 21:19:33 iteration: 16160 loss: 0.0058 lr: 0.02
2019-03-26 21:20:11 iteration: 16165 loss: 0.0049 lr: 0.02
2019-03-26 21:20:55 iteration: 16170 loss: 0.0043 lr: 0.02
2019-03-26 21:21:43 iteration: 16175 loss: 0.0045 lr: 0.02
2019-03-26 21:21:58 iteration: 16180 loss: 0.0048 lr: 0.02
2019-03-26 21:22:08 iteration: 16185 loss: 0.0043 lr: 0.02
2019-03-26 21:22:28 iteration: 16190 loss: 0.0074 lr: 0.02
2019-03-26 21:23:16 iteration: 16195 loss: 0.0065 lr: 0.02
2019-03-26 21:23:31 iteration: 16200 loss: 0.0063 lr: 0.02
2019-03-26 21:23:49 iteration: 16205 loss: 0.0057 lr: 0.02
2019-03-26 21:24:50 iteration: 16210 loss: 0.0041 lr: 0.02
2019-03-26 21:25:16 iteration: 16215 loss: 0.0052 lr: 0.02
2019-03-26 21:26:12 iteration: 16220 loss: 0.0047 lr: 0.02
2019-03-26 21:27:02 iteration: 16225 loss: 0.0058 lr: 0.02
2019-03-26 21:28:20 iteration: 16230 loss: 0.0036 lr: 0.02
2019-03-26 21:28:34 iteration: 16235 loss: 0.0046 lr: 0.02
2019-03-26 21:29:00 iteration: 16240 loss: 0.0056 lr: 0.02
2019-03-26 21:29:27 iteration: 16245 loss: 0.0065 lr: 0.02
2019-03-26 21:30:00 iteration: 16250 loss: 0.0061 lr: 0.02
2019-03-26 21:30:23 iteration: 16255 loss: 0.0043 lr: 0.02
2019-03-26 21:31:18 iteration: 16260 loss: 0.0041 lr: 0.02
2019-03-26 21:31:46 iteration: 16265 loss: 0.0065 lr: 0.02
2019-03-26 21:32:03 iteration: 16270 loss: 0.0057 lr: 0.02
2019-03-26 21:32:25 iteration: 16275 loss: 0.0063 lr: 0.02
2019-03-26 21:33:31 iteration: 16280 loss: 0.0036 lr: 0.02
2019-03-26 21:33:58 iteration: 16285 loss: 0.0047 lr: 0.02
2019-03-26 21:34:26 iteration: 16290 loss: 0.0044 lr: 0.02
2019-03-26 21:35:22 iteration: 16295 loss: 0.0040 lr: 0.02
2019-03-26 21:35:34 iteration: 16300 loss: 0.0048 lr: 0.02
2019-03-26 21:36:34 iteration: 16305 loss: 0.0044 lr: 0.02
2019-03-26 21:37:16 iteration: 16310 loss: 0.0039 lr: 0.02
2019-03-26 21:38:03 iteration: 16315 loss: 0.0050 lr: 0.02
2019-03-26 21:38:48 iteration: 16320 loss: 0.0040 lr: 0.02
2019-03-26 21:39:06 iteration: 16325 loss: 0.0051 lr: 0.02
2019-03-26 21:40:20 iteration: 16330 loss: 0.0028 lr: 0.02
2019-03-26 21:40:53 iteration: 16335 loss: 0.0038 lr: 0.02
2019-03-26 21:41:10 iteration: 16340 loss: 0.0077 lr: 0.02
2019-03-26 21:42:06 iteration: 16345 loss: 0.0037 lr: 0.02
2019-03-26 21:42:23 iteration: 16350 loss: 0.0066 lr: 0.02
2019-03-26 21:43:04 iteration: 16355 loss: 0.0042 lr: 0.02
2019-03-26 21:43:28 iteration: 16360 loss: 0.0061 lr: 0.02
2019-03-26 21:43:49 iteration: 16365 loss: 0.0045 lr: 0.02
2019-03-26 21:44:37 iteration: 16370 loss: 0.0031 lr: 0.02
2019-03-26 21:45:04 iteration: 16375 loss: 0.0048 lr: 0.02
2019-03-26 21:45:35 iteration: 16380 loss: 0.0050 lr: 0.02
2019-03-26 21:46:17 iteration: 16385 loss: 0.0040 lr: 0.02
2019-03-26 21:46:30 iteration: 16390 loss: 0.0100 lr: 0.02
2019-03-26 21:47:09 iteration: 16395 loss: 0.0044 lr: 0.02
2019-03-26 21:47:24 iteration: 16400 loss: 0.0056 lr: 0.02
2019-03-26 21:47:44 iteration: 16405 loss: 0.0061 lr: 0.02
2019-03-26 21:48:07 iteration: 16410 loss: 0.0041 lr: 0.02
2019-03-26 21:48:29 iteration: 16415 loss: 0.0059 lr: 0.02
2019-03-26 21:49:11 iteration: 16420 loss: 0.0054 lr: 0.02
2019-03-26 21:49:25 iteration: 16425 loss: 0.0076 lr: 0.02
2019-03-26 21:50:05 iteration: 16430 loss: 0.0042 lr: 0.02
2019-03-26 21:50:54 iteration: 16435 loss: 0.0062 lr: 0.02
2019-03-26 21:51:36 iteration: 16440 loss: 0.0068 lr: 0.02
2019-03-26 21:52:12 iteration: 16445 loss: 0.0050 lr: 0.02
2019-03-26 21:52:54 iteration: 16450 loss: 0.0038 lr: 0.02
2019-03-26 21:53:39 iteration: 16455 loss: 0.0038 lr: 0.02
2019-03-26 21:54:43 iteration: 16460 loss: 0.0053 lr: 0.02
2019-03-26 21:54:57 iteration: 16465 loss: 0.0066 lr: 0.02
2019-03-26 21:55:49 iteration: 16470 loss: 0.0050 lr: 0.02
2019-03-26 21:56:24 iteration: 16475 loss: 0.0038 lr: 0.02
2019-03-26 21:56:41 iteration: 16480 loss: 0.0045 lr: 0.02
2019-03-26 21:57:26 iteration: 16485 loss: 0.0051 lr: 0.02
2019-03-26 21:57:43 iteration: 16490 loss: 0.0045 lr: 0.02
2019-03-26 21:58:39 iteration: 16495 loss: 0.0037 lr: 0.02
2019-03-26 21:59:25 iteration: 16500 loss: 0.0051 lr: 0.02
2019-03-26 22:00:25 iteration: 16505 loss: 0.0047 lr: 0.02
2019-03-26 22:00:45 iteration: 16510 loss: 0.0056 lr: 0.02
2019-03-26 22:01:07 iteration: 16515 loss: 0.0052 lr: 0.02
2019-03-26 22:01:33 iteration: 16520 loss: 0.0059 lr: 0.02
2019-03-26 22:02:18 iteration: 16525 loss: 0.0043 lr: 0.02
2019-03-26 22:02:36 iteration: 16530 loss: 0.0050 lr: 0.02
2019-03-26 22:02:57 iteration: 16535 loss: 0.0057 lr: 0.02
2019-03-26 22:03:10 iteration: 16540 loss: 0.0051 lr: 0.02
2019-03-26 22:04:19 iteration: 16545 loss: 0.0049 lr: 0.02
2019-03-26 22:05:34 iteration: 16550 loss: 0.0056 lr: 0.02
2019-03-26 22:05:47 iteration: 16555 loss: 0.0070 lr: 0.02
2019-03-26 22:06:19 iteration: 16560 loss: 0.0045 lr: 0.02
2019-03-26 22:07:28 iteration: 16565 loss: 0.0042 lr: 0.02
2019-03-26 22:08:29 iteration: 16570 loss: 0.0052 lr: 0.02
2019-03-26 22:09:18 iteration: 16575 loss: 0.0057 lr: 0.02
2019-03-26 22:09:40 iteration: 16580 loss: 0.0044 lr: 0.02
2019-03-26 22:10:27 iteration: 16585 loss: 0.0061 lr: 0.02
2019-03-26 22:10:45 iteration: 16590 loss: 0.0044 lr: 0.02
2019-03-26 22:11:19 iteration: 16595 loss: 0.0045 lr: 0.02
2019-03-26 22:11:38 iteration: 16600 loss: 0.0080 lr: 0.02
2019-03-26 22:12:15 iteration: 16605 loss: 0.0055 lr: 0.02
2019-03-26 22:13:18 iteration: 16610 loss: 0.0045 lr: 0.02
2019-03-26 22:14:08 iteration: 16615 loss: 0.0048 lr: 0.02
2019-03-26 22:14:52 iteration: 16620 loss: 0.0051 lr: 0.02
2019-03-26 22:15:22 iteration: 16625 loss: 0.0055 lr: 0.02
2019-03-26 22:15:55 iteration: 16630 loss: 0.0042 lr: 0.02
2019-03-26 22:16:50 iteration: 16635 loss: 0.0054 lr: 0.02
2019-03-26 22:17:27 iteration: 16640 loss: 0.0054 lr: 0.02
2019-03-26 22:17:38 iteration: 16645 loss: 0.0064 lr: 0.02
2019-03-26 22:18:09 iteration: 16650 loss: 0.0054 lr: 0.02
2019-03-26 22:18:53 iteration: 16655 loss: 0.0058 lr: 0.02
2019-03-26 22:19:22 iteration: 16660 loss: 0.0049 lr: 0.02
2019-03-26 22:19:33 iteration: 16665 loss: 0.0052 lr: 0.02
2019-03-26 22:19:43 iteration: 16670 loss: 0.0090 lr: 0.02
2019-03-26 22:19:57 iteration: 16675 loss: 0.0048 lr: 0.02
2019-03-26 22:20:27 iteration: 16680 loss: 0.0060 lr: 0.02
2019-03-26 22:20:51 iteration: 16685 loss: 0.0054 lr: 0.02
2019-03-26 22:21:30 iteration: 16690 loss: 0.0046 lr: 0.02
2019-03-26 22:22:35 iteration: 16695 loss: 0.0043 lr: 0.02
2019-03-26 22:23:36 iteration: 16700 loss: 0.0039 lr: 0.02
2019-03-26 22:23:54 iteration: 16705 loss: 0.0052 lr: 0.02
2019-03-26 22:24:28 iteration: 16710 loss: 0.0048 lr: 0.02
2019-03-26 22:25:08 iteration: 16715 loss: 0.0043 lr: 0.02
2019-03-26 22:26:25 iteration: 16720 loss: 0.0052 lr: 0.02
2019-03-26 22:27:16 iteration: 16725 loss: 0.0041 lr: 0.02
2019-03-26 22:27:33 iteration: 16730 loss: 0.0092 lr: 0.02
2019-03-26 22:27:50 iteration: 16735 loss: 0.0084 lr: 0.02
2019-03-26 22:28:37 iteration: 16740 loss: 0.0045 lr: 0.02
2019-03-26 22:29:25 iteration: 16745 loss: 0.0050 lr: 0.02
2019-03-26 22:29:54 iteration: 16750 loss: 0.0038 lr: 0.02
2019-03-26 22:30:36 iteration: 16755 loss: 0.0052 lr: 0.02
2019-03-26 22:30:51 iteration: 16760 loss: 0.0060 lr: 0.02
2019-03-26 22:31:09 iteration: 16765 loss: 0.0061 lr: 0.02
2019-03-26 22:31:28 iteration: 16770 loss: 0.0044 lr: 0.02
2019-03-26 22:32:19 iteration: 16775 loss: 0.0046 lr: 0.02
2019-03-26 22:34:15 iteration: 16780 loss: 0.0046 lr: 0.02
2019-03-26 22:34:30 iteration: 16785 loss: 0.0070 lr: 0.02
2019-03-26 22:34:41 iteration: 16790 loss: 0.0065 lr: 0.02
2019-03-26 22:36:25 iteration: 16795 loss: 0.0040 lr: 0.02
2019-03-26 22:37:15 iteration: 16800 loss: 0.0058 lr: 0.02
2019-03-26 22:38:08 iteration: 16805 loss: 0.0060 lr: 0.02
2019-03-26 22:39:12 iteration: 16810 loss: 0.0033 lr: 0.02
2019-03-26 22:39:47 iteration: 16815 loss: 0.0057 lr: 0.02
2019-03-26 22:40:05 iteration: 16820 loss: 0.0058 lr: 0.02
2019-03-26 22:40:35 iteration: 16825 loss: 0.0057 lr: 0.02
2019-03-26 22:40:52 iteration: 16830 loss: 0.0044 lr: 0.02
2019-03-26 22:41:54 iteration: 16835 loss: 0.0037 lr: 0.02
2019-03-26 22:42:19 iteration: 16840 loss: 0.0047 lr: 0.02
2019-03-26 22:42:57 iteration: 16845 loss: 0.0067 lr: 0.02
2019-03-26 22:43:14 iteration: 16850 loss: 0.0045 lr: 0.02
2019-03-26 22:44:38 iteration: 16855 loss: 0.0071 lr: 0.02
2019-03-26 22:44:56 iteration: 16860 loss: 0.0065 lr: 0.02
2019-03-26 22:45:53 iteration: 16865 loss: 0.0058 lr: 0.02
2019-03-26 22:46:12 iteration: 16870 loss: 0.0042 lr: 0.02
2019-03-26 22:47:36 iteration: 16875 loss: 0.0043 lr: 0.02
2019-03-26 22:47:48 iteration: 16880 loss: 0.0052 lr: 0.02
2019-03-26 22:48:18 iteration: 16885 loss: 0.0067 lr: 0.02
2019-03-26 22:49:54 iteration: 16890 loss: 0.0064 lr: 0.02
2019-03-26 22:50:15 iteration: 16895 loss: 0.0050 lr: 0.02
2019-03-26 22:50:54 iteration: 16900 loss: 0.0052 lr: 0.02
2019-03-26 22:51:36 iteration: 16905 loss: 0.0045 lr: 0.02
2019-03-26 22:52:17 iteration: 16910 loss: 0.0049 lr: 0.02
2019-03-26 22:52:35 iteration: 16915 loss: 0.0061 lr: 0.02
2019-03-26 22:53:14 iteration: 16920 loss: 0.0044 lr: 0.02
2019-03-26 22:54:03 iteration: 16925 loss: 0.0048 lr: 0.02
2019-03-26 22:54:24 iteration: 16930 loss: 0.0062 lr: 0.02
2019-03-26 22:55:46 iteration: 16935 loss: 0.0036 lr: 0.02
2019-03-26 22:56:22 iteration: 16940 loss: 0.0047 lr: 0.02
2019-03-26 22:57:11 iteration: 16945 loss: 0.0062 lr: 0.02
2019-03-26 22:58:23 iteration: 16950 loss: 0.0045 lr: 0.02
2019-03-26 22:59:02 iteration: 16955 loss: 0.0049 lr: 0.02
2019-03-26 22:59:19 iteration: 16960 loss: 0.0049 lr: 0.02
2019-03-26 22:59:34 iteration: 16965 loss: 0.0069 lr: 0.02
2019-03-26 22:59:49 iteration: 16970 loss: 0.0051 lr: 0.02
2019-03-26 23:00:30 iteration: 16975 loss: 0.0037 lr: 0.02
2019-03-26 23:01:36 iteration: 16980 loss: 0.0042 lr: 0.02
2019-03-26 23:02:48 iteration: 16985 loss: 0.0076 lr: 0.02
2019-03-26 23:04:20 iteration: 16990 loss: 0.0045 lr: 0.02
2019-03-26 23:05:35 iteration: 16995 loss: 0.0059 lr: 0.02
2019-03-26 23:06:10 iteration: 17000 loss: 0.0058 lr: 0.02
2019-03-26 23:06:56 iteration: 17005 loss: 0.0053 lr: 0.02
2019-03-26 23:07:43 iteration: 17010 loss: 0.0051 lr: 0.02
2019-03-26 23:08:48 iteration: 17015 loss: 0.0042 lr: 0.02
2019-03-26 23:09:09 iteration: 17020 loss: 0.0065 lr: 0.02
2019-03-26 23:09:28 iteration: 17025 loss: 0.0048 lr: 0.02
2019-03-26 23:10:09 iteration: 17030 loss: 0.0049 lr: 0.02
2019-03-26 23:11:01 iteration: 17035 loss: 0.0046 lr: 0.02
2019-03-26 23:12:03 iteration: 17040 loss: 0.0043 lr: 0.02
2019-03-26 23:12:40 iteration: 17045 loss: 0.0050 lr: 0.02
2019-03-26 23:13:08 iteration: 17050 loss: 0.0034 lr: 0.02
2019-03-26 23:13:21 iteration: 17055 loss: 0.0051 lr: 0.02
2019-03-26 23:13:38 iteration: 17060 loss: 0.0060 lr: 0.02
2019-03-26 23:14:31 iteration: 17065 loss: 0.0049 lr: 0.02
2019-03-26 23:15:30 iteration: 17070 loss: 0.0050 lr: 0.02
2019-03-26 23:15:58 iteration: 17075 loss: 0.0057 lr: 0.02
2019-03-26 23:16:58 iteration: 17080 loss: 0.0039 lr: 0.02
2019-03-26 23:17:23 iteration: 17085 loss: 0.0052 lr: 0.02
2019-03-26 23:17:38 iteration: 17090 loss: 0.0059 lr: 0.02
2019-03-26 23:17:59 iteration: 17095 loss: 0.0077 lr: 0.02
2019-03-26 23:18:52 iteration: 17100 loss: 0.0043 lr: 0.02
2019-03-26 23:19:22 iteration: 17105 loss: 0.0071 lr: 0.02
2019-03-26 23:19:45 iteration: 17110 loss: 0.0053 lr: 0.02
2019-03-26 23:20:21 iteration: 17115 loss: 0.0047 lr: 0.02
2019-03-26 23:21:11 iteration: 17120 loss: 0.0059 lr: 0.02
2019-03-26 23:21:34 iteration: 17125 loss: 0.0058 lr: 0.02
2019-03-26 23:22:20 iteration: 17130 loss: 0.0051 lr: 0.02
2019-03-26 23:22:33 iteration: 17135 loss: 0.0081 lr: 0.02
2019-03-26 23:22:52 iteration: 17140 loss: 0.0054 lr: 0.02
2019-03-26 23:23:38 iteration: 17145 loss: 0.0038 lr: 0.02
2019-03-26 23:24:13 iteration: 17150 loss: 0.0036 lr: 0.02
2019-03-26 23:25:06 iteration: 17155 loss: 0.0083 lr: 0.02
2019-03-26 23:26:35 iteration: 17160 loss: 0.0051 lr: 0.02
2019-03-26 23:27:29 iteration: 17165 loss: 0.0037 lr: 0.02
2019-03-26 23:28:28 iteration: 17170 loss: 0.0059 lr: 0.02
2019-03-26 23:28:50 iteration: 17175 loss: 0.0057 lr: 0.02
2019-03-26 23:29:41 iteration: 17180 loss: 0.0040 lr: 0.02
2019-03-26 23:29:58 iteration: 17185 loss: 0.0043 lr: 0.02
2019-03-26 23:30:27 iteration: 17190 loss: 0.0049 lr: 0.02
2019-03-26 23:31:05 iteration: 17195 loss: 0.0039 lr: 0.02
2019-03-26 23:31:29 iteration: 17200 loss: 0.0045 lr: 0.02
2019-03-26 23:31:49 iteration: 17205 loss: 0.0045 lr: 0.02
2019-03-26 23:32:57 iteration: 17210 loss: 0.0051 lr: 0.02
2019-03-26 23:33:35 iteration: 17215 loss: 0.0056 lr: 0.02
2019-03-26 23:33:51 iteration: 17220 loss: 0.0095 lr: 0.02
2019-03-26 23:34:29 iteration: 17225 loss: 0.0043 lr: 0.02
2019-03-26 23:34:40 iteration: 17230 loss: 0.0075 lr: 0.02
2019-03-26 23:35:28 iteration: 17235 loss: 0.0052 lr: 0.02
2019-03-26 23:36:18 iteration: 17240 loss: 0.0054 lr: 0.02
2019-03-26 23:36:46 iteration: 17245 loss: 0.0045 lr: 0.02
2019-03-26 23:37:08 iteration: 17250 loss: 0.0059 lr: 0.02
2019-03-26 23:37:55 iteration: 17255 loss: 0.0066 lr: 0.02
2019-03-26 23:38:25 iteration: 17260 loss: 0.0041 lr: 0.02
2019-03-26 23:38:42 iteration: 17265 loss: 0.0051 lr: 0.02
2019-03-26 23:39:05 iteration: 17270 loss: 0.0046 lr: 0.02
2019-03-26 23:40:12 iteration: 17275 loss: 0.0038 lr: 0.02
2019-03-26 23:41:21 iteration: 17280 loss: 0.0041 lr: 0.02
2019-03-26 23:42:14 iteration: 17285 loss: 0.0063 lr: 0.02
2019-03-26 23:43:01 iteration: 17290 loss: 0.0043 lr: 0.02
2019-03-26 23:44:22 iteration: 17295 loss: 0.0052 lr: 0.02
2019-03-26 23:45:10 iteration: 17300 loss: 0.0041 lr: 0.02
2019-03-26 23:45:47 iteration: 17305 loss: 0.0047 lr: 0.02
2019-03-26 23:46:10 iteration: 17310 loss: 0.0057 lr: 0.02
2019-03-26 23:46:42 iteration: 17315 loss: 0.0038 lr: 0.02
2019-03-26 23:47:51 iteration: 17320 loss: 0.0037 lr: 0.02
2019-03-26 23:49:13 iteration: 17325 loss: 0.0061 lr: 0.02
2019-03-26 23:49:30 iteration: 17330 loss: 0.0065 lr: 0.02
2019-03-26 23:50:13 iteration: 17335 loss: 0.0060 lr: 0.02
2019-03-26 23:50:25 iteration: 17340 loss: 0.0074 lr: 0.02
2019-03-26 23:50:50 iteration: 17345 loss: 0.0065 lr: 0.02
2019-03-26 23:51:13 iteration: 17350 loss: 0.0051 lr: 0.02
2019-03-26 23:51:53 iteration: 17355 loss: 0.0046 lr: 0.02
2019-03-26 23:53:06 iteration: 17360 loss: 0.0051 lr: 0.02
2019-03-26 23:53:16 iteration: 17365 loss: 0.0070 lr: 0.02
2019-03-26 23:54:12 iteration: 17370 loss: 0.0037 lr: 0.02
2019-03-26 23:54:34 iteration: 17375 loss: 0.0047 lr: 0.02
2019-03-26 23:55:31 iteration: 17380 loss: 0.0033 lr: 0.02
2019-03-26 23:55:53 iteration: 17385 loss: 0.0081 lr: 0.02
2019-03-26 23:56:26 iteration: 17390 loss: 0.0051 lr: 0.02
2019-03-26 23:58:11 iteration: 17395 loss: 0.0034 lr: 0.02
2019-03-26 23:58:59 iteration: 17400 loss: 0.0057 lr: 0.02
2019-03-26 23:59:49 iteration: 17405 loss: 0.0067 lr: 0.02
2019-03-27 00:01:15 iteration: 17410 loss: 0.0048 lr: 0.02
2019-03-27 00:02:25 iteration: 17415 loss: 0.0039 lr: 0.02
2019-03-27 00:02:58 iteration: 17420 loss: 0.0043 lr: 0.02
2019-03-27 00:03:15 iteration: 17425 loss: 0.0041 lr: 0.02
2019-03-27 00:04:12 iteration: 17430 loss: 0.0030 lr: 0.02
2019-03-27 00:04:44 iteration: 17435 loss: 0.0048 lr: 0.02
2019-03-27 00:05:25 iteration: 17440 loss: 0.0032 lr: 0.02
2019-03-27 00:05:41 iteration: 17445 loss: 0.0055 lr: 0.02
2019-03-27 00:06:02 iteration: 17450 loss: 0.0042 lr: 0.02
2019-03-27 00:06:14 iteration: 17455 loss: 0.0061 lr: 0.02
2019-03-27 00:07:38 iteration: 17460 loss: 0.0058 lr: 0.02
2019-03-27 00:08:07 iteration: 17465 loss: 0.0056 lr: 0.02
2019-03-27 00:08:53 iteration: 17470 loss: 0.0045 lr: 0.02
2019-03-27 00:09:51 iteration: 17475 loss: 0.0044 lr: 0.02
2019-03-27 00:10:18 iteration: 17480 loss: 0.0053 lr: 0.02
2019-03-27 00:10:28 iteration: 17485 loss: 0.0061 lr: 0.02
2019-03-27 00:11:33 iteration: 17490 loss: 0.0043 lr: 0.02
2019-03-27 00:12:07 iteration: 17495 loss: 0.0046 lr: 0.02
2019-03-27 00:12:46 iteration: 17500 loss: 0.0047 lr: 0.02
2019-03-27 00:13:54 iteration: 17505 loss: 0.0036 lr: 0.02
2019-03-27 00:15:12 iteration: 17510 loss: 0.0054 lr: 0.02
2019-03-27 00:16:46 iteration: 17515 loss: 0.0047 lr: 0.02
2019-03-27 00:16:57 iteration: 17520 loss: 0.0072 lr: 0.02
2019-03-27 00:17:32 iteration: 17525 loss: 0.0051 lr: 0.02
2019-03-27 00:18:23 iteration: 17530 loss: 0.0048 lr: 0.02
2019-03-27 00:18:38 iteration: 17535 loss: 0.0055 lr: 0.02
2019-03-27 00:20:22 iteration: 17540 loss: 0.0054 lr: 0.02
2019-03-27 00:21:09 iteration: 17545 loss: 0.0051 lr: 0.02
2019-03-27 00:22:08 iteration: 17550 loss: 0.0035 lr: 0.02
2019-03-27 00:22:32 iteration: 17555 loss: 0.0066 lr: 0.02
2019-03-27 00:23:50 iteration: 17560 loss: 0.0048 lr: 0.02
2019-03-27 00:24:03 iteration: 17565 loss: 0.0072 lr: 0.02
2019-03-27 00:24:25 iteration: 17570 loss: 0.0060 lr: 0.02
2019-03-27 00:24:55 iteration: 17575 loss: 0.0054 lr: 0.02
2019-03-27 00:25:31 iteration: 17580 loss: 0.0047 lr: 0.02
2019-03-27 00:26:18 iteration: 17585 loss: 0.0065 lr: 0.02
2019-03-27 00:26:48 iteration: 17590 loss: 0.0043 lr: 0.02
2019-03-27 00:27:17 iteration: 17595 loss: 0.0046 lr: 0.02
2019-03-27 00:28:41 iteration: 17600 loss: 0.0075 lr: 0.02
2019-03-27 00:29:20 iteration: 17605 loss: 0.0049 lr: 0.02
2019-03-27 00:30:25 iteration: 17610 loss: 0.0041 lr: 0.02
2019-03-27 00:30:57 iteration: 17615 loss: 0.0039 lr: 0.02
2019-03-27 00:31:11 iteration: 17620 loss: 0.0052 lr: 0.02
2019-03-27 00:32:10 iteration: 17625 loss: 0.0034 lr: 0.02
2019-03-27 00:33:02 iteration: 17630 loss: 0.0047 lr: 0.02
2019-03-27 00:34:59 iteration: 17635 loss: 0.0041 lr: 0.02
2019-03-27 00:35:25 iteration: 17640 loss: 0.0049 lr: 0.02
2019-03-27 00:36:16 iteration: 17645 loss: 0.0048 lr: 0.02
2019-03-27 00:36:54 iteration: 17650 loss: 0.0076 lr: 0.02
2019-03-27 00:38:23 iteration: 17655 loss: 0.0057 lr: 0.02
2019-03-27 00:40:14 iteration: 17660 loss: 0.0053 lr: 0.02
2019-03-27 00:40:47 iteration: 17665 loss: 0.0050 lr: 0.02
2019-03-27 00:41:47 iteration: 17670 loss: 0.0052 lr: 0.02
2019-03-27 00:42:09 iteration: 17675 loss: 0.0051 lr: 0.02
2019-03-27 00:42:26 iteration: 17680 loss: 0.0051 lr: 0.02
2019-03-27 00:43:08 iteration: 17685 loss: 0.0060 lr: 0.02
2019-03-27 00:44:23 iteration: 17690 loss: 0.0029 lr: 0.02
2019-03-27 00:45:18 iteration: 17695 loss: 0.0054 lr: 0.02
2019-03-27 00:46:29 iteration: 17700 loss: 0.0083 lr: 0.02
2019-03-27 00:47:32 iteration: 17705 loss: 0.0060 lr: 0.02
2019-03-27 00:49:23 iteration: 17710 loss: 0.0067 lr: 0.02
2019-03-27 00:49:43 iteration: 17715 loss: 0.0056 lr: 0.02
2019-03-27 00:49:57 iteration: 17720 loss: 0.0053 lr: 0.02
2019-03-27 00:50:54 iteration: 17725 loss: 0.0030 lr: 0.02
2019-03-27 00:51:33 iteration: 17730 loss: 0.0056 lr: 0.02
2019-03-27 00:52:36 iteration: 17735 loss: 0.0044 lr: 0.02
2019-03-27 00:54:02 iteration: 17740 loss: 0.0059 lr: 0.02
2019-03-27 00:54:15 iteration: 17745 loss: 0.0072 lr: 0.02
2019-03-27 00:54:34 iteration: 17750 loss: 0.0059 lr: 0.02
2019-03-27 00:56:08 iteration: 17755 loss: 0.0045 lr: 0.02
2019-03-27 00:56:24 iteration: 17760 loss: 0.0049 lr: 0.02
2019-03-27 00:56:36 iteration: 17765 loss: 0.0060 lr: 0.02
2019-03-27 00:56:58 iteration: 17770 loss: 0.0044 lr: 0.02
2019-03-27 00:58:16 iteration: 17775 loss: 0.0042 lr: 0.02
2019-03-27 00:58:52 iteration: 17780 loss: 0.0054 lr: 0.02
2019-03-27 00:59:12 iteration: 17785 loss: 0.0046 lr: 0.02
2019-03-27 00:59:34 iteration: 17790 loss: 0.0036 lr: 0.02
2019-03-27 01:00:36 iteration: 17795 loss: 0.0052 lr: 0.02
2019-03-27 01:01:25 iteration: 17800 loss: 0.0057 lr: 0.02
2019-03-27 01:01:56 iteration: 17805 loss: 0.0038 lr: 0.02
2019-03-27 01:02:36 iteration: 17810 loss: 0.0034 lr: 0.02
2019-03-27 01:02:53 iteration: 17815 loss: 0.0084 lr: 0.02
2019-03-27 01:03:43 iteration: 17820 loss: 0.0048 lr: 0.02
2019-03-27 01:04:20 iteration: 17825 loss: 0.0044 lr: 0.02
2019-03-27 01:04:50 iteration: 17830 loss: 0.0058 lr: 0.02
2019-03-27 01:05:10 iteration: 17835 loss: 0.0092 lr: 0.02
2019-03-27 01:05:47 iteration: 17840 loss: 0.0050 lr: 0.02
2019-03-27 01:06:07 iteration: 17845 loss: 0.0051 lr: 0.02
2019-03-27 01:06:19 iteration: 17850 loss: 0.0054 lr: 0.02
2019-03-27 01:06:49 iteration: 17855 loss: 0.0052 lr: 0.02
2019-03-27 01:07:41 iteration: 17860 loss: 0.0053 lr: 0.02
2019-03-27 01:08:08 iteration: 17865 loss: 0.0053 lr: 0.02
2019-03-27 01:08:40 iteration: 17870 loss: 0.0054 lr: 0.02
2019-03-27 01:09:24 iteration: 17875 loss: 0.0072 lr: 0.02
2019-03-27 01:09:41 iteration: 17880 loss: 0.0048 lr: 0.02
2019-03-27 01:10:12 iteration: 17885 loss: 0.0054 lr: 0.02
2019-03-27 01:10:42 iteration: 17890 loss: 0.0045 lr: 0.02
2019-03-27 01:11:46 iteration: 17895 loss: 0.0053 lr: 0.02
2019-03-27 01:12:33 iteration: 17900 loss: 0.0040 lr: 0.02
2019-03-27 01:13:14 iteration: 17905 loss: 0.0068 lr: 0.02
2019-03-27 01:13:55 iteration: 17910 loss: 0.0046 lr: 0.02
2019-03-27 01:14:20 iteration: 17915 loss: 0.0044 lr: 0.02
2019-03-27 01:14:53 iteration: 17920 loss: 0.0048 lr: 0.02
2019-03-27 01:15:41 iteration: 17925 loss: 0.0045 lr: 0.02
2019-03-27 01:16:02 iteration: 17930 loss: 0.0053 lr: 0.02
2019-03-27 01:16:16 iteration: 17935 loss: 0.0066 lr: 0.02
2019-03-27 01:16:31 iteration: 17940 loss: 0.0050 lr: 0.02
2019-03-27 01:17:20 iteration: 17945 loss: 0.0042 lr: 0.02
2019-03-27 01:17:37 iteration: 17950 loss: 0.0053 lr: 0.02
2019-03-27 01:18:00 iteration: 17955 loss: 0.0040 lr: 0.02
2019-03-27 01:18:14 iteration: 17960 loss: 0.0053 lr: 0.02
2019-03-27 01:18:27 iteration: 17965 loss: 0.0054 lr: 0.02
2019-03-27 01:19:10 iteration: 17970 loss: 0.0058 lr: 0.02
2019-03-27 01:20:00 iteration: 17975 loss: 0.0058 lr: 0.02
2019-03-27 01:20:13 iteration: 17980 loss: 0.0052 lr: 0.02
2019-03-27 01:20:59 iteration: 17985 loss: 0.0059 lr: 0.02
2019-03-27 01:21:55 iteration: 17990 loss: 0.0046 lr: 0.02
2019-03-27 01:23:07 iteration: 17995 loss: 0.0041 lr: 0.02
2019-03-27 01:23:26 iteration: 18000 loss: 0.0060 lr: 0.02
2019-03-27 01:24:28 iteration: 18005 loss: 0.0049 lr: 0.02
2019-03-27 01:24:56 iteration: 18010 loss: 0.0042 lr: 0.02
2019-03-27 01:26:07 iteration: 18015 loss: 0.0034 lr: 0.02
2019-03-27 01:26:27 iteration: 18020 loss: 0.0043 lr: 0.02
2019-03-27 01:27:23 iteration: 18025 loss: 0.0039 lr: 0.02
2019-03-27 01:28:12 iteration: 18030 loss: 0.0060 lr: 0.02
2019-03-27 01:28:27 iteration: 18035 loss: 0.0064 lr: 0.02
2019-03-27 01:28:59 iteration: 18040 loss: 0.0053 lr: 0.02
2019-03-27 01:29:08 iteration: 18045 loss: 0.0067 lr: 0.02
2019-03-27 01:29:22 iteration: 18050 loss: 0.0073 lr: 0.02
2019-03-27 01:29:50 iteration: 18055 loss: 0.0048 lr: 0.02
2019-03-27 01:30:06 iteration: 18060 loss: 0.0059 lr: 0.02
2019-03-27 01:30:17 iteration: 18065 loss: 0.0051 lr: 0.02
2019-03-27 01:30:43 iteration: 18070 loss: 0.0046 lr: 0.02
2019-03-27 01:31:28 iteration: 18075 loss: 0.0052 lr: 0.02
2019-03-27 01:31:54 iteration: 18080 loss: 0.0051 lr: 0.02
2019-03-27 01:32:11 iteration: 18085 loss: 0.0056 lr: 0.02
2019-03-27 01:32:54 iteration: 18090 loss: 0.0036 lr: 0.02
2019-03-27 01:33:03 iteration: 18095 loss: 0.0051 lr: 0.02
2019-03-27 01:33:59 iteration: 18100 loss: 0.0059 lr: 0.02
2019-03-27 01:34:31 iteration: 18105 loss: 0.0050 lr: 0.02
2019-03-27 01:34:51 iteration: 18110 loss: 0.0044 lr: 0.02
2019-03-27 01:36:23 iteration: 18115 loss: 0.0049 lr: 0.02
2019-03-27 01:38:04 iteration: 18120 loss: 0.0039 lr: 0.02
2019-03-27 01:38:37 iteration: 18125 loss: 0.0051 lr: 0.02
2019-03-27 01:39:42 iteration: 18130 loss: 0.0033 lr: 0.02
2019-03-27 01:40:22 iteration: 18135 loss: 0.0041 lr: 0.02
2019-03-27 01:41:29 iteration: 18140 loss: 0.0036 lr: 0.02
2019-03-27 01:42:19 iteration: 18145 loss: 0.0046 lr: 0.02
2019-03-27 01:43:29 iteration: 18150 loss: 0.0046 lr: 0.02
2019-03-27 01:43:44 iteration: 18155 loss: 0.0053 lr: 0.02
2019-03-27 01:43:58 iteration: 18160 loss: 0.0061 lr: 0.02
2019-03-27 01:44:09 iteration: 18165 loss: 0.0037 lr: 0.02
2019-03-27 01:44:37 iteration: 18170 loss: 0.0054 lr: 0.02
2019-03-27 01:44:52 iteration: 18175 loss: 0.0059 lr: 0.02
2019-03-27 01:45:31 iteration: 18180 loss: 0.0046 lr: 0.02
2019-03-27 01:45:53 iteration: 18185 loss: 0.0065 lr: 0.02
2019-03-27 01:46:24 iteration: 18190 loss: 0.0044 lr: 0.02
2019-03-27 01:47:12 iteration: 18195 loss: 0.0049 lr: 0.02
2019-03-27 01:48:04 iteration: 18200 loss: 0.0050 lr: 0.02
2019-03-27 01:48:45 iteration: 18205 loss: 0.0054 lr: 0.02
2019-03-27 01:49:02 iteration: 18210 loss: 0.0071 lr: 0.02
2019-03-27 01:49:26 iteration: 18215 loss: 0.0053 lr: 0.02
2019-03-27 01:49:53 iteration: 18220 loss: 0.0042 lr: 0.02
2019-03-27 01:50:50 iteration: 18225 loss: 0.0049 lr: 0.02
2019-03-27 01:51:42 iteration: 18230 loss: 0.0063 lr: 0.02
2019-03-27 01:51:54 iteration: 18235 loss: 0.0066 lr: 0.02
2019-03-27 01:52:13 iteration: 18240 loss: 0.0049 lr: 0.02
2019-03-27 01:52:54 iteration: 18245 loss: 0.0036 lr: 0.02
2019-03-27 01:53:36 iteration: 18250 loss: 0.0052 lr: 0.02
2019-03-27 01:54:44 iteration: 18255 loss: 0.0037 lr: 0.02
2019-03-27 01:55:35 iteration: 18260 loss: 0.0049 lr: 0.02
2019-03-27 01:56:22 iteration: 18265 loss: 0.0060 lr: 0.02
2019-03-27 01:56:31 iteration: 18270 loss: 0.0066 lr: 0.02
2019-03-27 01:57:29 iteration: 18275 loss: 0.0048 lr: 0.02
2019-03-27 01:57:42 iteration: 18280 loss: 0.0051 lr: 0.02
2019-03-27 01:58:38 iteration: 18285 loss: 0.0061 lr: 0.02
2019-03-27 01:59:28 iteration: 18290 loss: 0.0058 lr: 0.02
2019-03-27 01:59:38 iteration: 18295 loss: 0.0053 lr: 0.02
2019-03-27 01:59:55 iteration: 18300 loss: 0.0048 lr: 0.02
2019-03-27 02:01:02 iteration: 18305 loss: 0.0042 lr: 0.02
2019-03-27 02:02:34 iteration: 18310 loss: 0.0038 lr: 0.02
2019-03-27 02:02:50 iteration: 18315 loss: 0.0040 lr: 0.02
2019-03-27 02:04:01 iteration: 18320 loss: 0.0030 lr: 0.02
2019-03-27 02:04:56 iteration: 18325 loss: 0.0041 lr: 0.02
2019-03-27 02:05:33 iteration: 18330 loss: 0.0038 lr: 0.02
2019-03-27 02:06:05 iteration: 18335 loss: 0.0066 lr: 0.02
2019-03-27 02:06:20 iteration: 18340 loss: 0.0049 lr: 0.02
2019-03-27 02:06:36 iteration: 18345 loss: 0.0073 lr: 0.02
2019-03-27 02:07:18 iteration: 18350 loss: 0.0041 lr: 0.02
2019-03-27 02:07:49 iteration: 18355 loss: 0.0046 lr: 0.02
2019-03-27 02:08:29 iteration: 18360 loss: 0.0044 lr: 0.02
2019-03-27 02:09:08 iteration: 18365 loss: 0.0044 lr: 0.02
2019-03-27 02:09:58 iteration: 18370 loss: 0.0045 lr: 0.02
2019-03-27 02:10:28 iteration: 18375 loss: 0.0049 lr: 0.02
2019-03-27 02:10:45 iteration: 18380 loss: 0.0058 lr: 0.02
2019-03-27 02:12:04 iteration: 18385 loss: 0.0044 lr: 0.02
2019-03-27 02:12:21 iteration: 18390 loss: 0.0060 lr: 0.02
2019-03-27 02:12:46 iteration: 18395 loss: 0.0053 lr: 0.02
2019-03-27 02:13:22 iteration: 18400 loss: 0.0058 lr: 0.02
2019-03-27 02:13:38 iteration: 18405 loss: 0.0062 lr: 0.02
2019-03-27 02:14:19 iteration: 18410 loss: 0.0065 lr: 0.02
2019-03-27 02:15:08 iteration: 18415 loss: 0.0058 lr: 0.02
2019-03-27 02:16:20 iteration: 18420 loss: 0.0039 lr: 0.02
2019-03-27 02:16:39 iteration: 18425 loss: 0.0036 lr: 0.02
2019-03-27 02:16:57 iteration: 18430 loss: 0.0052 lr: 0.02
2019-03-27 02:18:03 iteration: 18435 loss: 0.0062 lr: 0.02
2019-03-27 02:18:39 iteration: 18440 loss: 0.0049 lr: 0.02
2019-03-27 02:19:23 iteration: 18445 loss: 0.0068 lr: 0.02
2019-03-27 02:19:34 iteration: 18450 loss: 0.0060 lr: 0.02
2019-03-27 02:20:21 iteration: 18455 loss: 0.0041 lr: 0.02
2019-03-27 02:21:17 iteration: 18460 loss: 0.0057 lr: 0.02
2019-03-27 02:21:50 iteration: 18465 loss: 0.0046 lr: 0.02
2019-03-27 02:22:33 iteration: 18470 loss: 0.0043 lr: 0.02
2019-03-27 02:23:17 iteration: 18475 loss: 0.0055 lr: 0.02
2019-03-27 02:24:29 iteration: 18480 loss: 0.0051 lr: 0.02
2019-03-27 02:24:39 iteration: 18485 loss: 0.0057 lr: 0.02
2019-03-27 02:24:52 iteration: 18490 loss: 0.0050 lr: 0.02
2019-03-27 02:25:41 iteration: 18495 loss: 0.0040 lr: 0.02
2019-03-27 02:26:04 iteration: 18500 loss: 0.0041 lr: 0.02
2019-03-27 02:26:20 iteration: 18505 loss: 0.0084 lr: 0.02
2019-03-27 02:27:24 iteration: 18510 loss: 0.0038 lr: 0.02
2019-03-27 02:28:03 iteration: 18515 loss: 0.0048 lr: 0.02
2019-03-27 02:28:46 iteration: 18520 loss: 0.0039 lr: 0.02
2019-03-27 02:29:02 iteration: 18525 loss: 0.0055 lr: 0.02
2019-03-27 02:29:18 iteration: 18530 loss: 0.0053 lr: 0.02
2019-03-27 02:29:40 iteration: 18535 loss: 0.0051 lr: 0.02
2019-03-27 02:30:08 iteration: 18540 loss: 0.0058 lr: 0.02
2019-03-27 02:30:47 iteration: 18545 loss: 0.0055 lr: 0.02
2019-03-27 02:30:59 iteration: 18550 loss: 0.0048 lr: 0.02
2019-03-27 02:31:13 iteration: 18555 loss: 0.0045 lr: 0.02
2019-03-27 02:31:49 iteration: 18560 loss: 0.0064 lr: 0.02
2019-03-27 02:32:04 iteration: 18565 loss: 0.0058 lr: 0.02
2019-03-27 02:32:28 iteration: 18570 loss: 0.0047 lr: 0.02
2019-03-27 02:32:54 iteration: 18575 loss: 0.0043 lr: 0.02
2019-03-27 02:33:19 iteration: 18580 loss: 0.0043 lr: 0.02
2019-03-27 02:34:26 iteration: 18585 loss: 0.0061 lr: 0.02
2019-03-27 02:35:09 iteration: 18590 loss: 0.0050 lr: 0.02
2019-03-27 02:35:51 iteration: 18595 loss: 0.0057 lr: 0.02
2019-03-27 02:36:05 iteration: 18600 loss: 0.0062 lr: 0.02
2019-03-27 02:37:00 iteration: 18605 loss: 0.0034 lr: 0.02
2019-03-27 02:37:21 iteration: 18610 loss: 0.0053 lr: 0.02
2019-03-27 02:37:32 iteration: 18615 loss: 0.0050 lr: 0.02
2019-03-27 02:37:47 iteration: 18620 loss: 0.0051 lr: 0.02
2019-03-27 02:38:27 iteration: 18625 loss: 0.0036 lr: 0.02
2019-03-27 02:39:25 iteration: 18630 loss: 0.0040 lr: 0.02
2019-03-27 02:40:08 iteration: 18635 loss: 0.0050 lr: 0.02
2019-03-27 02:40:38 iteration: 18640 loss: 0.0036 lr: 0.02
2019-03-27 02:41:32 iteration: 18645 loss: 0.0054 lr: 0.02
2019-03-27 02:42:23 iteration: 18650 loss: 0.0038 lr: 0.02
2019-03-27 02:43:19 iteration: 18655 loss: 0.0040 lr: 0.02
2019-03-27 02:44:00 iteration: 18660 loss: 0.0047 lr: 0.02
2019-03-27 02:44:30 iteration: 18665 loss: 0.0038 lr: 0.02
2019-03-27 02:45:22 iteration: 18670 loss: 0.0077 lr: 0.02
2019-03-27 02:45:52 iteration: 18675 loss: 0.0039 lr: 0.02
2019-03-27 02:46:04 iteration: 18680 loss: 0.0047 lr: 0.02
2019-03-27 02:47:22 iteration: 18685 loss: 0.0044 lr: 0.02
2019-03-27 02:48:02 iteration: 18690 loss: 0.0044 lr: 0.02
2019-03-27 02:48:15 iteration: 18695 loss: 0.0054 lr: 0.02
2019-03-27 02:48:31 iteration: 18700 loss: 0.0044 lr: 0.02
2019-03-27 02:49:19 iteration: 18705 loss: 0.0056 lr: 0.02
2019-03-27 02:49:55 iteration: 18710 loss: 0.0047 lr: 0.02
2019-03-27 02:50:23 iteration: 18715 loss: 0.0060 lr: 0.02
2019-03-27 02:50:39 iteration: 18720 loss: 0.0040 lr: 0.02
2019-03-27 02:51:21 iteration: 18725 loss: 0.0044 lr: 0.02
2019-03-27 02:51:56 iteration: 18730 loss: 0.0073 lr: 0.02
2019-03-27 02:52:11 iteration: 18735 loss: 0.0055 lr: 0.02
2019-03-27 02:52:30 iteration: 18740 loss: 0.0049 lr: 0.02
2019-03-27 02:53:14 iteration: 18745 loss: 0.0056 lr: 0.02
2019-03-27 02:54:10 iteration: 18750 loss: 0.0043 lr: 0.02
2019-03-27 02:54:26 iteration: 18755 loss: 0.0103 lr: 0.02
2019-03-27 02:54:55 iteration: 18760 loss: 0.0047 lr: 0.02
2019-03-27 02:56:13 iteration: 18765 loss: 0.0044 lr: 0.02
2019-03-27 02:57:06 iteration: 18770 loss: 0.0046 lr: 0.02
2019-03-27 02:57:20 iteration: 18775 loss: 0.0045 lr: 0.02
2019-03-27 02:57:40 iteration: 18780 loss: 0.0053 lr: 0.02
2019-03-27 02:58:29 iteration: 18785 loss: 0.0034 lr: 0.02
2019-03-27 02:59:45 iteration: 18790 loss: 0.0042 lr: 0.02
2019-03-27 03:00:24 iteration: 18795 loss: 0.0056 lr: 0.02
2019-03-27 03:00:43 iteration: 18800 loss: 0.0058 lr: 0.02
2019-03-27 03:01:03 iteration: 18805 loss: 0.0054 lr: 0.02
2019-03-27 03:02:23 iteration: 18810 loss: 0.0041 lr: 0.02
2019-03-27 03:03:10 iteration: 18815 loss: 0.0042 lr: 0.02
2019-03-27 03:03:30 iteration: 18820 loss: 0.0054 lr: 0.02
2019-03-27 03:03:57 iteration: 18825 loss: 0.0055 lr: 0.02
2019-03-27 03:04:24 iteration: 18830 loss: 0.0050 lr: 0.02
2019-03-27 03:04:53 iteration: 18835 loss: 0.0052 lr: 0.02
2019-03-27 03:05:05 iteration: 18840 loss: 0.0069 lr: 0.02
2019-03-27 03:05:43 iteration: 18845 loss: 0.0047 lr: 0.02
2019-03-27 03:06:37 iteration: 18850 loss: 0.0035 lr: 0.02
2019-03-27 03:07:25 iteration: 18855 loss: 0.0049 lr: 0.02
2019-03-27 03:07:42 iteration: 18860 loss: 0.0054 lr: 0.02
2019-03-27 03:08:25 iteration: 18865 loss: 0.0069 lr: 0.02
2019-03-27 03:09:05 iteration: 18870 loss: 0.0045 lr: 0.02
2019-03-27 03:09:21 iteration: 18875 loss: 0.0050 lr: 0.02
2019-03-27 03:09:39 iteration: 18880 loss: 0.0065 lr: 0.02
2019-03-27 03:11:19 iteration: 18885 loss: 0.0037 lr: 0.02
2019-03-27 03:11:34 iteration: 18890 loss: 0.0036 lr: 0.02
2019-03-27 03:11:54 iteration: 18895 loss: 0.0059 lr: 0.02
2019-03-27 03:12:42 iteration: 18900 loss: 0.0052 lr: 0.02
2019-03-27 03:13:34 iteration: 18905 loss: 0.0046 lr: 0.02
2019-03-27 03:13:51 iteration: 18910 loss: 0.0079 lr: 0.02
2019-03-27 03:14:22 iteration: 18915 loss: 0.0039 lr: 0.02
2019-03-27 03:14:41 iteration: 18920 loss: 0.0056 lr: 0.02
2019-03-27 03:15:27 iteration: 18925 loss: 0.0051 lr: 0.02
2019-03-27 03:16:06 iteration: 18930 loss: 0.0068 lr: 0.02
2019-03-27 03:16:54 iteration: 18935 loss: 0.0045 lr: 0.02
2019-03-27 03:17:38 iteration: 18940 loss: 0.0056 lr: 0.02
2019-03-27 03:18:32 iteration: 18945 loss: 0.0042 lr: 0.02
2019-03-27 03:19:28 iteration: 18950 loss: 0.0046 lr: 0.02
2019-03-27 03:19:46 iteration: 18955 loss: 0.0048 lr: 0.02
2019-03-27 03:20:36 iteration: 18960 loss: 0.0036 lr: 0.02
2019-03-27 03:20:58 iteration: 18965 loss: 0.0056 lr: 0.02
2019-03-27 03:21:24 iteration: 18970 loss: 0.0046 lr: 0.02
2019-03-27 03:21:56 iteration: 18975 loss: 0.0051 lr: 0.02
2019-03-27 03:22:21 iteration: 18980 loss: 0.0039 lr: 0.02
2019-03-27 03:23:09 iteration: 18985 loss: 0.0043 lr: 0.02
2019-03-27 03:23:51 iteration: 18990 loss: 0.0042 lr: 0.02
2019-03-27 03:24:40 iteration: 18995 loss: 0.0045 lr: 0.02
2019-03-27 03:24:48 iteration: 19000 loss: 0.0070 lr: 0.02
2019-03-27 03:26:00 iteration: 19005 loss: 0.0062 lr: 0.02
2019-03-27 03:26:27 iteration: 19010 loss: 0.0055 lr: 0.02
2019-03-27 03:27:06 iteration: 19015 loss: 0.0035 lr: 0.02
2019-03-27 03:27:41 iteration: 19020 loss: 0.0051 lr: 0.02
2019-03-27 03:28:27 iteration: 19025 loss: 0.0054 lr: 0.02
2019-03-27 03:29:42 iteration: 19030 loss: 0.0046 lr: 0.02
2019-03-27 03:29:54 iteration: 19035 loss: 0.0064 lr: 0.02
2019-03-27 03:30:36 iteration: 19040 loss: 0.0052 lr: 0.02
2019-03-27 03:31:19 iteration: 19045 loss: 0.0055 lr: 0.02
2019-03-27 03:32:28 iteration: 19050 loss: 0.0033 lr: 0.02
2019-03-27 03:32:59 iteration: 19055 loss: 0.0044 lr: 0.02
2019-03-27 03:33:12 iteration: 19060 loss: 0.0105 lr: 0.02
2019-03-27 03:33:36 iteration: 19065 loss: 0.0064 lr: 0.02
2019-03-27 03:33:54 iteration: 19070 loss: 0.0093 lr: 0.02
2019-03-27 03:34:08 iteration: 19075 loss: 0.0057 lr: 0.02
2019-03-27 03:34:20 iteration: 19080 loss: 0.0057 lr: 0.02
2019-03-27 03:34:51 iteration: 19085 loss: 0.0051 lr: 0.02
2019-03-27 03:35:35 iteration: 19090 loss: 0.0047 lr: 0.02
2019-03-27 03:36:03 iteration: 19095 loss: 0.0046 lr: 0.02
2019-03-27 03:36:46 iteration: 19100 loss: 0.0033 lr: 0.02
2019-03-27 03:37:07 iteration: 19105 loss: 0.0044 lr: 0.02
2019-03-27 03:37:59 iteration: 19110 loss: 0.0055 lr: 0.02
2019-03-27 03:38:17 iteration: 19115 loss: 0.0050 lr: 0.02
2019-03-27 03:38:47 iteration: 19120 loss: 0.0048 lr: 0.02
2019-03-27 03:39:44 iteration: 19125 loss: 0.0055 lr: 0.02
2019-03-27 03:40:58 iteration: 19130 loss: 0.0042 lr: 0.02
2019-03-27 03:42:16 iteration: 19135 loss: 0.0044 lr: 0.02
2019-03-27 03:43:26 iteration: 19140 loss: 0.0049 lr: 0.02
2019-03-27 03:43:58 iteration: 19145 loss: 0.0039 lr: 0.02
2019-03-27 03:44:16 iteration: 19150 loss: 0.0040 lr: 0.02
2019-03-27 03:45:30 iteration: 19155 loss: 0.0033 lr: 0.02
2019-03-27 03:46:06 iteration: 19160 loss: 0.0037 lr: 0.02
2019-03-27 03:46:24 iteration: 19165 loss: 0.0059 lr: 0.02
2019-03-27 03:46:46 iteration: 19170 loss: 0.0056 lr: 0.02
2019-03-27 03:47:24 iteration: 19175 loss: 0.0043 lr: 0.02
2019-03-27 03:47:47 iteration: 19180 loss: 0.0044 lr: 0.02
2019-03-27 03:48:04 iteration: 19185 loss: 0.0061 lr: 0.02
2019-03-27 03:48:21 iteration: 19190 loss: 0.0061 lr: 0.02
2019-03-27 03:48:36 iteration: 19195 loss: 0.0044 lr: 0.02
2019-03-27 03:49:02 iteration: 19200 loss: 0.0070 lr: 0.02
2019-03-27 03:49:35 iteration: 19205 loss: 0.0055 lr: 0.02
2019-03-27 03:50:59 iteration: 19210 loss: 0.0045 lr: 0.02
2019-03-27 03:51:57 iteration: 19215 loss: 0.0050 lr: 0.02
2019-03-27 03:52:29 iteration: 19220 loss: 0.0039 lr: 0.02
2019-03-27 03:53:28 iteration: 19225 loss: 0.0035 lr: 0.02
2019-03-27 03:54:14 iteration: 19230 loss: 0.0049 lr: 0.02
2019-03-27 03:54:37 iteration: 19235 loss: 0.0055 lr: 0.02
2019-03-27 03:55:28 iteration: 19240 loss: 0.0069 lr: 0.02
2019-03-27 03:55:52 iteration: 19245 loss: 0.0033 lr: 0.02
2019-03-27 03:57:04 iteration: 19250 loss: 0.0041 lr: 0.02
2019-03-27 03:57:17 iteration: 19255 loss: 0.0082 lr: 0.02
2019-03-27 03:57:53 iteration: 19260 loss: 0.0045 lr: 0.02
2019-03-27 03:58:49 iteration: 19265 loss: 0.0036 lr: 0.02
2019-03-27 04:00:12 iteration: 19270 loss: 0.0044 lr: 0.02
2019-03-27 04:00:31 iteration: 19275 loss: 0.0055 lr: 0.02
2019-03-27 04:00:50 iteration: 19280 loss: 0.0048 lr: 0.02
2019-03-27 04:01:33 iteration: 19285 loss: 0.0039 lr: 0.02
2019-03-27 04:02:29 iteration: 19290 loss: 0.0046 lr: 0.02
2019-03-27 04:03:10 iteration: 19295 loss: 0.0045 lr: 0.02
2019-03-27 04:03:46 iteration: 19300 loss: 0.0047 lr: 0.02
2019-03-27 04:03:58 iteration: 19305 loss: 0.0046 lr: 0.02
2019-03-27 04:04:42 iteration: 19310 loss: 0.0052 lr: 0.02
2019-03-27 04:05:03 iteration: 19315 loss: 0.0049 lr: 0.02
2019-03-27 04:05:45 iteration: 19320 loss: 0.0047 lr: 0.02
2019-03-27 04:06:03 iteration: 19325 loss: 0.0038 lr: 0.02
2019-03-27 04:06:17 iteration: 19330 loss: 0.0048 lr: 0.02
2019-03-27 04:07:06 iteration: 19335 loss: 0.0055 lr: 0.02
2019-03-27 04:07:20 iteration: 19340 loss: 0.0052 lr: 0.02
2019-03-27 04:07:59 iteration: 19345 loss: 0.0055 lr: 0.02
2019-03-27 04:08:43 iteration: 19350 loss: 0.0044 lr: 0.02
2019-03-27 04:09:18 iteration: 19355 loss: 0.0035 lr: 0.02
2019-03-27 04:10:02 iteration: 19360 loss: 0.0057 lr: 0.02
2019-03-27 04:10:55 iteration: 19365 loss: 0.0042 lr: 0.02
2019-03-27 04:11:57 iteration: 19370 loss: 0.0052 lr: 0.02
2019-03-27 04:12:33 iteration: 19375 loss: 0.0063 lr: 0.02
2019-03-27 04:13:33 iteration: 19380 loss: 0.0047 lr: 0.02
2019-03-27 04:14:01 iteration: 19385 loss: 0.0056 lr: 0.02
2019-03-27 04:15:11 iteration: 19390 loss: 0.0053 lr: 0.02
2019-03-27 04:15:58 iteration: 19395 loss: 0.0046 lr: 0.02
2019-03-27 04:16:25 iteration: 19400 loss: 0.0034 lr: 0.02
2019-03-27 04:16:37 iteration: 19405 loss: 0.0056 lr: 0.02
2019-03-27 04:17:27 iteration: 19410 loss: 0.0043 lr: 0.02
2019-03-27 04:17:48 iteration: 19415 loss: 0.0070 lr: 0.02
2019-03-27 04:18:22 iteration: 19420 loss: 0.0053 lr: 0.02
2019-03-27 04:18:45 iteration: 19425 loss: 0.0046 lr: 0.02
2019-03-27 04:19:02 iteration: 19430 loss: 0.0053 lr: 0.02
2019-03-27 04:19:20 iteration: 19435 loss: 0.0054 lr: 0.02
2019-03-27 04:19:47 iteration: 19440 loss: 0.0058 lr: 0.02
2019-03-27 04:20:03 iteration: 19445 loss: 0.0042 lr: 0.02
2019-03-27 04:20:21 iteration: 19450 loss: 0.0057 lr: 0.02
2019-03-27 04:20:56 iteration: 19455 loss: 0.0065 lr: 0.02
2019-03-27 04:21:27 iteration: 19460 loss: 0.0043 lr: 0.02
2019-03-27 04:21:48 iteration: 19465 loss: 0.0061 lr: 0.02
2019-03-27 04:22:08 iteration: 19470 loss: 0.0049 lr: 0.02
2019-03-27 04:23:16 iteration: 19475 loss: 0.0048 lr: 0.02
2019-03-27 04:23:58 iteration: 19480 loss: 0.0046 lr: 0.02
2019-03-27 04:24:51 iteration: 19485 loss: 0.0043 lr: 0.02
2019-03-27 04:25:06 iteration: 19490 loss: 0.0066 lr: 0.02
2019-03-27 04:25:22 iteration: 19495 loss: 0.0048 lr: 0.02
2019-03-27 04:25:45 iteration: 19500 loss: 0.0044 lr: 0.02
2019-03-27 04:26:33 iteration: 19505 loss: 0.0051 lr: 0.02
2019-03-27 04:26:55 iteration: 19510 loss: 0.0044 lr: 0.02
2019-03-27 04:27:12 iteration: 19515 loss: 0.0104 lr: 0.02
2019-03-27 04:28:05 iteration: 19520 loss: 0.0040 lr: 0.02
2019-03-27 04:28:50 iteration: 19525 loss: 0.0060 lr: 0.02
2019-03-27 04:29:37 iteration: 19530 loss: 0.0045 lr: 0.02
2019-03-27 04:29:55 iteration: 19535 loss: 0.0063 lr: 0.02
2019-03-27 04:30:13 iteration: 19540 loss: 0.0070 lr: 0.02
2019-03-27 04:30:55 iteration: 19545 loss: 0.0057 lr: 0.02
2019-03-27 04:31:45 iteration: 19550 loss: 0.0038 lr: 0.02
2019-03-27 04:31:58 iteration: 19555 loss: 0.0081 lr: 0.02
2019-03-27 04:32:18 iteration: 19560 loss: 0.0058 lr: 0.02
2019-03-27 04:33:21 iteration: 19565 loss: 0.0041 lr: 0.02
2019-03-27 04:33:40 iteration: 19570 loss: 0.0047 lr: 0.02
2019-03-27 04:33:59 iteration: 19575 loss: 0.0044 lr: 0.02
2019-03-27 04:34:44 iteration: 19580 loss: 0.0045 lr: 0.02
2019-03-27 04:35:39 iteration: 19585 loss: 0.0041 lr: 0.02
2019-03-27 04:36:18 iteration: 19590 loss: 0.0044 lr: 0.02
2019-03-27 04:37:46 iteration: 19595 loss: 0.0060 lr: 0.02
2019-03-27 04:38:50 iteration: 19600 loss: 0.0056 lr: 0.02
2019-03-27 04:39:35 iteration: 19605 loss: 0.0051 lr: 0.02
2019-03-27 04:40:11 iteration: 19610 loss: 0.0047 lr: 0.02
2019-03-27 04:40:30 iteration: 19615 loss: 0.0043 lr: 0.02
2019-03-27 04:41:00 iteration: 19620 loss: 0.0066 lr: 0.02
2019-03-27 04:41:15 iteration: 19625 loss: 0.0039 lr: 0.02
2019-03-27 04:42:00 iteration: 19630 loss: 0.0051 lr: 0.02
2019-03-27 04:42:37 iteration: 19635 loss: 0.0044 lr: 0.02
2019-03-27 04:43:22 iteration: 19640 loss: 0.0045 lr: 0.02
2019-03-27 04:43:42 iteration: 19645 loss: 0.0042 lr: 0.02
2019-03-27 04:44:32 iteration: 19650 loss: 0.0035 lr: 0.02
2019-03-27 04:44:47 iteration: 19655 loss: 0.0049 lr: 0.02
2019-03-27 04:45:41 iteration: 19660 loss: 0.0049 lr: 0.02
2019-03-27 04:46:07 iteration: 19665 loss: 0.0067 lr: 0.02
2019-03-27 04:46:22 iteration: 19670 loss: 0.0068 lr: 0.02
2019-03-27 04:47:15 iteration: 19675 loss: 0.0035 lr: 0.02
2019-03-27 04:48:12 iteration: 19680 loss: 0.0054 lr: 0.02
2019-03-27 04:48:32 iteration: 19685 loss: 0.0040 lr: 0.02
2019-03-27 04:49:08 iteration: 19690 loss: 0.0050 lr: 0.02
2019-03-27 04:49:46 iteration: 19695 loss: 0.0039 lr: 0.02
2019-03-27 04:51:19 iteration: 19700 loss: 0.0039 lr: 0.02
2019-03-27 04:52:33 iteration: 19705 loss: 0.0034 lr: 0.02
2019-03-27 04:53:40 iteration: 19710 loss: 0.0036 lr: 0.02
2019-03-27 04:53:58 iteration: 19715 loss: 0.0054 lr: 0.02
2019-03-27 04:54:05 iteration: 19720 loss: 0.0071 lr: 0.02
2019-03-27 04:55:26 iteration: 19725 loss: 0.0049 lr: 0.02
2019-03-27 04:55:41 iteration: 19730 loss: 0.0054 lr: 0.02
2019-03-27 04:56:18 iteration: 19735 loss: 0.0043 lr: 0.02
2019-03-27 04:56:27 iteration: 19740 loss: 0.0054 lr: 0.02
2019-03-27 04:58:10 iteration: 19745 loss: 0.0038 lr: 0.02
2019-03-27 04:59:04 iteration: 19750 loss: 0.0043 lr: 0.02
2019-03-27 04:59:49 iteration: 19755 loss: 0.0052 lr: 0.02
2019-03-27 05:00:38 iteration: 19760 loss: 0.0062 lr: 0.02
2019-03-27 05:00:57 iteration: 19765 loss: 0.0049 lr: 0.02
2019-03-27 05:01:25 iteration: 19770 loss: 0.0050 lr: 0.02
2019-03-27 05:02:07 iteration: 19775 loss: 0.0045 lr: 0.02
2019-03-27 05:02:29 iteration: 19780 loss: 0.0059 lr: 0.02
2019-03-27 05:03:28 iteration: 19785 loss: 0.0039 lr: 0.02
2019-03-27 05:04:50 iteration: 19790 loss: 0.0034 lr: 0.02
2019-03-27 05:05:05 iteration: 19795 loss: 0.0060 lr: 0.02
2019-03-27 05:05:54 iteration: 19800 loss: 0.0053 lr: 0.02
2019-03-27 05:06:36 iteration: 19805 loss: 0.0050 lr: 0.02
2019-03-27 05:07:24 iteration: 19810 loss: 0.0043 lr: 0.02
2019-03-27 05:08:21 iteration: 19815 loss: 0.0050 lr: 0.02
2019-03-27 05:09:15 iteration: 19820 loss: 0.0041 lr: 0.02
2019-03-27 05:10:02 iteration: 19825 loss: 0.0048 lr: 0.02
2019-03-27 05:10:23 iteration: 19830 loss: 0.0064 lr: 0.02
2019-03-27 05:10:34 iteration: 19835 loss: 0.0062 lr: 0.02
2019-03-27 05:10:52 iteration: 19840 loss: 0.0059 lr: 0.02
2019-03-27 05:11:28 iteration: 19845 loss: 0.0103 lr: 0.02
2019-03-27 05:11:44 iteration: 19850 loss: 0.0063 lr: 0.02
2019-03-27 05:11:57 iteration: 19855 loss: 0.0046 lr: 0.02
2019-03-27 05:12:22 iteration: 19860 loss: 0.0050 lr: 0.02
2019-03-27 05:12:53 iteration: 19865 loss: 0.0044 lr: 0.02
2019-03-27 05:13:07 iteration: 19870 loss: 0.0056 lr: 0.02
2019-03-27 05:13:55 iteration: 19875 loss: 0.0051 lr: 0.02
2019-03-27 05:14:16 iteration: 19880 loss: 0.0058 lr: 0.02
2019-03-27 05:14:34 iteration: 19885 loss: 0.0069 lr: 0.02
2019-03-27 05:14:53 iteration: 19890 loss: 0.0066 lr: 0.02
2019-03-27 05:15:07 iteration: 19895 loss: 0.0053 lr: 0.02
2019-03-27 05:15:23 iteration: 19900 loss: 0.0063 lr: 0.02
2019-03-27 05:16:10 iteration: 19905 loss: 0.0041 lr: 0.02
2019-03-27 05:17:01 iteration: 19910 loss: 0.0041 lr: 0.02
2019-03-27 05:17:42 iteration: 19915 loss: 0.0028 lr: 0.02
2019-03-27 05:17:57 iteration: 19920 loss: 0.0060 lr: 0.02
2019-03-27 05:18:43 iteration: 19925 loss: 0.0048 lr: 0.02
2019-03-27 05:19:19 iteration: 19930 loss: 0.0053 lr: 0.02
2019-03-27 05:20:27 iteration: 19935 loss: 0.0053 lr: 0.02
2019-03-27 05:21:34 iteration: 19940 loss: 0.0049 lr: 0.02
2019-03-27 05:22:12 iteration: 19945 loss: 0.0055 lr: 0.02
2019-03-27 05:22:58 iteration: 19950 loss: 0.0052 lr: 0.02
2019-03-27 05:23:49 iteration: 19955 loss: 0.0058 lr: 0.02
2019-03-27 05:24:34 iteration: 19960 loss: 0.0067 lr: 0.02
2019-03-27 05:25:23 iteration: 19965 loss: 0.0048 lr: 0.02
2019-03-27 05:26:36 iteration: 19970 loss: 0.0039 lr: 0.02
2019-03-27 05:27:35 iteration: 19975 loss: 0.0042 lr: 0.02
2019-03-27 05:27:55 iteration: 19980 loss: 0.0043 lr: 0.02
2019-03-27 05:28:39 iteration: 19985 loss: 0.0039 lr: 0.02
2019-03-27 05:28:52 iteration: 19990 loss: 0.0045 lr: 0.02
2019-03-27 05:29:20 iteration: 19995 loss: 0.0048 lr: 0.02
2019-03-27 05:30:37 iteration: 20000 loss: 0.0054 lr: 0.02
2019-03-27 05:31:38 iteration: 20005 loss: 0.0048 lr: 0.02
2019-03-27 05:31:49 iteration: 20010 loss: 0.0079 lr: 0.02
2019-03-27 05:32:07 iteration: 20015 loss: 0.0056 lr: 0.02
2019-03-27 05:32:28 iteration: 20020 loss: 0.0053 lr: 0.02
2019-03-27 05:33:37 iteration: 20025 loss: 0.0035 lr: 0.02
2019-03-27 05:33:49 iteration: 20030 loss: 0.0055 lr: 0.02
2019-03-27 05:34:32 iteration: 20035 loss: 0.0042 lr: 0.02
2019-03-27 05:35:38 iteration: 20040 loss: 0.0053 lr: 0.02
2019-03-27 05:36:32 iteration: 20045 loss: 0.0053 lr: 0.02
2019-03-27 05:37:21 iteration: 20050 loss: 0.0043 lr: 0.02
2019-03-27 05:38:00 iteration: 20055 loss: 0.0047 lr: 0.02
2019-03-27 05:38:38 iteration: 20060 loss: 0.0062 lr: 0.02
2019-03-27 05:39:47 iteration: 20065 loss: 0.0034 lr: 0.02
2019-03-27 05:40:08 iteration: 20070 loss: 0.0051 lr: 0.02
2019-03-27 05:40:36 iteration: 20075 loss: 0.0044 lr: 0.02
2019-03-27 05:40:49 iteration: 20080 loss: 0.0048 lr: 0.02
2019-03-27 05:41:33 iteration: 20085 loss: 0.0050 lr: 0.02
2019-03-27 05:42:30 iteration: 20090 loss: 0.0036 lr: 0.02
2019-03-27 05:42:53 iteration: 20095 loss: 0.0075 lr: 0.02
2019-03-27 05:43:10 iteration: 20100 loss: 0.0068 lr: 0.02
2019-03-27 05:44:19 iteration: 20105 loss: 0.0036 lr: 0.02
2019-03-27 05:45:15 iteration: 20110 loss: 0.0043 lr: 0.02
2019-03-27 05:46:02 iteration: 20115 loss: 0.0032 lr: 0.02
2019-03-27 05:46:29 iteration: 20120 loss: 0.0034 lr: 0.02
2019-03-27 05:47:20 iteration: 20125 loss: 0.0054 lr: 0.02
2019-03-27 05:47:34 iteration: 20130 loss: 0.0041 lr: 0.02
2019-03-27 05:47:56 iteration: 20135 loss: 0.0051 lr: 0.02
2019-03-27 05:49:14 iteration: 20140 loss: 0.0040 lr: 0.02
2019-03-27 05:50:24 iteration: 20145 loss: 0.0037 lr: 0.02
2019-03-27 05:50:40 iteration: 20150 loss: 0.0059 lr: 0.02
2019-03-27 05:51:15 iteration: 20155 loss: 0.0051 lr: 0.02
2019-03-27 05:51:30 iteration: 20160 loss: 0.0089 lr: 0.02
2019-03-27 05:51:45 iteration: 20165 loss: 0.0049 lr: 0.02
2019-03-27 05:52:08 iteration: 20170 loss: 0.0052 lr: 0.02
2019-03-27 05:52:58 iteration: 20175 loss: 0.0048 lr: 0.02
2019-03-27 05:53:23 iteration: 20180 loss: 0.0052 lr: 0.02
2019-03-27 05:54:07 iteration: 20185 loss: 0.0035 lr: 0.02
2019-03-27 05:54:43 iteration: 20190 loss: 0.0053 lr: 0.02
2019-03-27 05:55:18 iteration: 20195 loss: 0.0038 lr: 0.02
2019-03-27 05:55:36 iteration: 20200 loss: 0.0051 lr: 0.02
2019-03-27 05:55:57 iteration: 20205 loss: 0.0046 lr: 0.02
2019-03-27 05:56:47 iteration: 20210 loss: 0.0046 lr: 0.02
2019-03-27 05:57:16 iteration: 20215 loss: 0.0054 lr: 0.02
2019-03-27 05:57:41 iteration: 20220 loss: 0.0055 lr: 0.02
2019-03-27 05:58:25 iteration: 20225 loss: 0.0053 lr: 0.02
2019-03-27 05:59:01 iteration: 20230 loss: 0.0040 lr: 0.02
2019-03-27 05:59:29 iteration: 20235 loss: 0.0049 lr: 0.02
2019-03-27 05:59:58 iteration: 20240 loss: 0.0044 lr: 0.02
2019-03-27 06:00:26 iteration: 20245 loss: 0.0046 lr: 0.02
2019-03-27 06:00:57 iteration: 20250 loss: 0.0068 lr: 0.02
2019-03-27 06:01:24 iteration: 20255 loss: 0.0047 lr: 0.02
2019-03-27 06:01:33 iteration: 20260 loss: 0.0067 lr: 0.02
2019-03-27 06:02:26 iteration: 20265 loss: 0.0037 lr: 0.02
2019-03-27 06:02:42 iteration: 20270 loss: 0.0053 lr: 0.02
2019-03-27 06:03:55 iteration: 20275 loss: 0.0041 lr: 0.02
2019-03-27 06:04:50 iteration: 20280 loss: 0.0038 lr: 0.02
2019-03-27 06:05:24 iteration: 20285 loss: 0.0050 lr: 0.02
2019-03-27 06:06:23 iteration: 20290 loss: 0.0041 lr: 0.02
2019-03-27 06:07:30 iteration: 20295 loss: 0.0039 lr: 0.02
2019-03-27 06:08:21 iteration: 20300 loss: 0.0044 lr: 0.02
2019-03-27 06:08:37 iteration: 20305 loss: 0.0058 lr: 0.02
2019-03-27 06:09:30 iteration: 20310 loss: 0.0046 lr: 0.02
2019-03-27 06:09:55 iteration: 20315 loss: 0.0038 lr: 0.02
2019-03-27 06:10:49 iteration: 20320 loss: 0.0071 lr: 0.02
2019-03-27 06:12:10 iteration: 20325 loss: 0.0036 lr: 0.02
2019-03-27 06:13:16 iteration: 20330 loss: 0.0040 lr: 0.02
2019-03-27 06:14:04 iteration: 20335 loss: 0.0041 lr: 0.02
2019-03-27 06:14:24 iteration: 20340 loss: 0.0044 lr: 0.02
2019-03-27 06:15:07 iteration: 20345 loss: 0.0041 lr: 0.02
2019-03-27 06:15:50 iteration: 20350 loss: 0.0059 lr: 0.02
2019-03-27 06:16:07 iteration: 20355 loss: 0.0089 lr: 0.02
2019-03-27 06:17:01 iteration: 20360 loss: 0.0074 lr: 0.02
2019-03-27 06:17:46 iteration: 20365 loss: 0.0034 lr: 0.02
2019-03-27 06:18:10 iteration: 20370 loss: 0.0057 lr: 0.02
2019-03-27 06:19:05 iteration: 20375 loss: 0.0037 lr: 0.02
2019-03-27 06:19:44 iteration: 20380 loss: 0.0041 lr: 0.02
2019-03-27 06:19:55 iteration: 20385 loss: 0.0048 lr: 0.02
2019-03-27 06:21:13 iteration: 20390 loss: 0.0043 lr: 0.02
2019-03-27 06:22:00 iteration: 20395 loss: 0.0036 lr: 0.02
2019-03-27 06:22:28 iteration: 20400 loss: 0.0037 lr: 0.02
2019-03-27 06:23:31 iteration: 20405 loss: 0.0030 lr: 0.02
2019-03-27 06:24:08 iteration: 20410 loss: 0.0036 lr: 0.02
2019-03-27 06:25:12 iteration: 20415 loss: 0.0041 lr: 0.02
2019-03-27 06:25:33 iteration: 20420 loss: 0.0052 lr: 0.02
2019-03-27 06:25:58 iteration: 20425 loss: 0.0040 lr: 0.02
2019-03-27 06:26:46 iteration: 20430 loss: 0.0041 lr: 0.02
2019-03-27 06:27:25 iteration: 20435 loss: 0.0045 lr: 0.02
2019-03-27 06:28:27 iteration: 20440 loss: 0.0033 lr: 0.02
2019-03-27 06:28:59 iteration: 20445 loss: 0.0032 lr: 0.02
2019-03-27 06:29:39 iteration: 20450 loss: 0.0041 lr: 0.02
2019-03-27 06:29:59 iteration: 20455 loss: 0.0033 lr: 0.02
2019-03-27 06:30:55 iteration: 20460 loss: 0.0041 lr: 0.02
2019-03-27 06:31:08 iteration: 20465 loss: 0.0051 lr: 0.02
2019-03-27 06:31:25 iteration: 20470 loss: 0.0046 lr: 0.02
2019-03-27 06:32:19 iteration: 20475 loss: 0.0062 lr: 0.02
2019-03-27 06:33:07 iteration: 20480 loss: 0.0054 lr: 0.02
2019-03-27 06:33:52 iteration: 20485 loss: 0.0053 lr: 0.02
2019-03-27 06:34:28 iteration: 20490 loss: 0.0057 lr: 0.02
2019-03-27 06:35:47 iteration: 20495 loss: 0.0055 lr: 0.02
2019-03-27 06:36:35 iteration: 20500 loss: 0.0053 lr: 0.02
2019-03-27 06:37:23 iteration: 20505 loss: 0.0042 lr: 0.02
2019-03-27 06:38:15 iteration: 20510 loss: 0.0043 lr: 0.02
2019-03-27 06:39:47 iteration: 20515 loss: 0.0044 lr: 0.02
2019-03-27 06:40:07 iteration: 20520 loss: 0.0063 lr: 0.02
2019-03-27 06:40:45 iteration: 20525 loss: 0.0050 lr: 0.02
2019-03-27 06:41:01 iteration: 20530 loss: 0.0068 lr: 0.02
2019-03-27 06:41:44 iteration: 20535 loss: 0.0034 lr: 0.02
2019-03-27 06:42:11 iteration: 20540 loss: 0.0048 lr: 0.02
2019-03-27 06:42:50 iteration: 20545 loss: 0.0047 lr: 0.02
2019-03-27 06:43:11 iteration: 20550 loss: 0.0038 lr: 0.02
2019-03-27 06:43:44 iteration: 20555 loss: 0.0046 lr: 0.02
2019-03-27 06:44:02 iteration: 20560 loss: 0.0114 lr: 0.02
2019-03-27 06:44:34 iteration: 20565 loss: 0.0044 lr: 0.02
2019-03-27 06:44:48 iteration: 20570 loss: 0.0039 lr: 0.02
2019-03-27 06:45:15 iteration: 20575 loss: 0.0056 lr: 0.02
2019-03-27 06:45:34 iteration: 20580 loss: 0.0061 lr: 0.02
2019-03-27 06:46:26 iteration: 20585 loss: 0.0036 lr: 0.02
2019-03-27 06:47:22 iteration: 20590 loss: 0.0046 lr: 0.02
2019-03-27 06:47:49 iteration: 20595 loss: 0.0068 lr: 0.02
2019-03-27 06:48:05 iteration: 20600 loss: 0.0045 lr: 0.02
2019-03-27 06:48:33 iteration: 20605 loss: 0.0053 lr: 0.02
2019-03-27 06:49:08 iteration: 20610 loss: 0.0038 lr: 0.02
2019-03-27 06:49:36 iteration: 20615 loss: 0.0084 lr: 0.02
2019-03-27 06:50:26 iteration: 20620 loss: 0.0045 lr: 0.02
2019-03-27 06:50:35 iteration: 20625 loss: 0.0057 lr: 0.02
2019-03-27 06:51:31 iteration: 20630 loss: 0.0049 lr: 0.02
2019-03-27 06:52:43 iteration: 20635 loss: 0.0034 lr: 0.02
2019-03-27 06:52:58 iteration: 20640 loss: 0.0066 lr: 0.02
2019-03-27 06:53:11 iteration: 20645 loss: 0.0064 lr: 0.02
2019-03-27 06:54:06 iteration: 20650 loss: 0.0047 lr: 0.02
2019-03-27 06:54:58 iteration: 20655 loss: 0.0031 lr: 0.02
2019-03-27 06:55:11 iteration: 20660 loss: 0.0098 lr: 0.02
2019-03-27 06:55:41 iteration: 20665 loss: 0.0036 lr: 0.02
2019-03-27 06:56:11 iteration: 20670 loss: 0.0052 lr: 0.02
2019-03-27 06:56:29 iteration: 20675 loss: 0.0052 lr: 0.02
2019-03-27 06:56:43 iteration: 20680 loss: 0.0039 lr: 0.02
2019-03-27 06:58:00 iteration: 20685 loss: 0.0050 lr: 0.02
2019-03-27 06:58:28 iteration: 20690 loss: 0.0070 lr: 0.02
2019-03-27 06:59:49 iteration: 20695 loss: 0.0039 lr: 0.02
2019-03-27 07:00:02 iteration: 20700 loss: 0.0051 lr: 0.02
2019-03-27 07:00:56 iteration: 20705 loss: 0.0048 lr: 0.02
2019-03-27 07:01:30 iteration: 20710 loss: 0.0051 lr: 0.02
2019-03-27 07:02:03 iteration: 20715 loss: 0.0054 lr: 0.02
2019-03-27 07:02:23 iteration: 20720 loss: 0.0051 lr: 0.02
2019-03-27 07:03:21 iteration: 20725 loss: 0.0057 lr: 0.02
2019-03-27 07:03:55 iteration: 20730 loss: 0.0053 lr: 0.02
2019-03-27 07:04:20 iteration: 20735 loss: 0.0056 lr: 0.02
2019-03-27 07:05:26 iteration: 20740 loss: 0.0048 lr: 0.02
2019-03-27 07:05:53 iteration: 20745 loss: 0.0064 lr: 0.02
2019-03-27 07:06:30 iteration: 20750 loss: 0.0043 lr: 0.02
2019-03-27 07:06:55 iteration: 20755 loss: 0.0041 lr: 0.02
2019-03-27 07:07:35 iteration: 20760 loss: 0.0044 lr: 0.02
2019-03-27 07:07:48 iteration: 20765 loss: 0.0060 lr: 0.02
2019-03-27 07:08:09 iteration: 20770 loss: 0.0048 lr: 0.02
2019-03-27 07:08:31 iteration: 20775 loss: 0.0049 lr: 0.02
2019-03-27 07:09:12 iteration: 20780 loss: 0.0064 lr: 0.02
2019-03-27 07:09:41 iteration: 20785 loss: 0.0059 lr: 0.02
2019-03-27 07:10:07 iteration: 20790 loss: 0.0043 lr: 0.02
2019-03-27 07:10:59 iteration: 20795 loss: 0.0050 lr: 0.02
2019-03-27 07:11:55 iteration: 20800 loss: 0.0028 lr: 0.02
2019-03-27 07:12:52 iteration: 20805 loss: 0.0041 lr: 0.02
2019-03-27 07:13:21 iteration: 20810 loss: 0.0054 lr: 0.02
2019-03-27 07:15:07 iteration: 20815 loss: 0.0055 lr: 0.02
2019-03-27 07:16:04 iteration: 20820 loss: 0.0043 lr: 0.02
2019-03-27 07:17:02 iteration: 20825 loss: 0.0046 lr: 0.02
2019-03-27 07:17:37 iteration: 20830 loss: 0.0046 lr: 0.02
2019-03-27 07:18:13 iteration: 20835 loss: 0.0049 lr: 0.02
2019-03-27 07:19:04 iteration: 20840 loss: 0.0048 lr: 0.02
2019-03-27 07:19:51 iteration: 20845 loss: 0.0046 lr: 0.02
2019-03-27 07:20:46 iteration: 20850 loss: 0.0053 lr: 0.02
2019-03-27 07:21:49 iteration: 20855 loss: 0.0039 lr: 0.02
2019-03-27 07:22:35 iteration: 20860 loss: 0.0042 lr: 0.02
2019-03-27 07:23:20 iteration: 20865 loss: 0.0047 lr: 0.02
2019-03-27 07:23:41 iteration: 20870 loss: 0.0046 lr: 0.02
2019-03-27 07:24:35 iteration: 20875 loss: 0.0041 lr: 0.02
2019-03-27 07:24:54 iteration: 20880 loss: 0.0044 lr: 0.02
2019-03-27 07:25:38 iteration: 20885 loss: 0.0062 lr: 0.02
2019-03-27 07:26:28 iteration: 20890 loss: 0.0042 lr: 0.02
2019-03-27 07:27:12 iteration: 20895 loss: 0.0061 lr: 0.02
2019-03-27 07:27:55 iteration: 20900 loss: 0.0041 lr: 0.02
2019-03-27 07:28:16 iteration: 20905 loss: 0.0046 lr: 0.02
2019-03-27 07:28:50 iteration: 20910 loss: 0.0038 lr: 0.02
2019-03-27 07:29:08 iteration: 20915 loss: 0.0045 lr: 0.02
2019-03-27 07:29:21 iteration: 20920 loss: 0.0074 lr: 0.02
2019-03-27 07:29:45 iteration: 20925 loss: 0.0051 lr: 0.02
2019-03-27 07:30:08 iteration: 20930 loss: 0.0045 lr: 0.02
2019-03-27 07:30:33 iteration: 20935 loss: 0.0039 lr: 0.02
2019-03-27 07:30:43 iteration: 20940 loss: 0.0066 lr: 0.02
2019-03-27 07:32:22 iteration: 20945 loss: 0.0028 lr: 0.02
2019-03-27 07:33:07 iteration: 20950 loss: 0.0039 lr: 0.02
2019-03-27 07:33:55 iteration: 20955 loss: 0.0047 lr: 0.02
2019-03-27 07:35:01 iteration: 20960 loss: 0.0031 lr: 0.02
2019-03-27 07:35:25 iteration: 20965 loss: 0.0055 lr: 0.02
2019-03-27 07:35:45 iteration: 20970 loss: 0.0078 lr: 0.02
2019-03-27 07:36:39 iteration: 20975 loss: 0.0036 lr: 0.02
2019-03-27 07:37:32 iteration: 20980 loss: 0.0039 lr: 0.02
2019-03-27 07:38:57 iteration: 20985 loss: 0.0048 lr: 0.02
2019-03-27 07:39:14 iteration: 20990 loss: 0.0050 lr: 0.02
2019-03-27 07:39:49 iteration: 20995 loss: 0.0043 lr: 0.02
2019-03-27 07:40:25 iteration: 21000 loss: 0.0056 lr: 0.02
2019-03-27 07:41:06 iteration: 21005 loss: 0.0047 lr: 0.02
2019-03-27 07:41:31 iteration: 21010 loss: 0.0051 lr: 0.02
2019-03-27 07:42:04 iteration: 21015 loss: 0.0034 lr: 0.02
2019-03-27 07:42:35 iteration: 21020 loss: 0.0039 lr: 0.02
2019-03-27 07:43:25 iteration: 21025 loss: 0.0037 lr: 0.02
2019-03-27 07:43:45 iteration: 21030 loss: 0.0051 lr: 0.02
2019-03-27 07:44:05 iteration: 21035 loss: 0.0048 lr: 0.02
2019-03-27 07:45:03 iteration: 21040 loss: 0.0059 lr: 0.02
2019-03-27 07:45:50 iteration: 21045 loss: 0.0033 lr: 0.02
2019-03-27 07:46:18 iteration: 21050 loss: 0.0058 lr: 0.02
2019-03-27 07:46:25 iteration: 21055 loss: 0.0067 lr: 0.02
2019-03-27 07:46:34 iteration: 21060 loss: 0.0050 lr: 0.02
2019-03-27 07:46:59 iteration: 21065 loss: 0.0045 lr: 0.02
2019-03-27 07:47:29 iteration: 21070 loss: 0.0055 lr: 0.02
2019-03-27 07:48:13 iteration: 21075 loss: 0.0049 lr: 0.02
2019-03-27 07:48:36 iteration: 21080 loss: 0.0056 lr: 0.02
2019-03-27 07:49:19 iteration: 21085 loss: 0.0044 lr: 0.02
2019-03-27 07:49:43 iteration: 21090 loss: 0.0058 lr: 0.02
2019-03-27 07:49:57 iteration: 21095 loss: 0.0042 lr: 0.02
2019-03-27 07:50:09 iteration: 21100 loss: 0.0052 lr: 0.02
2019-03-27 07:50:30 iteration: 21105 loss: 0.0060 lr: 0.02
2019-03-27 07:51:20 iteration: 21110 loss: 0.0045 lr: 0.02
2019-03-27 07:51:54 iteration: 21115 loss: 0.0037 lr: 0.02
2019-03-27 07:52:27 iteration: 21120 loss: 0.0038 lr: 0.02
2019-03-27 07:52:50 iteration: 21125 loss: 0.0040 lr: 0.02
2019-03-27 07:53:45 iteration: 21130 loss: 0.0031 lr: 0.02
2019-03-27 07:54:26 iteration: 21135 loss: 0.0052 lr: 0.02
2019-03-27 07:54:42 iteration: 21140 loss: 0.0048 lr: 0.02
2019-03-27 07:55:58 iteration: 21145 loss: 0.0036 lr: 0.02
2019-03-27 07:56:13 iteration: 21150 loss: 0.0067 lr: 0.02
2019-03-27 07:57:08 iteration: 21155 loss: 0.0065 lr: 0.02
2019-03-27 07:57:28 iteration: 21160 loss: 0.0092 lr: 0.02
2019-03-27 07:57:55 iteration: 21165 loss: 0.0050 lr: 0.02
2019-03-27 07:58:24 iteration: 21170 loss: 0.0044 lr: 0.02
2019-03-27 07:59:36 iteration: 21175 loss: 0.0025 lr: 0.02
2019-03-27 08:00:51 iteration: 21180 loss: 0.0037 lr: 0.02
2019-03-27 08:01:03 iteration: 21185 loss: 0.0044 lr: 0.02
2019-03-27 08:01:47 iteration: 21190 loss: 0.0066 lr: 0.02
2019-03-27 08:02:05 iteration: 21195 loss: 0.0057 lr: 0.02
2019-03-27 08:02:45 iteration: 21200 loss: 0.0036 lr: 0.02
2019-03-27 08:03:30 iteration: 21205 loss: 0.0046 lr: 0.02
2019-03-27 08:03:47 iteration: 21210 loss: 0.0057 lr: 0.02
2019-03-27 08:04:10 iteration: 21215 loss: 0.0073 lr: 0.02
2019-03-27 08:04:57 iteration: 21220 loss: 0.0053 lr: 0.02
2019-03-27 08:06:08 iteration: 21225 loss: 0.0036 lr: 0.02
2019-03-27 08:07:01 iteration: 21230 loss: 0.0035 lr: 0.02
2019-03-27 08:07:52 iteration: 21235 loss: 0.0049 lr: 0.02
2019-03-27 08:08:46 iteration: 21240 loss: 0.0054 lr: 0.02
2019-03-27 08:10:03 iteration: 21245 loss: 0.0042 lr: 0.02
2019-03-27 08:10:32 iteration: 21250 loss: 0.0032 lr: 0.02
2019-03-27 08:11:33 iteration: 21255 loss: 0.0044 lr: 0.02
2019-03-27 08:11:47 iteration: 21260 loss: 0.0103 lr: 0.02
2019-03-27 08:11:58 iteration: 21265 loss: 0.0046 lr: 0.02
2019-03-27 08:12:29 iteration: 21270 loss: 0.0054 lr: 0.02
2019-03-27 08:13:18 iteration: 21275 loss: 0.0050 lr: 0.02
2019-03-27 08:13:59 iteration: 21280 loss: 0.0042 lr: 0.02
2019-03-27 08:14:12 iteration: 21285 loss: 0.0048 lr: 0.02
2019-03-27 08:14:42 iteration: 21290 loss: 0.0049 lr: 0.02
2019-03-27 08:14:53 iteration: 21295 loss: 0.0062 lr: 0.02
2019-03-27 08:15:07 iteration: 21300 loss: 0.0070 lr: 0.02
2019-03-27 08:16:44 iteration: 21305 loss: 0.0057 lr: 0.02
2019-03-27 08:17:01 iteration: 21310 loss: 0.0042 lr: 0.02
2019-03-27 08:17:51 iteration: 21315 loss: 0.0051 lr: 0.02
2019-03-27 08:18:50 iteration: 21320 loss: 0.0037 lr: 0.02
2019-03-27 08:19:28 iteration: 21325 loss: 0.0085 lr: 0.02
2019-03-27 08:19:55 iteration: 21330 loss: 0.0045 lr: 0.02
2019-03-27 08:20:50 iteration: 21335 loss: 0.0051 lr: 0.02
2019-03-27 08:21:02 iteration: 21340 loss: 0.0041 lr: 0.02
2019-03-27 08:21:34 iteration: 21345 loss: 0.0041 lr: 0.02
2019-03-27 08:22:03 iteration: 21350 loss: 0.0057 lr: 0.02
2019-03-27 08:23:03 iteration: 21355 loss: 0.0046 lr: 0.02
2019-03-27 08:23:58 iteration: 21360 loss: 0.0037 lr: 0.02
2019-03-27 08:24:15 iteration: 21365 loss: 0.0060 lr: 0.02
2019-03-27 08:24:50 iteration: 21370 loss: 0.0044 lr: 0.02
2019-03-27 08:25:02 iteration: 21375 loss: 0.0046 lr: 0.02
2019-03-27 08:26:06 iteration: 21380 loss: 0.0040 lr: 0.02
2019-03-27 08:26:50 iteration: 21385 loss: 0.0061 lr: 0.02
2019-03-27 08:27:20 iteration: 21390 loss: 0.0035 lr: 0.02
2019-03-27 08:28:17 iteration: 21395 loss: 0.0038 lr: 0.02
2019-03-27 08:28:31 iteration: 21400 loss: 0.0042 lr: 0.02
2019-03-27 08:29:15 iteration: 21405 loss: 0.0043 lr: 0.02
2019-03-27 08:30:04 iteration: 21410 loss: 0.0048 lr: 0.02
2019-03-27 08:30:21 iteration: 21415 loss: 0.0062 lr: 0.02
2019-03-27 08:31:09 iteration: 21420 loss: 0.0046 lr: 0.02
2019-03-27 08:32:00 iteration: 21425 loss: 0.0048 lr: 0.02
2019-03-27 08:32:10 iteration: 21430 loss: 0.0051 lr: 0.02
2019-03-27 08:32:35 iteration: 21435 loss: 0.0040 lr: 0.02
2019-03-27 08:33:04 iteration: 21440 loss: 0.0044 lr: 0.02
2019-03-27 08:34:14 iteration: 21445 loss: 0.0059 lr: 0.02
2019-03-27 08:34:52 iteration: 21450 loss: 0.0055 lr: 0.02
2019-03-27 08:35:14 iteration: 21455 loss: 0.0048 lr: 0.02
2019-03-27 08:35:24 iteration: 21460 loss: 0.0052 lr: 0.02
2019-03-27 08:36:13 iteration: 21465 loss: 0.0062 lr: 0.02
2019-03-27 08:36:37 iteration: 21470 loss: 0.0061 lr: 0.02
2019-03-27 08:37:13 iteration: 21475 loss: 0.0045 lr: 0.02
2019-03-27 08:38:10 iteration: 21480 loss: 0.0053 lr: 0.02
2019-03-27 08:38:46 iteration: 21485 loss: 0.0045 lr: 0.02
2019-03-27 08:39:31 iteration: 21490 loss: 0.0057 lr: 0.02
2019-03-27 08:39:55 iteration: 21495 loss: 0.0044 lr: 0.02
2019-03-27 08:40:10 iteration: 21500 loss: 0.0059 lr: 0.02
2019-03-27 08:41:10 iteration: 21505 loss: 0.0035 lr: 0.02
2019-03-27 08:41:25 iteration: 21510 loss: 0.0057 lr: 0.02
2019-03-27 08:42:25 iteration: 21515 loss: 0.0070 lr: 0.02
2019-03-27 08:43:02 iteration: 21520 loss: 0.0029 lr: 0.02
2019-03-27 08:44:24 iteration: 21525 loss: 0.0044 lr: 0.02
2019-03-27 08:45:15 iteration: 21530 loss: 0.0049 lr: 0.02
2019-03-27 08:45:45 iteration: 21535 loss: 0.0045 lr: 0.02
2019-03-27 08:46:39 iteration: 21540 loss: 0.0041 lr: 0.02
2019-03-27 08:47:02 iteration: 21545 loss: 0.0047 lr: 0.02
2019-03-27 08:47:47 iteration: 21550 loss: 0.0039 lr: 0.02
2019-03-27 08:48:32 iteration: 21555 loss: 0.0044 lr: 0.02
2019-03-27 08:48:52 iteration: 21560 loss: 0.0043 lr: 0.02
2019-03-27 08:49:18 iteration: 21565 loss: 0.0037 lr: 0.02
2019-03-27 08:50:12 iteration: 21570 loss: 0.0043 lr: 0.02
2019-03-27 08:50:54 iteration: 21575 loss: 0.0056 lr: 0.02
2019-03-27 08:51:06 iteration: 21580 loss: 0.0039 lr: 0.02
2019-03-27 08:51:26 iteration: 21585 loss: 0.0041 lr: 0.02
2019-03-27 08:51:44 iteration: 21590 loss: 0.0065 lr: 0.02
2019-03-27 08:52:00 iteration: 21595 loss: 0.0040 lr: 0.02
2019-03-27 08:52:48 iteration: 21600 loss: 0.0037 lr: 0.02
2019-03-27 08:53:19 iteration: 21605 loss: 0.0053 lr: 0.02
2019-03-27 08:53:32 iteration: 21610 loss: 0.0056 lr: 0.02
2019-03-27 08:53:53 iteration: 21615 loss: 0.0043 lr: 0.02
2019-03-27 08:54:44 iteration: 21620 loss: 0.0044 lr: 0.02
2019-03-27 08:55:16 iteration: 21625 loss: 0.0039 lr: 0.02
2019-03-27 08:55:37 iteration: 21630 loss: 0.0054 lr: 0.02
2019-03-27 08:55:52 iteration: 21635 loss: 0.0061 lr: 0.02
2019-03-27 08:57:04 iteration: 21640 loss: 0.0035 lr: 0.02
2019-03-27 08:57:45 iteration: 21645 loss: 0.0030 lr: 0.02
2019-03-27 08:58:45 iteration: 21650 loss: 0.0036 lr: 0.02
2019-03-27 08:59:50 iteration: 21655 loss: 0.0044 lr: 0.02
2019-03-27 09:00:45 iteration: 21660 loss: 0.0078 lr: 0.02
2019-03-27 09:01:46 iteration: 21665 loss: 0.0043 lr: 0.02
2019-03-27 09:02:01 iteration: 21670 loss: 0.0043 lr: 0.02
2019-03-27 09:02:57 iteration: 21675 loss: 0.0040 lr: 0.02
2019-03-27 09:03:30 iteration: 21680 loss: 0.0060 lr: 0.02
2019-03-27 09:03:43 iteration: 21685 loss: 0.0057 lr: 0.02
2019-03-27 09:04:07 iteration: 21690 loss: 0.0047 lr: 0.02
2019-03-27 09:04:26 iteration: 21695 loss: 0.0063 lr: 0.02
2019-03-27 09:05:20 iteration: 21700 loss: 0.0064 lr: 0.02
2019-03-27 09:06:19 iteration: 21705 loss: 0.0055 lr: 0.02
2019-03-27 09:06:49 iteration: 21710 loss: 0.0038 lr: 0.02
2019-03-27 09:07:15 iteration: 21715 loss: 0.0043 lr: 0.02
2019-03-27 09:07:54 iteration: 21720 loss: 0.0048 lr: 0.02
2019-03-27 09:08:12 iteration: 21725 loss: 0.0072 lr: 0.02
2019-03-27 09:08:43 iteration: 21730 loss: 0.0052 lr: 0.02
2019-03-27 09:09:08 iteration: 21735 loss: 0.0042 lr: 0.02
2019-03-27 09:09:28 iteration: 21740 loss: 0.0044 lr: 0.02
2019-03-27 09:10:08 iteration: 21745 loss: 0.0040 lr: 0.02
2019-03-27 09:10:50 iteration: 21750 loss: 0.0069 lr: 0.02
2019-03-27 09:11:44 iteration: 21755 loss: 0.0054 lr: 0.02
2019-03-27 09:12:12 iteration: 21760 loss: 0.0075 lr: 0.02
2019-03-27 09:12:50 iteration: 21765 loss: 0.0066 lr: 0.02
2019-03-27 09:13:51 iteration: 21770 loss: 0.0050 lr: 0.02
2019-03-27 09:14:48 iteration: 21775 loss: 0.0040 lr: 0.02
2019-03-27 09:15:05 iteration: 21780 loss: 0.0043 lr: 0.02
2019-03-27 09:15:45 iteration: 21785 loss: 0.0068 lr: 0.02
2019-03-27 09:16:29 iteration: 21790 loss: 0.0043 lr: 0.02
2019-03-27 09:17:11 iteration: 21795 loss: 0.0039 lr: 0.02
2019-03-27 09:18:03 iteration: 21800 loss: 0.0054 lr: 0.02
2019-03-27 09:18:17 iteration: 21805 loss: 0.0073 lr: 0.02
2019-03-27 09:19:31 iteration: 21810 loss: 0.0047 lr: 0.02
2019-03-27 09:19:59 iteration: 21815 loss: 0.0060 lr: 0.02
2019-03-27 09:20:17 iteration: 21820 loss: 0.0053 lr: 0.02
2019-03-27 09:21:05 iteration: 21825 loss: 0.0067 lr: 0.02
2019-03-27 09:22:08 iteration: 21830 loss: 0.0051 lr: 0.02
2019-03-27 09:23:18 iteration: 21835 loss: 0.0051 lr: 0.02
2019-03-27 09:23:46 iteration: 21840 loss: 0.0055 lr: 0.02
2019-03-27 09:24:02 iteration: 21845 loss: 0.0052 lr: 0.02
2019-03-27 09:24:42 iteration: 21850 loss: 0.0059 lr: 0.02
2019-03-27 09:25:15 iteration: 21855 loss: 0.0052 lr: 0.02
2019-03-27 09:25:57 iteration: 21860 loss: 0.0093 lr: 0.02
2019-03-27 09:26:20 iteration: 21865 loss: 0.0062 lr: 0.02
2019-03-27 09:26:52 iteration: 21870 loss: 0.0056 lr: 0.02
2019-03-27 09:27:49 iteration: 21875 loss: 0.0050 lr: 0.02
2019-03-27 09:28:04 iteration: 21880 loss: 0.0043 lr: 0.02
2019-03-27 09:28:22 iteration: 21885 loss: 0.0047 lr: 0.02
2019-03-27 09:28:54 iteration: 21890 loss: 0.0053 lr: 0.02
2019-03-27 09:29:30 iteration: 21895 loss: 0.0066 lr: 0.02
2019-03-27 09:29:46 iteration: 21900 loss: 0.0055 lr: 0.02
2019-03-27 09:30:30 iteration: 21905 loss: 0.0048 lr: 0.02
2019-03-27 09:30:49 iteration: 21910 loss: 0.0048 lr: 0.02
2019-03-27 09:31:15 iteration: 21915 loss: 0.0035 lr: 0.02
2019-03-27 09:33:07 iteration: 21920 loss: 0.0037 lr: 0.02
2019-03-27 09:33:54 iteration: 21925 loss: 0.0037 lr: 0.02
2019-03-27 09:34:06 iteration: 21930 loss: 0.0048 lr: 0.02
2019-03-27 09:34:44 iteration: 21935 loss: 0.0061 lr: 0.02
2019-03-27 09:35:30 iteration: 21940 loss: 0.0051 lr: 0.02
2019-03-27 09:35:57 iteration: 21945 loss: 0.0052 lr: 0.02
2019-03-27 09:36:45 iteration: 21950 loss: 0.0046 lr: 0.02
2019-03-27 09:37:30 iteration: 21955 loss: 0.0045 lr: 0.02
2019-03-27 09:38:56 iteration: 21960 loss: 0.0043 lr: 0.02
2019-03-27 09:39:31 iteration: 21965 loss: 0.0046 lr: 0.02
2019-03-27 09:40:30 iteration: 21970 loss: 0.0055 lr: 0.02
2019-03-27 09:40:51 iteration: 21975 loss: 0.0040 lr: 0.02
2019-03-27 09:41:05 iteration: 21980 loss: 0.0048 lr: 0.02
2019-03-27 09:41:33 iteration: 21985 loss: 0.0042 lr: 0.02
2019-03-27 09:42:30 iteration: 21990 loss: 0.0042 lr: 0.02
2019-03-27 09:43:01 iteration: 21995 loss: 0.0039 lr: 0.02
2019-03-27 09:43:53 iteration: 22000 loss: 0.0036 lr: 0.02
2019-03-27 09:44:55 iteration: 22005 loss: 0.0048 lr: 0.02
2019-03-27 09:45:40 iteration: 22010 loss: 0.0039 lr: 0.02
2019-03-27 09:46:02 iteration: 22015 loss: 0.0059 lr: 0.02
2019-03-27 09:46:24 iteration: 22020 loss: 0.0043 lr: 0.02
2019-03-27 09:46:46 iteration: 22025 loss: 0.0077 lr: 0.02
2019-03-27 09:47:01 iteration: 22030 loss: 0.0047 lr: 0.02
2019-03-27 09:48:04 iteration: 22035 loss: 0.0052 lr: 0.02
2019-03-27 09:49:25 iteration: 22040 loss: 0.0045 lr: 0.02
2019-03-27 09:49:57 iteration: 22045 loss: 0.0043 lr: 0.02
2019-03-27 09:50:20 iteration: 22050 loss: 0.0056 lr: 0.02
2019-03-27 09:50:30 iteration: 22055 loss: 0.0054 lr: 0.02
2019-03-27 09:50:42 iteration: 22060 loss: 0.0056 lr: 0.02
2019-03-27 09:51:27 iteration: 22065 loss: 0.0039 lr: 0.02
2019-03-27 09:52:09 iteration: 22070 loss: 0.0076 lr: 0.02
2019-03-27 09:52:58 iteration: 22075 loss: 0.0046 lr: 0.02
2019-03-27 09:53:59 iteration: 22080 loss: 0.0044 lr: 0.02
2019-03-27 09:54:28 iteration: 22085 loss: 0.0039 lr: 0.02
2019-03-27 09:54:46 iteration: 22090 loss: 0.0062 lr: 0.02
2019-03-27 09:55:42 iteration: 22095 loss: 0.0058 lr: 0.02
2019-03-27 09:56:51 iteration: 22100 loss: 0.0038 lr: 0.02
2019-03-27 09:57:19 iteration: 22105 loss: 0.0050 lr: 0.02
2019-03-27 09:58:00 iteration: 22110 loss: 0.0046 lr: 0.02
2019-03-27 09:58:16 iteration: 22115 loss: 0.0061 lr: 0.02
2019-03-27 09:59:01 iteration: 22120 loss: 0.0047 lr: 0.02
2019-03-27 09:59:23 iteration: 22125 loss: 0.0034 lr: 0.02
2019-03-27 09:59:47 iteration: 22130 loss: 0.0074 lr: 0.02
2019-03-27 10:00:29 iteration: 22135 loss: 0.0036 lr: 0.02
2019-03-27 10:00:56 iteration: 22140 loss: 0.0048 lr: 0.02
2019-03-27 10:01:41 iteration: 22145 loss: 0.0056 lr: 0.02
2019-03-27 10:02:51 iteration: 22150 loss: 0.0028 lr: 0.02
2019-03-27 10:03:07 iteration: 22155 loss: 0.0045 lr: 0.02
2019-03-27 10:04:20 iteration: 22160 loss: 0.0042 lr: 0.02
2019-03-27 10:04:34 iteration: 22165 loss: 0.0069 lr: 0.02
2019-03-27 10:04:51 iteration: 22170 loss: 0.0049 lr: 0.02
2019-03-27 10:05:46 iteration: 22175 loss: 0.0056 lr: 0.02
2019-03-27 10:06:07 iteration: 22180 loss: 0.0052 lr: 0.02
2019-03-27 10:06:23 iteration: 22185 loss: 0.0059 lr: 0.02
2019-03-27 10:06:47 iteration: 22190 loss: 0.0047 lr: 0.02
2019-03-27 10:07:03 iteration: 22195 loss: 0.0053 lr: 0.02
2019-03-27 10:07:23 iteration: 22200 loss: 0.0071 lr: 0.02
2019-03-27 10:07:45 iteration: 22205 loss: 0.0048 lr: 0.02
2019-03-27 10:08:42 iteration: 22210 loss: 0.0039 lr: 0.02
2019-03-27 10:09:05 iteration: 22215 loss: 0.0065 lr: 0.02
2019-03-27 10:09:23 iteration: 22220 loss: 0.0057 lr: 0.02
2019-03-27 10:10:02 iteration: 22225 loss: 0.0043 lr: 0.02
2019-03-27 10:10:29 iteration: 22230 loss: 0.0059 lr: 0.02
2019-03-27 10:11:30 iteration: 22235 loss: 0.0039 lr: 0.02
2019-03-27 10:11:41 iteration: 22240 loss: 0.0066 lr: 0.02
2019-03-27 10:12:31 iteration: 22245 loss: 0.0057 lr: 0.02
2019-03-27 10:13:54 iteration: 22250 loss: 0.0054 lr: 0.02
2019-03-27 10:14:10 iteration: 22255 loss: 0.0043 lr: 0.02
2019-03-27 10:14:29 iteration: 22260 loss: 0.0041 lr: 0.02
2019-03-27 10:14:58 iteration: 22265 loss: 0.0063 lr: 0.02
2019-03-27 10:15:37 iteration: 22270 loss: 0.0060 lr: 0.02
2019-03-27 10:16:22 iteration: 22275 loss: 0.0039 lr: 0.02
2019-03-27 10:17:08 iteration: 22280 loss: 0.0036 lr: 0.02
2019-03-27 10:18:00 iteration: 22285 loss: 0.0038 lr: 0.02
2019-03-27 10:18:59 iteration: 22290 loss: 0.0042 lr: 0.02
2019-03-27 10:19:15 iteration: 22295 loss: 0.0081 lr: 0.02
2019-03-27 10:19:34 iteration: 22300 loss: 0.0053 lr: 0.02
2019-03-27 10:20:32 iteration: 22305 loss: 0.0037 lr: 0.02
2019-03-27 10:20:46 iteration: 22310 loss: 0.0066 lr: 0.02
2019-03-27 10:21:57 iteration: 22315 loss: 0.0051 lr: 0.02
2019-03-27 10:22:16 iteration: 22320 loss: 0.0046 lr: 0.02
2019-03-27 10:22:44 iteration: 22325 loss: 0.0049 lr: 0.02
2019-03-27 10:23:20 iteration: 22330 loss: 0.0062 lr: 0.02
2019-03-27 10:23:34 iteration: 22335 loss: 0.0046 lr: 0.02
2019-03-27 10:23:53 iteration: 22340 loss: 0.0041 lr: 0.02
2019-03-27 10:24:22 iteration: 22345 loss: 0.0045 lr: 0.02
2019-03-27 10:24:37 iteration: 22350 loss: 0.0062 lr: 0.02
2019-03-27 10:25:41 iteration: 22355 loss: 0.0055 lr: 0.02
2019-03-27 10:26:31 iteration: 22360 loss: 0.0056 lr: 0.02
2019-03-27 10:27:01 iteration: 22365 loss: 0.0053 lr: 0.02
2019-03-27 10:28:06 iteration: 22370 loss: 0.0040 lr: 0.02
2019-03-27 10:29:08 iteration: 22375 loss: 0.0033 lr: 0.02
2019-03-27 10:30:01 iteration: 22380 loss: 0.0045 lr: 0.02
2019-03-27 10:31:33 iteration: 22385 loss: 0.0041 lr: 0.02
2019-03-27 10:32:55 iteration: 22390 loss: 0.0039 lr: 0.02
2019-03-27 10:33:11 iteration: 22395 loss: 0.0048 lr: 0.02
2019-03-27 10:33:44 iteration: 22400 loss: 0.0053 lr: 0.02
2019-03-27 10:34:10 iteration: 22405 loss: 0.0044 lr: 0.02
2019-03-27 10:34:40 iteration: 22410 loss: 0.0049 lr: 0.02
2019-03-27 10:34:52 iteration: 22415 loss: 0.0060 lr: 0.02
2019-03-27 10:35:18 iteration: 22420 loss: 0.0052 lr: 0.02
2019-03-27 10:35:30 iteration: 22425 loss: 0.0042 lr: 0.02
2019-03-27 10:36:40 iteration: 22430 loss: 0.0040 lr: 0.02
2019-03-27 10:37:35 iteration: 22435 loss: 0.0047 lr: 0.02
2019-03-27 10:38:03 iteration: 22440 loss: 0.0042 lr: 0.02
2019-03-27 10:38:36 iteration: 22445 loss: 0.0051 lr: 0.02
2019-03-27 10:39:32 iteration: 22450 loss: 0.0037 lr: 0.02
2019-03-27 10:40:01 iteration: 22455 loss: 0.0048 lr: 0.02
2019-03-27 10:40:35 iteration: 22460 loss: 0.0043 lr: 0.02
2019-03-27 10:41:52 iteration: 22465 loss: 0.0035 lr: 0.02
2019-03-27 10:42:08 iteration: 22470 loss: 0.0046 lr: 0.02
2019-03-27 10:42:33 iteration: 22475 loss: 0.0046 lr: 0.02
2019-03-27 10:43:06 iteration: 22480 loss: 0.0040 lr: 0.02
2019-03-27 10:43:36 iteration: 22485 loss: 0.0049 lr: 0.02
2019-03-27 10:43:54 iteration: 22490 loss: 0.0047 lr: 0.02
2019-03-27 10:44:12 iteration: 22495 loss: 0.0070 lr: 0.02
2019-03-27 10:44:40 iteration: 22500 loss: 0.0043 lr: 0.02
2019-03-27 10:45:53 iteration: 22505 loss: 0.0034 lr: 0.02
2019-03-27 10:46:41 iteration: 22510 loss: 0.0058 lr: 0.02
2019-03-27 10:47:06 iteration: 22515 loss: 0.0065 lr: 0.02
2019-03-27 10:48:31 iteration: 22520 loss: 0.0056 lr: 0.02
2019-03-27 10:48:51 iteration: 22525 loss: 0.0040 lr: 0.02
2019-03-27 10:49:12 iteration: 22530 loss: 0.0054 lr: 0.02
2019-03-27 10:49:37 iteration: 22535 loss: 0.0052 lr: 0.02
2019-03-27 10:50:35 iteration: 22540 loss: 0.0053 lr: 0.02
2019-03-27 10:50:47 iteration: 22545 loss: 0.0046 lr: 0.02
2019-03-27 10:51:29 iteration: 22550 loss: 0.0046 lr: 0.02
2019-03-27 10:53:21 iteration: 22555 loss: 0.0030 lr: 0.02
2019-03-27 10:53:33 iteration: 22560 loss: 0.0060 lr: 0.02
2019-03-27 10:54:56 iteration: 22565 loss: 0.0032 lr: 0.02
2019-03-27 10:55:32 iteration: 22570 loss: 0.0044 lr: 0.02
2019-03-27 10:55:50 iteration: 22575 loss: 0.0080 lr: 0.02
2019-03-27 10:56:05 iteration: 22580 loss: 0.0057 lr: 0.02
2019-03-27 10:56:59 iteration: 22585 loss: 0.0035 lr: 0.02
2019-03-27 10:57:42 iteration: 22590 loss: 0.0028 lr: 0.02
2019-03-27 10:58:37 iteration: 22595 loss: 0.0043 lr: 0.02
2019-03-27 11:00:22 iteration: 22600 loss: 0.0043 lr: 0.02
2019-03-27 11:00:33 iteration: 22605 loss: 0.0065 lr: 0.02
2019-03-27 11:01:12 iteration: 22610 loss: 0.0042 lr: 0.02
2019-03-27 11:01:36 iteration: 22615 loss: 0.0051 lr: 0.02
2019-03-27 11:02:22 iteration: 22620 loss: 0.0044 lr: 0.02
2019-03-27 11:03:06 iteration: 22625 loss: 0.0045 lr: 0.02
2019-03-27 11:03:18 iteration: 22630 loss: 0.0043 lr: 0.02
2019-03-27 11:04:12 iteration: 22635 loss: 0.0065 lr: 0.02
2019-03-27 11:05:12 iteration: 22640 loss: 0.0036 lr: 0.02
2019-03-27 11:05:59 iteration: 22645 loss: 0.0053 lr: 0.02
2019-03-27 11:06:15 iteration: 22650 loss: 0.0066 lr: 0.02
2019-03-27 11:06:42 iteration: 22655 loss: 0.0055 lr: 0.02
2019-03-27 11:07:33 iteration: 22660 loss: 0.0063 lr: 0.02
2019-03-27 11:08:07 iteration: 22665 loss: 0.0062 lr: 0.02
2019-03-27 11:08:35 iteration: 22670 loss: 0.0048 lr: 0.02
2019-03-27 11:09:25 iteration: 22675 loss: 0.0055 lr: 0.02
2019-03-27 11:09:49 iteration: 22680 loss: 0.0064 lr: 0.02
2019-03-27 11:10:27 iteration: 22685 loss: 0.0041 lr: 0.02
2019-03-27 11:11:04 iteration: 22690 loss: 0.0046 lr: 0.02
2019-03-27 11:11:28 iteration: 22695 loss: 0.0041 lr: 0.02
2019-03-27 11:12:57 iteration: 22700 loss: 0.0040 lr: 0.02
2019-03-27 11:13:22 iteration: 22705 loss: 0.0044 lr: 0.02
2019-03-27 11:14:37 iteration: 22710 loss: 0.0037 lr: 0.02
2019-03-27 11:15:20 iteration: 22715 loss: 0.0034 lr: 0.02
2019-03-27 11:15:55 iteration: 22720 loss: 0.0042 lr: 0.02
2019-03-27 11:16:54 iteration: 22725 loss: 0.0056 lr: 0.02
2019-03-27 11:17:40 iteration: 22730 loss: 0.0045 lr: 0.02
2019-03-27 11:17:57 iteration: 22735 loss: 0.0054 lr: 0.02
2019-03-27 11:18:57 iteration: 22740 loss: 0.0045 lr: 0.02
2019-03-27 11:19:31 iteration: 22745 loss: 0.0043 lr: 0.02
2019-03-27 11:20:02 iteration: 22750 loss: 0.0043 lr: 0.02
2019-03-27 11:20:54 iteration: 22755 loss: 0.0077 lr: 0.02
2019-03-27 11:21:13 iteration: 22760 loss: 0.0048 lr: 0.02
2019-03-27 11:21:45 iteration: 22765 loss: 0.0041 lr: 0.02
2019-03-27 11:22:34 iteration: 22770 loss: 0.0042 lr: 0.02
2019-03-27 11:23:57 iteration: 22775 loss: 0.0033 lr: 0.02
2019-03-27 11:24:14 iteration: 22780 loss: 0.0050 lr: 0.02
2019-03-27 11:24:47 iteration: 22785 loss: 0.0053 lr: 0.02
2019-03-27 11:26:11 iteration: 22790 loss: 0.0051 lr: 0.02
2019-03-27 11:26:38 iteration: 22795 loss: 0.0061 lr: 0.02
2019-03-27 11:27:00 iteration: 22800 loss: 0.0049 lr: 0.02
2019-03-27 11:27:46 iteration: 22805 loss: 0.0046 lr: 0.02
2019-03-27 11:28:52 iteration: 22810 loss: 0.0057 lr: 0.02
2019-03-27 11:29:08 iteration: 22815 loss: 0.0046 lr: 0.02
2019-03-27 11:29:26 iteration: 22820 loss: 0.0053 lr: 0.02
2019-03-27 11:29:47 iteration: 22825 loss: 0.0052 lr: 0.02
2019-03-27 11:30:20 iteration: 22830 loss: 0.0059 lr: 0.02
2019-03-27 11:30:36 iteration: 22835 loss: 0.0060 lr: 0.02
2019-03-27 11:31:18 iteration: 22840 loss: 0.0042 lr: 0.02
2019-03-27 11:32:18 iteration: 22845 loss: 0.0063 lr: 0.02
2019-03-27 11:33:07 iteration: 22850 loss: 0.0055 lr: 0.02
2019-03-27 11:33:59 iteration: 22855 loss: 0.0045 lr: 0.02
2019-03-27 11:35:29 iteration: 22860 loss: 0.0044 lr: 0.02
2019-03-27 11:36:18 iteration: 22865 loss: 0.0046 lr: 0.02
2019-03-27 11:37:03 iteration: 22870 loss: 0.0048 lr: 0.02
2019-03-27 11:38:39 iteration: 22875 loss: 0.0041 lr: 0.02
2019-03-27 11:39:48 iteration: 22880 loss: 0.0047 lr: 0.02
2019-03-27 11:40:15 iteration: 22885 loss: 0.0049 lr: 0.02
2019-03-27 11:40:36 iteration: 22890 loss: 0.0048 lr: 0.02
2019-03-27 11:41:42 iteration: 22895 loss: 0.0043 lr: 0.02
2019-03-27 11:42:15 iteration: 22900 loss: 0.0049 lr: 0.02
2019-03-27 11:42:34 iteration: 22905 loss: 0.0064 lr: 0.02
2019-03-27 11:43:05 iteration: 22910 loss: 0.0061 lr: 0.02
2019-03-27 11:43:22 iteration: 22915 loss: 0.0055 lr: 0.02
2019-03-27 11:43:48 iteration: 22920 loss: 0.0065 lr: 0.02
2019-03-27 11:44:19 iteration: 22925 loss: 0.0078 lr: 0.02
2019-03-27 11:44:46 iteration: 22930 loss: 0.0041 lr: 0.02
2019-03-27 11:45:22 iteration: 22935 loss: 0.0052 lr: 0.02
2019-03-27 11:45:43 iteration: 22940 loss: 0.0058 lr: 0.02
2019-03-27 11:46:22 iteration: 22945 loss: 0.0045 lr: 0.02
2019-03-27 11:47:45 iteration: 22950 loss: 0.0056 lr: 0.02
2019-03-27 11:48:35 iteration: 22955 loss: 0.0057 lr: 0.02
2019-03-27 11:48:57 iteration: 22960 loss: 0.0046 lr: 0.02
2019-03-27 11:49:50 iteration: 22965 loss: 0.0046 lr: 0.02
2019-03-27 11:50:08 iteration: 22970 loss: 0.0044 lr: 0.02
2019-03-27 11:50:50 iteration: 22975 loss: 0.0070 lr: 0.02
2019-03-27 11:51:41 iteration: 22980 loss: 0.0057 lr: 0.02
2019-03-27 11:52:44 iteration: 22985 loss: 0.0051 lr: 0.02
2019-03-27 11:53:02 iteration: 22990 loss: 0.0047 lr: 0.02
2019-03-27 11:53:32 iteration: 22995 loss: 0.0032 lr: 0.02
2019-03-27 11:53:53 iteration: 23000 loss: 0.0052 lr: 0.02
2019-03-27 11:54:36 iteration: 23005 loss: 0.0040 lr: 0.02
2019-03-27 11:55:04 iteration: 23010 loss: 0.0070 lr: 0.02
2019-03-27 11:55:50 iteration: 23015 loss: 0.0054 lr: 0.02
2019-03-27 11:57:14 iteration: 23020 loss: 0.0043 lr: 0.02
2019-03-27 11:57:59 iteration: 23025 loss: 0.0051 lr: 0.02
2019-03-27 11:58:47 iteration: 23030 loss: 0.0043 lr: 0.02
2019-03-27 11:59:42 iteration: 23035 loss: 0.0053 lr: 0.02
2019-03-27 12:00:12 iteration: 23040 loss: 0.0058 lr: 0.02
2019-03-27 12:00:31 iteration: 23045 loss: 0.0063 lr: 0.02
2019-03-27 12:00:56 iteration: 23050 loss: 0.0066 lr: 0.02
2019-03-27 12:01:15 iteration: 23055 loss: 0.0046 lr: 0.02
2019-03-27 12:02:05 iteration: 23060 loss: 0.0058 lr: 0.02
2019-03-27 12:02:19 iteration: 23065 loss: 0.0066 lr: 0.02
2019-03-27 12:02:37 iteration: 23070 loss: 0.0045 lr: 0.02
2019-03-27 12:02:54 iteration: 23075 loss: 0.0055 lr: 0.02
2019-03-27 12:03:39 iteration: 23080 loss: 0.0051 lr: 0.02
2019-03-27 12:04:46 iteration: 23085 loss: 0.0032 lr: 0.02
2019-03-27 12:05:36 iteration: 23090 loss: 0.0041 lr: 0.02
2019-03-27 12:06:25 iteration: 23095 loss: 0.0043 lr: 0.02
2019-03-27 12:07:08 iteration: 23100 loss: 0.0037 lr: 0.02
2019-03-27 12:08:00 iteration: 23105 loss: 0.0035 lr: 0.02
2019-03-27 12:08:26 iteration: 23110 loss: 0.0053 lr: 0.02
2019-03-27 12:08:40 iteration: 23115 loss: 0.0049 lr: 0.02
2019-03-27 12:08:54 iteration: 23120 loss: 0.0075 lr: 0.02
2019-03-27 12:09:30 iteration: 23125 loss: 0.0044 lr: 0.02
2019-03-27 12:09:59 iteration: 23130 loss: 0.0073 lr: 0.02
2019-03-27 12:10:50 iteration: 23135 loss: 0.0041 lr: 0.02
2019-03-27 12:11:19 iteration: 23140 loss: 0.0053 lr: 0.02
2019-03-27 12:11:36 iteration: 23145 loss: 0.0052 lr: 0.02
2019-03-27 12:12:24 iteration: 23150 loss: 0.0052 lr: 0.02
2019-03-27 12:13:15 iteration: 23155 loss: 0.0067 lr: 0.02
2019-03-27 12:13:57 iteration: 23160 loss: 0.0034 lr: 0.02
2019-03-27 12:14:26 iteration: 23165 loss: 0.0085 lr: 0.02
2019-03-27 12:15:17 iteration: 23170 loss: 0.0051 lr: 0.02
2019-03-27 12:16:02 iteration: 23175 loss: 0.0047 lr: 0.02
2019-03-27 12:16:21 iteration: 23180 loss: 0.0058 lr: 0.02
2019-03-27 12:16:32 iteration: 23185 loss: 0.0057 lr: 0.02
2019-03-27 12:17:38 iteration: 23190 loss: 0.0060 lr: 0.02
2019-03-27 12:17:57 iteration: 23195 loss: 0.0045 lr: 0.02
2019-03-27 12:18:22 iteration: 23200 loss: 0.0049 lr: 0.02
2019-03-27 12:18:38 iteration: 23205 loss: 0.0056 lr: 0.02
2019-03-27 12:19:26 iteration: 23210 loss: 0.0058 lr: 0.02
2019-03-27 12:20:13 iteration: 23215 loss: 0.0055 lr: 0.02
2019-03-27 12:20:36 iteration: 23220 loss: 0.0044 lr: 0.02
2019-03-27 12:21:27 iteration: 23225 loss: 0.0059 lr: 0.02
2019-03-27 12:22:19 iteration: 23230 loss: 0.0057 lr: 0.02
2019-03-27 12:23:00 iteration: 23235 loss: 0.0050 lr: 0.02
2019-03-27 12:23:20 iteration: 23240 loss: 0.0043 lr: 0.02
2019-03-27 12:24:05 iteration: 23245 loss: 0.0042 lr: 0.02
2019-03-27 12:24:19 iteration: 23250 loss: 0.0084 lr: 0.02
2019-03-27 12:24:55 iteration: 23255 loss: 0.0033 lr: 0.02
2019-03-27 12:25:49 iteration: 23260 loss: 0.0052 lr: 0.02
2019-03-27 12:27:08 iteration: 23265 loss: 0.0044 lr: 0.02
2019-03-27 12:28:03 iteration: 23270 loss: 0.0046 lr: 0.02
2019-03-27 12:28:20 iteration: 23275 loss: 0.0057 lr: 0.02
2019-03-27 12:28:46 iteration: 23280 loss: 0.0088 lr: 0.02
2019-03-27 12:29:13 iteration: 23285 loss: 0.0055 lr: 0.02
2019-03-27 12:29:28 iteration: 23290 loss: 0.0052 lr: 0.02
2019-03-27 12:30:00 iteration: 23295 loss: 0.0044 lr: 0.02
2019-03-27 12:30:46 iteration: 23300 loss: 0.0043 lr: 0.02
2019-03-27 12:31:14 iteration: 23305 loss: 0.0041 lr: 0.02
2019-03-27 12:31:51 iteration: 23310 loss: 0.0047 lr: 0.02
2019-03-27 12:32:16 iteration: 23315 loss: 0.0043 lr: 0.02
2019-03-27 12:33:03 iteration: 23320 loss: 0.0056 lr: 0.02
2019-03-27 12:33:42 iteration: 23325 loss: 0.0052 lr: 0.02
2019-03-27 12:34:49 iteration: 23330 loss: 0.0039 lr: 0.02
2019-03-27 12:35:08 iteration: 23335 loss: 0.0049 lr: 0.02
2019-03-27 12:36:24 iteration: 23340 loss: 0.0041 lr: 0.02
2019-03-27 12:37:25 iteration: 23345 loss: 0.0038 lr: 0.02
2019-03-27 12:38:03 iteration: 23350 loss: 0.0038 lr: 0.02
2019-03-27 12:39:12 iteration: 23355 loss: 0.0037 lr: 0.02
2019-03-27 12:39:52 iteration: 23360 loss: 0.0067 lr: 0.02
2019-03-27 12:40:06 iteration: 23365 loss: 0.0052 lr: 0.02
2019-03-27 12:40:58 iteration: 23370 loss: 0.0050 lr: 0.02
2019-03-27 12:42:05 iteration: 23375 loss: 0.0054 lr: 0.02
2019-03-27 12:42:50 iteration: 23380 loss: 0.0077 lr: 0.02
2019-03-27 12:43:11 iteration: 23385 loss: 0.0060 lr: 0.02
2019-03-27 12:43:34 iteration: 23390 loss: 0.0046 lr: 0.02
2019-03-27 12:44:29 iteration: 23395 loss: 0.0035 lr: 0.02
2019-03-27 12:45:08 iteration: 23400 loss: 0.0037 lr: 0.02
2019-03-27 12:45:47 iteration: 23405 loss: 0.0047 lr: 0.02
2019-03-27 12:46:47 iteration: 23410 loss: 0.0032 lr: 0.02
2019-03-27 12:47:53 iteration: 23415 loss: 0.0049 lr: 0.02
2019-03-27 12:48:44 iteration: 23420 loss: 0.0050 lr: 0.02
2019-03-27 12:49:02 iteration: 23425 loss: 0.0046 lr: 0.02
2019-03-27 12:49:48 iteration: 23430 loss: 0.0040 lr: 0.02
2019-03-27 12:50:35 iteration: 23435 loss: 0.0042 lr: 0.02
2019-03-27 12:50:46 iteration: 23440 loss: 0.0076 lr: 0.02
2019-03-27 12:51:23 iteration: 23445 loss: 0.0053 lr: 0.02
2019-03-27 12:52:30 iteration: 23450 loss: 0.0043 lr: 0.02
2019-03-27 12:52:57 iteration: 23455 loss: 0.0047 lr: 0.02
2019-03-27 12:53:41 iteration: 23460 loss: 0.0040 lr: 0.02
2019-03-27 12:54:01 iteration: 23465 loss: 0.0042 lr: 0.02
2019-03-27 12:54:26 iteration: 23470 loss: 0.0040 lr: 0.02
2019-03-27 12:55:22 iteration: 23475 loss: 0.0055 lr: 0.02
2019-03-27 12:56:13 iteration: 23480 loss: 0.0040 lr: 0.02
2019-03-27 12:57:23 iteration: 23485 loss: 0.0042 lr: 0.02
2019-03-27 12:57:43 iteration: 23490 loss: 0.0050 lr: 0.02
2019-03-27 12:58:09 iteration: 23495 loss: 0.0038 lr: 0.02
2019-03-27 12:58:54 iteration: 23500 loss: 0.0037 lr: 0.02
2019-03-27 12:59:33 iteration: 23505 loss: 0.0052 lr: 0.02
2019-03-27 12:59:59 iteration: 23510 loss: 0.0052 lr: 0.02
2019-03-27 13:00:19 iteration: 23515 loss: 0.0053 lr: 0.02
2019-03-27 13:00:32 iteration: 23520 loss: 0.0048 lr: 0.02
2019-03-27 13:00:52 iteration: 23525 loss: 0.0068 lr: 0.02
2019-03-27 13:01:49 iteration: 23530 loss: 0.0057 lr: 0.02
2019-03-27 13:02:57 iteration: 23535 loss: 0.0041 lr: 0.02
2019-03-27 13:03:30 iteration: 23540 loss: 0.0045 lr: 0.02
2019-03-27 13:03:50 iteration: 23545 loss: 0.0063 lr: 0.02
2019-03-27 13:04:44 iteration: 23550 loss: 0.0042 lr: 0.02
2019-03-27 13:05:35 iteration: 23555 loss: 0.0058 lr: 0.02
2019-03-27 13:06:22 iteration: 23560 loss: 0.0052 lr: 0.02
2019-03-27 13:07:17 iteration: 23565 loss: 0.0052 lr: 0.02
2019-03-27 13:07:56 iteration: 23570 loss: 0.0060 lr: 0.02
2019-03-27 13:08:29 iteration: 23575 loss: 0.0042 lr: 0.02
2019-03-27 13:08:51 iteration: 23580 loss: 0.0050 lr: 0.02
2019-03-27 13:09:31 iteration: 23585 loss: 0.0054 lr: 0.02
2019-03-27 13:10:25 iteration: 23590 loss: 0.0054 lr: 0.02
2019-03-27 13:10:42 iteration: 23595 loss: 0.0044 lr: 0.02
2019-03-27 13:10:59 iteration: 23600 loss: 0.0064 lr: 0.02
2019-03-27 13:11:23 iteration: 23605 loss: 0.0051 lr: 0.02
2019-03-27 13:11:39 iteration: 23610 loss: 0.0053 lr: 0.02
2019-03-27 13:11:59 iteration: 23615 loss: 0.0057 lr: 0.02
2019-03-27 13:12:25 iteration: 23620 loss: 0.0062 lr: 0.02
2019-03-27 13:12:55 iteration: 23625 loss: 0.0046 lr: 0.02
2019-03-27 13:13:04 iteration: 23630 loss: 0.0049 lr: 0.02
2019-03-27 13:13:21 iteration: 23635 loss: 0.0039 lr: 0.02
2019-03-27 13:13:53 iteration: 23640 loss: 0.0034 lr: 0.02
2019-03-27 13:15:06 iteration: 23645 loss: 0.0063 lr: 0.02
2019-03-27 13:15:53 iteration: 23650 loss: 0.0043 lr: 0.02
2019-03-27 13:16:27 iteration: 23655 loss: 0.0043 lr: 0.02
2019-03-27 13:18:00 iteration: 23660 loss: 0.0057 lr: 0.02
2019-03-27 13:18:29 iteration: 23665 loss: 0.0037 lr: 0.02
2019-03-27 13:20:15 iteration: 23670 loss: 0.0044 lr: 0.02
2019-03-27 13:20:45 iteration: 23675 loss: 0.0042 lr: 0.02
2019-03-27 13:21:02 iteration: 23680 loss: 0.0056 lr: 0.02
2019-03-27 13:22:26 iteration: 23685 loss: 0.0031 lr: 0.02
2019-03-27 13:23:07 iteration: 23690 loss: 0.0064 lr: 0.02
2019-03-27 13:24:01 iteration: 23695 loss: 0.0064 lr: 0.02
2019-03-27 13:24:56 iteration: 23700 loss: 0.0046 lr: 0.02
2019-03-27 13:25:34 iteration: 23705 loss: 0.0052 lr: 0.02
2019-03-27 13:26:05 iteration: 23710 loss: 0.0038 lr: 0.02
2019-03-27 13:26:49 iteration: 23715 loss: 0.0050 lr: 0.02
2019-03-27 13:28:08 iteration: 23720 loss: 0.0081 lr: 0.02
2019-03-27 13:28:31 iteration: 23725 loss: 0.0061 lr: 0.02
2019-03-27 13:29:15 iteration: 23730 loss: 0.0057 lr: 0.02
2019-03-27 13:29:50 iteration: 23735 loss: 0.0051 lr: 0.02
2019-03-27 13:30:55 iteration: 23740 loss: 0.0044 lr: 0.02
2019-03-27 13:31:46 iteration: 23745 loss: 0.0040 lr: 0.02
2019-03-27 13:32:17 iteration: 23750 loss: 0.0045 lr: 0.02
2019-03-27 13:32:31 iteration: 23755 loss: 0.0062 lr: 0.02
2019-03-27 13:32:58 iteration: 23760 loss: 0.0040 lr: 0.02
2019-03-27 13:33:30 iteration: 23765 loss: 0.0039 lr: 0.02
2019-03-27 13:33:48 iteration: 23770 loss: 0.0045 lr: 0.02
2019-03-27 13:34:20 iteration: 23775 loss: 0.0051 lr: 0.02
2019-03-27 13:35:28 iteration: 23780 loss: 0.0047 lr: 0.02
2019-03-27 13:35:40 iteration: 23785 loss: 0.0066 lr: 0.02
2019-03-27 13:36:26 iteration: 23790 loss: 0.0036 lr: 0.02
2019-03-27 13:37:22 iteration: 23795 loss: 0.0039 lr: 0.02
2019-03-27 13:37:49 iteration: 23800 loss: 0.0038 lr: 0.02
2019-03-27 13:38:06 iteration: 23805 loss: 0.0043 lr: 0.02
2019-03-27 13:39:06 iteration: 23810 loss: 0.0037 lr: 0.02
2019-03-27 13:40:03 iteration: 23815 loss: 0.0039 lr: 0.02
2019-03-27 13:40:42 iteration: 23820 loss: 0.0028 lr: 0.02
2019-03-27 13:41:00 iteration: 23825 loss: 0.0062 lr: 0.02
2019-03-27 13:41:25 iteration: 23830 loss: 0.0051 lr: 0.02
2019-03-27 13:41:45 iteration: 23835 loss: 0.0046 lr: 0.02
2019-03-27 13:42:32 iteration: 23840 loss: 0.0044 lr: 0.02
2019-03-27 13:43:08 iteration: 23845 loss: 0.0042 lr: 0.02
2019-03-27 13:44:05 iteration: 23850 loss: 0.0054 lr: 0.02
2019-03-27 13:44:20 iteration: 23855 loss: 0.0041 lr: 0.02
2019-03-27 13:45:22 iteration: 23860 loss: 0.0039 lr: 0.02
2019-03-27 13:46:06 iteration: 23865 loss: 0.0036 lr: 0.02
2019-03-27 13:46:21 iteration: 23870 loss: 0.0062 lr: 0.02
2019-03-27 13:47:09 iteration: 23875 loss: 0.0049 lr: 0.02
2019-03-27 13:48:10 iteration: 23880 loss: 0.0038 lr: 0.02
2019-03-27 13:48:29 iteration: 23885 loss: 0.0053 lr: 0.02
2019-03-27 13:48:48 iteration: 23890 loss: 0.0057 lr: 0.02
2019-03-27 13:49:15 iteration: 23895 loss: 0.0036 lr: 0.02
2019-03-27 13:49:34 iteration: 23900 loss: 0.0061 lr: 0.02
2019-03-27 13:49:47 iteration: 23905 loss: 0.0049 lr: 0.02
2019-03-27 13:50:29 iteration: 23910 loss: 0.0053 lr: 0.02
2019-03-27 13:51:01 iteration: 23915 loss: 0.0041 lr: 0.02
2019-03-27 13:51:41 iteration: 23920 loss: 0.0055 lr: 0.02
2019-03-27 13:51:54 iteration: 23925 loss: 0.0040 lr: 0.02
2019-03-27 13:52:07 iteration: 23930 loss: 0.0069 lr: 0.02
2019-03-27 13:52:20 iteration: 23935 loss: 0.0066 lr: 0.02
2019-03-27 13:53:08 iteration: 23940 loss: 0.0043 lr: 0.02
2019-03-27 13:53:19 iteration: 23945 loss: 0.0048 lr: 0.02
2019-03-27 13:53:58 iteration: 23950 loss: 0.0046 lr: 0.02
2019-03-27 13:54:42 iteration: 23955 loss: 0.0046 lr: 0.02
2019-03-27 13:54:52 iteration: 23960 loss: 0.0050 lr: 0.02
2019-03-27 13:55:40 iteration: 23965 loss: 0.0039 lr: 0.02
2019-03-27 13:56:14 iteration: 23970 loss: 0.0037 lr: 0.02
2019-03-27 13:57:19 iteration: 23975 loss: 0.0035 lr: 0.02
2019-03-27 13:57:49 iteration: 23980 loss: 0.0044 lr: 0.02
2019-03-27 13:58:10 iteration: 23985 loss: 0.0055 lr: 0.02
2019-03-27 13:58:54 iteration: 23990 loss: 0.0047 lr: 0.02
2019-03-27 13:59:47 iteration: 23995 loss: 0.0060 lr: 0.02
2019-03-27 14:00:02 iteration: 24000 loss: 0.0048 lr: 0.02
2019-03-27 14:00:58 iteration: 24005 loss: 0.0040 lr: 0.02
2019-03-27 14:01:12 iteration: 24010 loss: 0.0049 lr: 0.02
2019-03-27 14:02:14 iteration: 24015 loss: 0.0061 lr: 0.02
2019-03-27 14:02:44 iteration: 24020 loss: 0.0046 lr: 0.02
2019-03-27 14:03:01 iteration: 24025 loss: 0.0051 lr: 0.02
2019-03-27 14:03:44 iteration: 24030 loss: 0.0036 lr: 0.02
2019-03-27 14:04:45 iteration: 24035 loss: 0.0032 lr: 0.02
2019-03-27 14:06:08 iteration: 24040 loss: 0.0024 lr: 0.02
2019-03-27 14:06:32 iteration: 24045 loss: 0.0053 lr: 0.02
2019-03-27 14:07:16 iteration: 24050 loss: 0.0044 lr: 0.02
2019-03-27 14:07:35 iteration: 24055 loss: 0.0042 lr: 0.02
2019-03-27 14:08:45 iteration: 24060 loss: 0.0045 lr: 0.02
2019-03-27 14:09:57 iteration: 24065 loss: 0.0031 lr: 0.02
2019-03-27 14:10:49 iteration: 24070 loss: 0.0041 lr: 0.02
2019-03-27 14:11:31 iteration: 24075 loss: 0.0031 lr: 0.02
2019-03-27 14:11:51 iteration: 24080 loss: 0.0053 lr: 0.02
2019-03-27 14:12:03 iteration: 24085 loss: 0.0076 lr: 0.02
2019-03-27 14:13:12 iteration: 24090 loss: 0.0044 lr: 0.02
2019-03-27 14:13:54 iteration: 24095 loss: 0.0034 lr: 0.02
2019-03-27 14:14:44 iteration: 24100 loss: 0.0045 lr: 0.02
2019-03-27 14:14:57 iteration: 24105 loss: 0.0042 lr: 0.02
2019-03-27 14:15:49 iteration: 24110 loss: 0.0054 lr: 0.02
2019-03-27 14:16:18 iteration: 24115 loss: 0.0046 lr: 0.02
2019-03-27 14:16:57 iteration: 24120 loss: 0.0048 lr: 0.02
2019-03-27 14:17:09 iteration: 24125 loss: 0.0060 lr: 0.02
2019-03-27 14:17:35 iteration: 24130 loss: 0.0075 lr: 0.02
2019-03-27 14:18:38 iteration: 24135 loss: 0.0043 lr: 0.02
2019-03-27 14:18:57 iteration: 24140 loss: 0.0062 lr: 0.02
2019-03-27 14:19:12 iteration: 24145 loss: 0.0039 lr: 0.02
2019-03-27 14:19:34 iteration: 24150 loss: 0.0051 lr: 0.02
2019-03-27 14:19:56 iteration: 24155 loss: 0.0053 lr: 0.02
2019-03-27 14:20:37 iteration: 24160 loss: 0.0087 lr: 0.02
2019-03-27 14:21:09 iteration: 24165 loss: 0.0064 lr: 0.02
2019-03-27 14:22:12 iteration: 24170 loss: 0.0040 lr: 0.02
2019-03-27 14:22:52 iteration: 24175 loss: 0.0045 lr: 0.02
2019-03-27 14:23:25 iteration: 24180 loss: 0.0052 lr: 0.02
2019-03-27 14:23:51 iteration: 24185 loss: 0.0035 lr: 0.02
2019-03-27 14:24:09 iteration: 24190 loss: 0.0053 lr: 0.02
2019-03-27 14:25:00 iteration: 24195 loss: 0.0040 lr: 0.02
2019-03-27 14:25:15 iteration: 24200 loss: 0.0043 lr: 0.02
2019-03-27 14:26:22 iteration: 24205 loss: 0.0043 lr: 0.02
2019-03-27 14:27:00 iteration: 24210 loss: 0.0034 lr: 0.02
2019-03-27 14:27:19 iteration: 24215 loss: 0.0044 lr: 0.02
2019-03-27 14:28:38 iteration: 24220 loss: 0.0031 lr: 0.02
2019-03-27 14:29:31 iteration: 24225 loss: 0.0050 lr: 0.02
2019-03-27 14:29:57 iteration: 24230 loss: 0.0039 lr: 0.02
2019-03-27 14:30:16 iteration: 24235 loss: 0.0054 lr: 0.02
2019-03-27 14:30:33 iteration: 24240 loss: 0.0045 lr: 0.02
2019-03-27 14:31:05 iteration: 24245 loss: 0.0030 lr: 0.02
2019-03-27 14:31:26 iteration: 24250 loss: 0.0056 lr: 0.02
2019-03-27 14:31:58 iteration: 24255 loss: 0.0061 lr: 0.02
2019-03-27 14:32:38 iteration: 24260 loss: 0.0045 lr: 0.02
2019-03-27 14:33:23 iteration: 24265 loss: 0.0055 lr: 0.02
2019-03-27 14:34:09 iteration: 24270 loss: 0.0042 lr: 0.02
2019-03-27 14:34:47 iteration: 24275 loss: 0.0041 lr: 0.02
2019-03-27 14:36:24 iteration: 24280 loss: 0.0043 lr: 0.02
2019-03-27 14:37:04 iteration: 24285 loss: 0.0029 lr: 0.02
2019-03-27 14:37:28 iteration: 24290 loss: 0.0040 lr: 0.02
2019-03-27 14:37:50 iteration: 24295 loss: 0.0067 lr: 0.02
2019-03-27 14:38:11 iteration: 24300 loss: 0.0052 lr: 0.02
2019-03-27 14:38:28 iteration: 24305 loss: 0.0051 lr: 0.02
2019-03-27 14:38:45 iteration: 24310 loss: 0.0049 lr: 0.02
2019-03-27 14:39:17 iteration: 24315 loss: 0.0050 lr: 0.02
2019-03-27 14:41:04 iteration: 24320 loss: 0.0042 lr: 0.02
2019-03-27 14:42:28 iteration: 24325 loss: 0.0033 lr: 0.02
2019-03-27 14:43:13 iteration: 24330 loss: 0.0056 lr: 0.02
2019-03-27 14:43:27 iteration: 24335 loss: 0.0065 lr: 0.02
2019-03-27 14:43:52 iteration: 24340 loss: 0.0030 lr: 0.02
2019-03-27 14:44:25 iteration: 24345 loss: 0.0043 lr: 0.02
2019-03-27 14:44:41 iteration: 24350 loss: 0.0067 lr: 0.02
2019-03-27 14:44:56 iteration: 24355 loss: 0.0055 lr: 0.02
2019-03-27 14:46:06 iteration: 24360 loss: 0.0036 lr: 0.02
2019-03-27 14:46:30 iteration: 24365 loss: 0.0042 lr: 0.02
2019-03-27 14:47:27 iteration: 24370 loss: 0.0055 lr: 0.02
2019-03-27 14:48:24 iteration: 24375 loss: 0.0039 lr: 0.02
2019-03-27 14:48:49 iteration: 24380 loss: 0.0036 lr: 0.02
2019-03-27 14:49:44 iteration: 24385 loss: 0.0030 lr: 0.02
2019-03-27 14:50:29 iteration: 24390 loss: 0.0040 lr: 0.02
2019-03-27 14:50:45 iteration: 24395 loss: 0.0122 lr: 0.02
2019-03-27 14:51:03 iteration: 24400 loss: 0.0049 lr: 0.02
2019-03-27 14:51:13 iteration: 24405 loss: 0.0046 lr: 0.02
2019-03-27 14:51:49 iteration: 24410 loss: 0.0040 lr: 0.02
2019-03-27 14:52:25 iteration: 24415 loss: 0.0051 lr: 0.02
2019-03-27 14:52:35 iteration: 24420 loss: 0.0049 lr: 0.02
2019-03-27 14:52:47 iteration: 24425 loss: 0.0053 lr: 0.02
2019-03-27 14:53:06 iteration: 24430 loss: 0.0032 lr: 0.02
2019-03-27 14:53:19 iteration: 24435 loss: 0.0049 lr: 0.02
2019-03-27 14:53:39 iteration: 24440 loss: 0.0039 lr: 0.02
2019-03-27 14:55:53 iteration: 24445 loss: 0.0038 lr: 0.02
2019-03-27 14:57:11 iteration: 24450 loss: 0.0045 lr: 0.02
2019-03-27 14:57:29 iteration: 24455 loss: 0.0039 lr: 0.02
2019-03-27 14:57:50 iteration: 24460 loss: 0.0049 lr: 0.02
2019-03-27 14:58:26 iteration: 24465 loss: 0.0038 lr: 0.02
2019-03-27 14:59:04 iteration: 24470 loss: 0.0035 lr: 0.02
2019-03-27 14:59:19 iteration: 24475 loss: 0.0060 lr: 0.02
2019-03-27 14:59:32 iteration: 24480 loss: 0.0062 lr: 0.02
2019-03-27 15:00:30 iteration: 24485 loss: 0.0048 lr: 0.02
2019-03-27 15:00:41 iteration: 24490 loss: 0.0048 lr: 0.02
2019-03-27 15:01:12 iteration: 24495 loss: 0.0038 lr: 0.02
2019-03-27 15:01:44 iteration: 24500 loss: 0.0051 lr: 0.02
2019-03-27 15:03:31 iteration: 24505 loss: 0.0041 lr: 0.02
2019-03-27 15:04:20 iteration: 24510 loss: 0.0047 lr: 0.02
2019-03-27 15:04:55 iteration: 24515 loss: 0.0042 lr: 0.02
2019-03-27 15:06:37 iteration: 24520 loss: 0.0030 lr: 0.02
2019-03-27 15:07:30 iteration: 24525 loss: 0.0043 lr: 0.02
2019-03-27 15:08:50 iteration: 24530 loss: 0.0045 lr: 0.02
2019-03-27 15:09:34 iteration: 24535 loss: 0.0037 lr: 0.02
2019-03-27 15:10:13 iteration: 24540 loss: 0.0066 lr: 0.02
2019-03-27 15:11:34 iteration: 24545 loss: 0.0062 lr: 0.02
2019-03-27 15:12:40 iteration: 24550 loss: 0.0035 lr: 0.02
2019-03-27 15:13:36 iteration: 24555 loss: 0.0058 lr: 0.02
2019-03-27 15:14:03 iteration: 24560 loss: 0.0050 lr: 0.02
2019-03-27 15:14:27 iteration: 24565 loss: 0.0041 lr: 0.02
2019-03-27 15:14:52 iteration: 24570 loss: 0.0036 lr: 0.02
2019-03-27 15:15:35 iteration: 24575 loss: 0.0043 lr: 0.02
2019-03-27 15:15:58 iteration: 24580 loss: 0.0052 lr: 0.02
2019-03-27 15:16:42 iteration: 24585 loss: 0.0039 lr: 0.02
2019-03-27 15:18:21 iteration: 24590 loss: 0.0056 lr: 0.02
2019-03-27 15:18:38 iteration: 24595 loss: 0.0040 lr: 0.02
2019-03-27 15:20:20 iteration: 24600 loss: 0.0052 lr: 0.02
2019-03-27 15:21:02 iteration: 24605 loss: 0.0028 lr: 0.02
2019-03-27 15:21:59 iteration: 24610 loss: 0.0046 lr: 0.02
2019-03-27 15:22:45 iteration: 24615 loss: 0.0035 lr: 0.02
2019-03-27 15:23:05 iteration: 24620 loss: 0.0052 lr: 0.02
2019-03-27 15:24:12 iteration: 24625 loss: 0.0048 lr: 0.02
2019-03-27 15:24:30 iteration: 24630 loss: 0.0038 lr: 0.02
2019-03-27 15:25:35 iteration: 24635 loss: 0.0044 lr: 0.02
2019-03-27 15:27:05 iteration: 24640 loss: 0.0042 lr: 0.02
2019-03-27 15:27:33 iteration: 24645 loss: 0.0050 lr: 0.02
2019-03-27 15:28:23 iteration: 24650 loss: 0.0035 lr: 0.02
2019-03-27 15:28:42 iteration: 24655 loss: 0.0049 lr: 0.02
2019-03-27 15:28:53 iteration: 24660 loss: 0.0062 lr: 0.02
2019-03-27 15:29:31 iteration: 24665 loss: 0.0069 lr: 0.02
2019-03-27 15:30:36 iteration: 24670 loss: 0.0047 lr: 0.02
2019-03-27 15:31:13 iteration: 24675 loss: 0.0051 lr: 0.02
2019-03-27 15:32:01 iteration: 24680 loss: 0.0064 lr: 0.02
2019-03-27 15:32:15 iteration: 24685 loss: 0.0054 lr: 0.02
2019-03-27 15:32:41 iteration: 24690 loss: 0.0063 lr: 0.02
2019-03-27 15:32:58 iteration: 24695 loss: 0.0064 lr: 0.02
2019-03-27 15:33:51 iteration: 24700 loss: 0.0062 lr: 0.02
2019-03-27 15:34:03 iteration: 24705 loss: 0.0053 lr: 0.02
2019-03-27 15:35:31 iteration: 24710 loss: 0.0047 lr: 0.02
2019-03-27 15:35:46 iteration: 24715 loss: 0.0051 lr: 0.02
2019-03-27 15:36:01 iteration: 24720 loss: 0.0038 lr: 0.02
2019-03-27 15:36:37 iteration: 24725 loss: 0.0052 lr: 0.02
2019-03-27 15:36:49 iteration: 24730 loss: 0.0063 lr: 0.02
2019-03-27 15:37:23 iteration: 24735 loss: 0.0039 lr: 0.02
2019-03-27 15:37:41 iteration: 24740 loss: 0.0070 lr: 0.02
2019-03-27 15:38:02 iteration: 24745 loss: 0.0041 lr: 0.02
2019-03-27 15:38:18 iteration: 24750 loss: 0.0044 lr: 0.02
2019-03-27 15:38:59 iteration: 24755 loss: 0.0064 lr: 0.02
2019-03-27 15:39:22 iteration: 24760 loss: 0.0042 lr: 0.02
2019-03-27 15:39:41 iteration: 24765 loss: 0.0037 lr: 0.02
2019-03-27 15:40:34 iteration: 24770 loss: 0.0047 lr: 0.02
2019-03-27 15:42:06 iteration: 24775 loss: 0.0031 lr: 0.02
2019-03-27 15:42:18 iteration: 24780 loss: 0.0046 lr: 0.02
2019-03-27 15:43:08 iteration: 24785 loss: 0.0039 lr: 0.02
2019-03-27 15:44:56 iteration: 24790 loss: 0.0035 lr: 0.02
2019-03-27 15:45:11 iteration: 24795 loss: 0.0043 lr: 0.02
2019-03-27 15:46:13 iteration: 24800 loss: 0.0036 lr: 0.02
2019-03-27 15:46:43 iteration: 24805 loss: 0.0048 lr: 0.02
2019-03-27 15:48:04 iteration: 24810 loss: 0.0039 lr: 0.02
2019-03-27 15:48:43 iteration: 24815 loss: 0.0041 lr: 0.02
2019-03-27 15:48:54 iteration: 24820 loss: 0.0046 lr: 0.02
2019-03-27 15:49:17 iteration: 24825 loss: 0.0079 lr: 0.02
2019-03-27 15:49:29 iteration: 24830 loss: 0.0058 lr: 0.02
2019-03-27 15:50:05 iteration: 24835 loss: 0.0049 lr: 0.02
2019-03-27 15:50:47 iteration: 24840 loss: 0.0039 lr: 0.02
2019-03-27 15:51:02 iteration: 24845 loss: 0.0054 lr: 0.02
2019-03-27 15:52:29 iteration: 24850 loss: 0.0040 lr: 0.02
2019-03-27 15:53:02 iteration: 24855 loss: 0.0046 lr: 0.02
2019-03-27 15:53:25 iteration: 24860 loss: 0.0061 lr: 0.02
2019-03-27 15:53:43 iteration: 24865 loss: 0.0051 lr: 0.02
2019-03-27 15:53:58 iteration: 24870 loss: 0.0060 lr: 0.02
2019-03-27 15:54:36 iteration: 24875 loss: 0.0045 lr: 0.02
2019-03-27 15:55:40 iteration: 24880 loss: 0.0045 lr: 0.02
2019-03-27 15:57:24 iteration: 24885 loss: 0.0047 lr: 0.02
2019-03-27 15:57:41 iteration: 24890 loss: 0.0065 lr: 0.02
2019-03-27 15:58:17 iteration: 24895 loss: 0.0071 lr: 0.02
2019-03-27 15:58:43 iteration: 24900 loss: 0.0048 lr: 0.02
2019-03-27 15:59:36 iteration: 24905 loss: 0.0049 lr: 0.02
2019-03-27 15:59:51 iteration: 24910 loss: 0.0041 lr: 0.02
2019-03-27 16:00:20 iteration: 24915 loss: 0.0046 lr: 0.02
2019-03-27 16:01:28 iteration: 24920 loss: 0.0044 lr: 0.02
2019-03-27 16:02:14 iteration: 24925 loss: 0.0052 lr: 0.02
2019-03-27 16:02:28 iteration: 24930 loss: 0.0062 lr: 0.02
2019-03-27 16:02:53 iteration: 24935 loss: 0.0039 lr: 0.02
2019-03-27 16:03:14 iteration: 24940 loss: 0.0043 lr: 0.02
2019-03-27 16:03:41 iteration: 24945 loss: 0.0042 lr: 0.02
2019-03-27 16:05:28 iteration: 24950 loss: 0.0050 lr: 0.02
2019-03-27 16:06:18 iteration: 24955 loss: 0.0043 lr: 0.02
2019-03-27 16:06:32 iteration: 24960 loss: 0.0062 lr: 0.02
2019-03-27 16:07:01 iteration: 24965 loss: 0.0038 lr: 0.02
2019-03-27 16:08:19 iteration: 24970 loss: 0.0040 lr: 0.02
2019-03-27 16:08:38 iteration: 24975 loss: 0.0039 lr: 0.02
2019-03-27 16:10:07 iteration: 24980 loss: 0.0045 lr: 0.02
2019-03-27 16:11:14 iteration: 24985 loss: 0.0023 lr: 0.02
2019-03-27 16:12:00 iteration: 24990 loss: 0.0040 lr: 0.02
2019-03-27 16:13:04 iteration: 24995 loss: 0.0040 lr: 0.02
2019-03-27 16:14:13 iteration: 25000 loss: 0.0039 lr: 0.02
2019-03-27 16:14:49 iteration: 25005 loss: 0.0072 lr: 0.02
2019-03-27 16:16:20 iteration: 25010 loss: 0.0037 lr: 0.02
2019-03-27 16:17:12 iteration: 25015 loss: 0.0052 lr: 0.02
2019-03-27 16:17:58 iteration: 25020 loss: 0.0028 lr: 0.02
2019-03-27 16:18:57 iteration: 25025 loss: 0.0039 lr: 0.02
2019-03-27 16:19:26 iteration: 25030 loss: 0.0044 lr: 0.02
2019-03-27 16:20:23 iteration: 25035 loss: 0.0067 lr: 0.02
2019-03-27 16:20:55 iteration: 25040 loss: 0.0035 lr: 0.02
2019-03-27 16:21:44 iteration: 25045 loss: 0.0038 lr: 0.02
2019-03-27 16:22:10 iteration: 25050 loss: 0.0037 lr: 0.02
2019-03-27 16:22:52 iteration: 25055 loss: 0.0037 lr: 0.02
2019-03-27 16:23:11 iteration: 25060 loss: 0.0054 lr: 0.02
2019-03-27 16:23:38 iteration: 25065 loss: 0.0046 lr: 0.02
2019-03-27 16:24:34 iteration: 25070 loss: 0.0052 lr: 0.02
2019-03-27 16:25:27 iteration: 25075 loss: 0.0050 lr: 0.02
2019-03-27 16:26:08 iteration: 25080 loss: 0.0051 lr: 0.02
2019-03-27 16:26:28 iteration: 25085 loss: 0.0045 lr: 0.02
2019-03-27 16:27:04 iteration: 25090 loss: 0.0034 lr: 0.02
2019-03-27 16:28:22 iteration: 25095 loss: 0.0035 lr: 0.02
2019-03-27 16:28:40 iteration: 25100 loss: 0.0051 lr: 0.02
2019-03-27 16:29:08 iteration: 25105 loss: 0.0038 lr: 0.02
2019-03-27 16:29:42 iteration: 25110 loss: 0.0040 lr: 0.02
2019-03-27 16:30:10 iteration: 25115 loss: 0.0047 lr: 0.02
2019-03-27 16:31:26 iteration: 25120 loss: 0.0036 lr: 0.02
2019-03-27 16:32:34 iteration: 25125 loss: 0.0044 lr: 0.02
2019-03-27 16:33:07 iteration: 25130 loss: 0.0046 lr: 0.02
2019-03-27 16:33:35 iteration: 25135 loss: 0.0039 lr: 0.02
2019-03-27 16:33:51 iteration: 25140 loss: 0.0039 lr: 0.02
2019-03-27 16:34:13 iteration: 25145 loss: 0.0061 lr: 0.02
2019-03-27 16:34:55 iteration: 25150 loss: 0.0028 lr: 0.02
2019-03-27 16:35:20 iteration: 25155 loss: 0.0077 lr: 0.02
2019-03-27 16:35:52 iteration: 25160 loss: 0.0033 lr: 0.02
2019-03-27 16:36:10 iteration: 25165 loss: 0.0044 lr: 0.02
2019-03-27 16:37:12 iteration: 25170 loss: 0.0036 lr: 0.02
2019-03-27 16:37:52 iteration: 25175 loss: 0.0034 lr: 0.02
2019-03-27 16:38:37 iteration: 25180 loss: 0.0048 lr: 0.02
2019-03-27 16:39:57 iteration: 25185 loss: 0.0039 lr: 0.02
2019-03-27 16:40:22 iteration: 25190 loss: 0.0048 lr: 0.02
2019-03-27 16:40:41 iteration: 25195 loss: 0.0064 lr: 0.02
2019-03-27 16:41:31 iteration: 25200 loss: 0.0048 lr: 0.02
2019-03-27 16:41:46 iteration: 25205 loss: 0.0060 lr: 0.02
2019-03-27 16:43:02 iteration: 25210 loss: 0.0037 lr: 0.02
2019-03-27 16:43:35 iteration: 25215 loss: 0.0043 lr: 0.02
2019-03-27 16:44:49 iteration: 25220 loss: 0.0043 lr: 0.02
2019-03-27 16:45:06 iteration: 25225 loss: 0.0067 lr: 0.02
2019-03-27 16:45:21 iteration: 25230 loss: 0.0046 lr: 0.02
2019-03-27 16:45:57 iteration: 25235 loss: 0.0059 lr: 0.02
2019-03-27 16:46:09 iteration: 25240 loss: 0.0051 lr: 0.02
2019-03-27 16:47:05 iteration: 25245 loss: 0.0036 lr: 0.02
2019-03-27 16:47:22 iteration: 25250 loss: 0.0061 lr: 0.02
2019-03-27 16:48:17 iteration: 25255 loss: 0.0044 lr: 0.02
2019-03-27 16:48:46 iteration: 25260 loss: 0.0052 lr: 0.02
2019-03-27 16:50:00 iteration: 25265 loss: 0.0035 lr: 0.02
2019-03-27 16:50:19 iteration: 25270 loss: 0.0040 lr: 0.02
2019-03-27 16:51:22 iteration: 25275 loss: 0.0040 lr: 0.02
2019-03-27 16:51:54 iteration: 25280 loss: 0.0047 lr: 0.02
2019-03-27 16:52:13 iteration: 25285 loss: 0.0048 lr: 0.02
2019-03-27 16:52:45 iteration: 25290 loss: 0.0049 lr: 0.02
2019-03-27 16:53:34 iteration: 25295 loss: 0.0051 lr: 0.02
2019-03-27 16:53:52 iteration: 25300 loss: 0.0045 lr: 0.02
2019-03-27 16:54:22 iteration: 25305 loss: 0.0052 lr: 0.02
2019-03-27 16:54:42 iteration: 25310 loss: 0.0048 lr: 0.02
2019-03-27 16:55:05 iteration: 25315 loss: 0.0062 lr: 0.02
2019-03-27 16:55:29 iteration: 25320 loss: 0.0060 lr: 0.02
2019-03-27 16:55:59 iteration: 25325 loss: 0.0047 lr: 0.02
2019-03-27 16:56:13 iteration: 25330 loss: 0.0074 lr: 0.02
2019-03-27 16:56:37 iteration: 25335 loss: 0.0044 lr: 0.02
2019-03-27 16:57:54 iteration: 25340 loss: 0.0040 lr: 0.02
2019-03-27 16:58:54 iteration: 25345 loss: 0.0037 lr: 0.02
2019-03-27 16:59:04 iteration: 25350 loss: 0.0050 lr: 0.02
2019-03-27 16:59:26 iteration: 25355 loss: 0.0034 lr: 0.02
2019-03-27 17:01:37 iteration: 25360 loss: 0.0040 lr: 0.02
2019-03-27 17:01:58 iteration: 25365 loss: 0.0040 lr: 0.02
2019-03-27 17:03:08 iteration: 25370 loss: 0.0049 lr: 0.02
2019-03-27 17:03:48 iteration: 25375 loss: 0.0042 lr: 0.02
2019-03-27 17:04:16 iteration: 25380 loss: 0.0034 lr: 0.02
2019-03-27 17:05:14 iteration: 25385 loss: 0.0046 lr: 0.02
2019-03-27 17:06:18 iteration: 25390 loss: 0.0043 lr: 0.02
2019-03-27 17:07:01 iteration: 25395 loss: 0.0050 lr: 0.02
2019-03-27 17:08:15 iteration: 25400 loss: 0.0039 lr: 0.02
2019-03-27 17:09:31 iteration: 25405 loss: 0.0040 lr: 0.02
2019-03-27 17:10:08 iteration: 25410 loss: 0.0066 lr: 0.02
2019-03-27 17:11:03 iteration: 25415 loss: 0.0050 lr: 0.02
2019-03-27 17:11:37 iteration: 25420 loss: 0.0041 lr: 0.02
2019-03-27 17:12:27 iteration: 25425 loss: 0.0050 lr: 0.02
2019-03-27 17:12:54 iteration: 25430 loss: 0.0041 lr: 0.02
2019-03-27 17:13:31 iteration: 25435 loss: 0.0032 lr: 0.02
2019-03-27 17:14:30 iteration: 25440 loss: 0.0030 lr: 0.02
2019-03-27 17:14:44 iteration: 25445 loss: 0.0051 lr: 0.02
2019-03-27 17:15:01 iteration: 25450 loss: 0.0065 lr: 0.02
2019-03-27 17:15:15 iteration: 25455 loss: 0.0044 lr: 0.02
2019-03-27 17:15:49 iteration: 25460 loss: 0.0039 lr: 0.02
2019-03-27 17:17:00 iteration: 25465 loss: 0.0034 lr: 0.02
2019-03-27 17:18:12 iteration: 25470 loss: 0.0032 lr: 0.02
2019-03-27 17:18:34 iteration: 25475 loss: 0.0050 lr: 0.02
2019-03-27 17:18:48 iteration: 25480 loss: 0.0080 lr: 0.02
2019-03-27 17:19:46 iteration: 25485 loss: 0.0042 lr: 0.02
2019-03-27 17:20:03 iteration: 25490 loss: 0.0054 lr: 0.02
2019-03-27 17:21:23 iteration: 25495 loss: 0.0059 lr: 0.02
2019-03-27 17:21:40 iteration: 25500 loss: 0.0050 lr: 0.02
2019-03-27 17:22:24 iteration: 25505 loss: 0.0042 lr: 0.02
2019-03-27 17:23:16 iteration: 25510 loss: 0.0032 lr: 0.02
2019-03-27 17:24:06 iteration: 25515 loss: 0.0042 lr: 0.02
2019-03-27 17:24:55 iteration: 25520 loss: 0.0062 lr: 0.02
2019-03-27 17:25:13 iteration: 25525 loss: 0.0049 lr: 0.02
2019-03-27 17:26:07 iteration: 25530 loss: 0.0033 lr: 0.02
2019-03-27 17:26:38 iteration: 25535 loss: 0.0048 lr: 0.02
2019-03-27 17:26:56 iteration: 25540 loss: 0.0053 lr: 0.02
2019-03-27 17:27:24 iteration: 25545 loss: 0.0036 lr: 0.02
2019-03-27 17:28:45 iteration: 25550 loss: 0.0044 lr: 0.02
2019-03-27 17:30:04 iteration: 25555 loss: 0.0032 lr: 0.02
2019-03-27 17:30:57 iteration: 25560 loss: 0.0046 lr: 0.02
2019-03-27 17:31:24 iteration: 25565 loss: 0.0040 lr: 0.02
2019-03-27 17:32:50 iteration: 25570 loss: 0.0033 lr: 0.02
2019-03-27 17:33:56 iteration: 25575 loss: 0.0043 lr: 0.02
2019-03-27 17:35:20 iteration: 25580 loss: 0.0033 lr: 0.02
2019-03-27 17:36:02 iteration: 25585 loss: 0.0051 lr: 0.02
2019-03-27 17:36:45 iteration: 25590 loss: 0.0041 lr: 0.02
2019-03-27 17:37:19 iteration: 25595 loss: 0.0036 lr: 0.02
2019-03-27 17:38:33 iteration: 25600 loss: 0.0032 lr: 0.02
2019-03-27 17:39:41 iteration: 25605 loss: 0.0041 lr: 0.02
2019-03-27 17:40:13 iteration: 25610 loss: 0.0041 lr: 0.02
2019-03-27 17:40:31 iteration: 25615 loss: 0.0056 lr: 0.02
2019-03-27 17:40:50 iteration: 25620 loss: 0.0048 lr: 0.02
2019-03-27 17:40:58 iteration: 25625 loss: 0.0060 lr: 0.02
2019-03-27 17:41:18 iteration: 25630 loss: 0.0047 lr: 0.02
2019-03-27 17:41:43 iteration: 25635 loss: 0.0050 lr: 0.02
2019-03-27 17:42:00 iteration: 25640 loss: 0.0031 lr: 0.02
2019-03-27 17:42:51 iteration: 25645 loss: 0.0055 lr: 0.02
2019-03-27 17:43:07 iteration: 25650 loss: 0.0064 lr: 0.02
2019-03-27 17:43:34 iteration: 25655 loss: 0.0044 lr: 0.02
2019-03-27 17:44:08 iteration: 25660 loss: 0.0038 lr: 0.02
2019-03-27 17:44:32 iteration: 25665 loss: 0.0060 lr: 0.02
2019-03-27 17:44:49 iteration: 25670 loss: 0.0049 lr: 0.02
2019-03-27 17:45:18 iteration: 25675 loss: 0.0039 lr: 0.02
2019-03-27 17:46:26 iteration: 25680 loss: 0.0038 lr: 0.02
2019-03-27 17:47:28 iteration: 25685 loss: 0.0036 lr: 0.02
2019-03-27 17:47:49 iteration: 25690 loss: 0.0040 lr: 0.02
2019-03-27 17:49:02 iteration: 25695 loss: 0.0033 lr: 0.02
2019-03-27 17:49:35 iteration: 25700 loss: 0.0046 lr: 0.02
2019-03-27 17:49:49 iteration: 25705 loss: 0.0087 lr: 0.02
2019-03-27 17:51:14 iteration: 25710 loss: 0.0056 lr: 0.02
2019-03-27 17:52:01 iteration: 25715 loss: 0.0040 lr: 0.02
2019-03-27 17:52:17 iteration: 25720 loss: 0.0056 lr: 0.02
2019-03-27 17:53:14 iteration: 25725 loss: 0.0044 lr: 0.02
2019-03-27 17:54:11 iteration: 25730 loss: 0.0030 lr: 0.02
2019-03-27 17:54:50 iteration: 25735 loss: 0.0045 lr: 0.02
2019-03-27 17:55:57 iteration: 25740 loss: 0.0041 lr: 0.02
2019-03-27 17:56:18 iteration: 25745 loss: 0.0046 lr: 0.02
2019-03-27 17:57:01 iteration: 25750 loss: 0.0033 lr: 0.02
2019-03-27 17:57:24 iteration: 25755 loss: 0.0059 lr: 0.02
2019-03-27 17:57:54 iteration: 25760 loss: 0.0046 lr: 0.02
2019-03-27 17:58:13 iteration: 25765 loss: 0.0047 lr: 0.02
2019-03-27 17:58:21 iteration: 25770 loss: 0.0064 lr: 0.02
2019-03-27 17:58:54 iteration: 25775 loss: 0.0050 lr: 0.02
2019-03-27 17:59:53 iteration: 25780 loss: 0.0036 lr: 0.02
2019-03-27 18:00:12 iteration: 25785 loss: 0.0038 lr: 0.02
2019-03-27 18:01:21 iteration: 25790 loss: 0.0042 lr: 0.02
2019-03-27 18:01:52 iteration: 25795 loss: 0.0053 lr: 0.02
2019-03-27 18:02:36 iteration: 25800 loss: 0.0040 lr: 0.02
2019-03-27 18:02:56 iteration: 25805 loss: 0.0038 lr: 0.02
2019-03-27 18:03:23 iteration: 25810 loss: 0.0094 lr: 0.02
2019-03-27 18:03:47 iteration: 25815 loss: 0.0038 lr: 0.02
2019-03-27 18:04:25 iteration: 25820 loss: 0.0048 lr: 0.02
2019-03-27 18:04:51 iteration: 25825 loss: 0.0039 lr: 0.02
2019-03-27 18:05:24 iteration: 25830 loss: 0.0041 lr: 0.02
2019-03-27 18:05:38 iteration: 25835 loss: 0.0052 lr: 0.02
2019-03-27 18:06:28 iteration: 25840 loss: 0.0047 lr: 0.02
2019-03-27 18:07:17 iteration: 25845 loss: 0.0049 lr: 0.02
2019-03-27 18:07:34 iteration: 25850 loss: 0.0052 lr: 0.02
2019-03-27 18:08:19 iteration: 25855 loss: 0.0043 lr: 0.02
2019-03-27 18:09:12 iteration: 25860 loss: 0.0050 lr: 0.02
2019-03-27 18:10:25 iteration: 25865 loss: 0.0041 lr: 0.02
2019-03-27 18:11:40 iteration: 25870 loss: 0.0033 lr: 0.02
2019-03-27 18:12:51 iteration: 25875 loss: 0.0036 lr: 0.02
2019-03-27 18:13:19 iteration: 25880 loss: 0.0036 lr: 0.02
2019-03-27 18:14:17 iteration: 25885 loss: 0.0038 lr: 0.02
2019-03-27 18:15:48 iteration: 25890 loss: 0.0047 lr: 0.02
2019-03-27 18:16:02 iteration: 25895 loss: 0.0052 lr: 0.02
2019-03-27 18:16:36 iteration: 25900 loss: 0.0040 lr: 0.02
2019-03-27 18:17:02 iteration: 25905 loss: 0.0034 lr: 0.02
2019-03-27 18:17:38 iteration: 25910 loss: 0.0037 lr: 0.02
2019-03-27 18:18:08 iteration: 25915 loss: 0.0036 lr: 0.02
2019-03-27 18:18:52 iteration: 25920 loss: 0.0054 lr: 0.02
2019-03-27 18:19:56 iteration: 25925 loss: 0.0059 lr: 0.02
2019-03-27 18:20:18 iteration: 25930 loss: 0.0046 lr: 0.02
2019-03-27 18:21:28 iteration: 25935 loss: 0.0047 lr: 0.02
2019-03-27 18:21:45 iteration: 25940 loss: 0.0051 lr: 0.02
2019-03-27 18:22:48 iteration: 25945 loss: 0.0040 lr: 0.02
2019-03-27 18:23:03 iteration: 25950 loss: 0.0042 lr: 0.02
2019-03-27 18:23:20 iteration: 25955 loss: 0.0057 lr: 0.02
2019-03-27 18:23:47 iteration: 25960 loss: 0.0038 lr: 0.02
2019-03-27 18:24:33 iteration: 25965 loss: 0.0064 lr: 0.02
2019-03-27 18:25:02 iteration: 25970 loss: 0.0052 lr: 0.02
2019-03-27 18:26:13 iteration: 25975 loss: 0.0032 lr: 0.02
2019-03-27 18:27:06 iteration: 25980 loss: 0.0052 lr: 0.02
2019-03-27 18:28:21 iteration: 25985 loss: 0.0034 lr: 0.02
2019-03-27 18:28:48 iteration: 25990 loss: 0.0037 lr: 0.02
2019-03-27 18:30:35 iteration: 25995 loss: 0.0031 lr: 0.02
2019-03-27 18:30:49 iteration: 26000 loss: 0.0068 lr: 0.02
2019-03-27 18:31:25 iteration: 26005 loss: 0.0071 lr: 0.02
2019-03-27 18:32:02 iteration: 26010 loss: 0.0066 lr: 0.02
2019-03-27 18:32:17 iteration: 26015 loss: 0.0068 lr: 0.02
2019-03-27 18:33:43 iteration: 26020 loss: 0.0070 lr: 0.02
2019-03-27 18:34:03 iteration: 26025 loss: 0.0050 lr: 0.02
2019-03-27 18:34:22 iteration: 26030 loss: 0.0054 lr: 0.02
2019-03-27 18:34:47 iteration: 26035 loss: 0.0045 lr: 0.02
2019-03-27 18:35:03 iteration: 26040 loss: 0.0066 lr: 0.02
2019-03-27 18:36:00 iteration: 26045 loss: 0.0037 lr: 0.02
2019-03-27 18:36:21 iteration: 26050 loss: 0.0053 lr: 0.02
2019-03-27 18:37:04 iteration: 26055 loss: 0.0024 lr: 0.02
2019-03-27 18:37:39 iteration: 26060 loss: 0.0036 lr: 0.02
2019-03-27 18:39:01 iteration: 26065 loss: 0.0055 lr: 0.02
2019-03-27 18:40:27 iteration: 26070 loss: 0.0037 lr: 0.02
2019-03-27 18:40:51 iteration: 26075 loss: 0.0056 lr: 0.02
2019-03-27 18:41:05 iteration: 26080 loss: 0.0049 lr: 0.02
2019-03-27 18:41:54 iteration: 26085 loss: 0.0039 lr: 0.02
2019-03-27 18:42:32 iteration: 26090 loss: 0.0044 lr: 0.02
2019-03-27 18:43:17 iteration: 26095 loss: 0.0046 lr: 0.02
2019-03-27 18:43:49 iteration: 26100 loss: 0.0048 lr: 0.02
2019-03-27 18:44:13 iteration: 26105 loss: 0.0041 lr: 0.02
2019-03-27 18:44:37 iteration: 26110 loss: 0.0054 lr: 0.02
2019-03-27 18:45:05 iteration: 26115 loss: 0.0040 lr: 0.02
2019-03-27 18:46:14 iteration: 26120 loss: 0.0037 lr: 0.02
2019-03-27 18:47:02 iteration: 26125 loss: 0.0043 lr: 0.02
2019-03-27 18:47:18 iteration: 26130 loss: 0.0065 lr: 0.02
2019-03-27 18:48:27 iteration: 26135 loss: 0.0043 lr: 0.02
2019-03-27 18:49:21 iteration: 26140 loss: 0.0036 lr: 0.02
2019-03-27 18:50:43 iteration: 26145 loss: 0.0026 lr: 0.02
2019-03-27 18:51:27 iteration: 26150 loss: 0.0045 lr: 0.02
2019-03-27 18:52:06 iteration: 26155 loss: 0.0041 lr: 0.02
2019-03-27 18:52:20 iteration: 26160 loss: 0.0048 lr: 0.02
2019-03-27 18:52:37 iteration: 26165 loss: 0.0050 lr: 0.02
2019-03-27 18:52:51 iteration: 26170 loss: 0.0059 lr: 0.02
2019-03-27 18:53:07 iteration: 26175 loss: 0.0044 lr: 0.02
2019-03-27 18:54:17 iteration: 26180 loss: 0.0039 lr: 0.02
2019-03-27 18:54:34 iteration: 26185 loss: 0.0066 lr: 0.02
2019-03-27 18:55:21 iteration: 26190 loss: 0.0054 lr: 0.02
2019-03-27 18:56:09 iteration: 26195 loss: 0.0040 lr: 0.02
2019-03-27 18:57:31 iteration: 26200 loss: 0.0028 lr: 0.02
2019-03-27 18:58:10 iteration: 26205 loss: 0.0040 lr: 0.02
2019-03-27 18:58:55 iteration: 26210 loss: 0.0042 lr: 0.02
2019-03-27 18:59:49 iteration: 26215 loss: 0.0044 lr: 0.02
2019-03-27 19:00:16 iteration: 26220 loss: 0.0046 lr: 0.02
2019-03-27 19:00:32 iteration: 26225 loss: 0.0049 lr: 0.02
2019-03-27 19:00:57 iteration: 26230 loss: 0.0040 lr: 0.02
2019-03-27 19:01:27 iteration: 26235 loss: 0.0042 lr: 0.02
2019-03-27 19:01:45 iteration: 26240 loss: 0.0061 lr: 0.02
2019-03-27 19:02:20 iteration: 26245 loss: 0.0043 lr: 0.02
2019-03-27 19:03:06 iteration: 26250 loss: 0.0038 lr: 0.02
2019-03-27 19:03:42 iteration: 26255 loss: 0.0048 lr: 0.02
2019-03-27 19:04:12 iteration: 26260 loss: 0.0032 lr: 0.02
2019-03-27 19:05:29 iteration: 26265 loss: 0.0036 lr: 0.02
2019-03-27 19:05:46 iteration: 26270 loss: 0.0075 lr: 0.02
2019-03-27 19:06:14 iteration: 26275 loss: 0.0047 lr: 0.02
2019-03-27 19:06:30 iteration: 26280 loss: 0.0045 lr: 0.02
2019-03-27 19:06:58 iteration: 26285 loss: 0.0038 lr: 0.02
2019-03-27 19:08:05 iteration: 26290 loss: 0.0064 lr: 0.02
2019-03-27 19:08:56 iteration: 26295 loss: 0.0090 lr: 0.02
2019-03-27 19:09:59 iteration: 26300 loss: 0.0036 lr: 0.02
2019-03-27 19:10:32 iteration: 26305 loss: 0.0072 lr: 0.02
2019-03-27 19:10:46 iteration: 26310 loss: 0.0048 lr: 0.02
2019-03-27 19:11:03 iteration: 26315 loss: 0.0038 lr: 0.02
2019-03-27 19:11:39 iteration: 26320 loss: 0.0041 lr: 0.02
2019-03-27 19:12:29 iteration: 26325 loss: 0.0041 lr: 0.02
2019-03-27 19:12:46 iteration: 26330 loss: 0.0043 lr: 0.02
2019-03-27 19:13:27 iteration: 26335 loss: 0.0043 lr: 0.02
2019-03-27 19:13:59 iteration: 26340 loss: 0.0040 lr: 0.02
2019-03-27 19:14:27 iteration: 26345 loss: 0.0039 lr: 0.02
2019-03-27 19:15:50 iteration: 26350 loss: 0.0034 lr: 0.02
2019-03-27 19:16:28 iteration: 26355 loss: 0.0047 lr: 0.02
2019-03-27 19:16:45 iteration: 26360 loss: 0.0044 lr: 0.02
2019-03-27 19:17:02 iteration: 26365 loss: 0.0062 lr: 0.02
2019-03-27 19:17:23 iteration: 26370 loss: 0.0067 lr: 0.02
2019-03-27 19:18:32 iteration: 26375 loss: 0.0054 lr: 0.02
2019-03-27 19:19:23 iteration: 26380 loss: 0.0048 lr: 0.02
2019-03-27 19:20:15 iteration: 26385 loss: 0.0037 lr: 0.02
2019-03-27 19:20:58 iteration: 26390 loss: 0.0046 lr: 0.02
2019-03-27 19:21:30 iteration: 26395 loss: 0.0038 lr: 0.02
2019-03-27 19:21:53 iteration: 26400 loss: 0.0046 lr: 0.02
2019-03-27 19:22:12 iteration: 26405 loss: 0.0047 lr: 0.02
2019-03-27 19:22:57 iteration: 26410 loss: 0.0039 lr: 0.02
2019-03-27 19:23:29 iteration: 26415 loss: 0.0059 lr: 0.02
2019-03-27 19:24:42 iteration: 26420 loss: 0.0039 lr: 0.02
2019-03-27 19:25:06 iteration: 26425 loss: 0.0084 lr: 0.02
2019-03-27 19:25:19 iteration: 26430 loss: 0.0046 lr: 0.02
2019-03-27 19:26:44 iteration: 26435 loss: 0.0041 lr: 0.02
2019-03-27 19:27:28 iteration: 26440 loss: 0.0045 lr: 0.02
2019-03-27 19:28:36 iteration: 26445 loss: 0.0062 lr: 0.02
2019-03-27 19:28:53 iteration: 26450 loss: 0.0052 lr: 0.02
2019-03-27 19:29:05 iteration: 26455 loss: 0.0045 lr: 0.02
2019-03-27 19:30:17 iteration: 26460 loss: 0.0047 lr: 0.02
2019-03-27 19:30:58 iteration: 26465 loss: 0.0053 lr: 0.02
2019-03-27 19:31:13 iteration: 26470 loss: 0.0054 lr: 0.02
2019-03-27 19:31:51 iteration: 26475 loss: 0.0041 lr: 0.02
2019-03-27 19:32:42 iteration: 26480 loss: 0.0047 lr: 0.02
2019-03-27 19:33:08 iteration: 26485 loss: 0.0046 lr: 0.02
2019-03-27 19:33:26 iteration: 26490 loss: 0.0044 lr: 0.02
2019-03-27 19:34:18 iteration: 26495 loss: 0.0037 lr: 0.02
2019-03-27 19:34:47 iteration: 26500 loss: 0.0048 lr: 0.02
2019-03-27 19:35:03 iteration: 26505 loss: 0.0063 lr: 0.02
2019-03-27 19:35:50 iteration: 26510 loss: 0.0048 lr: 0.02
2019-03-27 19:36:33 iteration: 26515 loss: 0.0054 lr: 0.02
2019-03-27 19:36:46 iteration: 26520 loss: 0.0045 lr: 0.02
2019-03-27 19:37:31 iteration: 26525 loss: 0.0039 lr: 0.02
2019-03-27 19:38:51 iteration: 26530 loss: 0.0049 lr: 0.02
2019-03-27 19:39:15 iteration: 26535 loss: 0.0038 lr: 0.02
2019-03-27 19:40:30 iteration: 26540 loss: 0.0040 lr: 0.02
2019-03-27 19:41:38 iteration: 26545 loss: 0.0049 lr: 0.02
2019-03-27 19:42:06 iteration: 26550 loss: 0.0039 lr: 0.02
2019-03-27 19:42:52 iteration: 26555 loss: 0.0041 lr: 0.02
2019-03-27 19:43:29 iteration: 26560 loss: 0.0034 lr: 0.02
2019-03-27 19:44:25 iteration: 26565 loss: 0.0036 lr: 0.02
2019-03-27 19:45:19 iteration: 26570 loss: 0.0049 lr: 0.02
2019-03-27 19:46:06 iteration: 26575 loss: 0.0035 lr: 0.02
2019-03-27 19:46:27 iteration: 26580 loss: 0.0047 lr: 0.02
2019-03-27 19:47:55 iteration: 26585 loss: 0.0040 lr: 0.02
2019-03-27 19:49:06 iteration: 26590 loss: 0.0031 lr: 0.02
2019-03-27 19:49:54 iteration: 26595 loss: 0.0037 lr: 0.02
2019-03-27 19:50:16 iteration: 26600 loss: 0.0035 lr: 0.02
2019-03-27 19:50:58 iteration: 26605 loss: 0.0036 lr: 0.02
2019-03-27 19:51:56 iteration: 26610 loss: 0.0045 lr: 0.02
2019-03-27 19:52:16 iteration: 26615 loss: 0.0043 lr: 0.02
2019-03-27 19:52:48 iteration: 26620 loss: 0.0050 lr: 0.02
2019-03-27 19:53:38 iteration: 26625 loss: 0.0035 lr: 0.02
2019-03-27 19:54:14 iteration: 26630 loss: 0.0044 lr: 0.02
2019-03-27 19:55:06 iteration: 26635 loss: 0.0040 lr: 0.02
2019-03-27 19:55:57 iteration: 26640 loss: 0.0058 lr: 0.02
2019-03-27 19:56:13 iteration: 26645 loss: 0.0067 lr: 0.02
2019-03-27 19:57:47 iteration: 26650 loss: 0.0040 lr: 0.02
2019-03-27 19:59:08 iteration: 26655 loss: 0.0032 lr: 0.02
2019-03-27 19:59:50 iteration: 26660 loss: 0.0045 lr: 0.02
2019-03-27 20:00:49 iteration: 26665 loss: 0.0044 lr: 0.02
2019-03-27 20:01:25 iteration: 26670 loss: 0.0037 lr: 0.02
2019-03-27 20:02:10 iteration: 26675 loss: 0.0039 lr: 0.02
2019-03-27 20:03:28 iteration: 26680 loss: 0.0029 lr: 0.02
2019-03-27 20:04:24 iteration: 26685 loss: 0.0036 lr: 0.02
2019-03-27 20:05:18 iteration: 26690 loss: 0.0036 lr: 0.02
2019-03-27 20:05:53 iteration: 26695 loss: 0.0041 lr: 0.02
2019-03-27 20:06:03 iteration: 26700 loss: 0.0067 lr: 0.02
2019-03-27 20:06:40 iteration: 26705 loss: 0.0044 lr: 0.02
2019-03-27 20:08:14 iteration: 26710 loss: 0.0025 lr: 0.02
2019-03-27 20:08:50 iteration: 26715 loss: 0.0042 lr: 0.02
2019-03-27 20:09:13 iteration: 26720 loss: 0.0042 lr: 0.02
2019-03-27 20:09:22 iteration: 26725 loss: 0.0054 lr: 0.02
2019-03-27 20:09:39 iteration: 26730 loss: 0.0054 lr: 0.02
2019-03-27 20:09:53 iteration: 26735 loss: 0.0039 lr: 0.02
2019-03-27 20:10:30 iteration: 26740 loss: 0.0034 lr: 0.02
2019-03-27 20:11:19 iteration: 26745 loss: 0.0047 lr: 0.02
2019-03-27 20:12:18 iteration: 26750 loss: 0.0044 lr: 0.02
2019-03-27 20:12:35 iteration: 26755 loss: 0.0079 lr: 0.02
2019-03-27 20:13:46 iteration: 26760 loss: 0.0043 lr: 0.02
2019-03-27 20:13:59 iteration: 26765 loss: 0.0045 lr: 0.02
2019-03-27 20:14:16 iteration: 26770 loss: 0.0050 lr: 0.02
2019-03-27 20:14:38 iteration: 26775 loss: 0.0055 lr: 0.02
2019-03-27 20:15:44 iteration: 26780 loss: 0.0043 lr: 0.02
2019-03-27 20:16:26 iteration: 26785 loss: 0.0033 lr: 0.02
2019-03-27 20:17:45 iteration: 26790 loss: 0.0037 lr: 0.02
2019-03-27 20:18:30 iteration: 26795 loss: 0.0059 lr: 0.02
2019-03-27 20:19:04 iteration: 26800 loss: 0.0058 lr: 0.02
2019-03-27 20:20:06 iteration: 26805 loss: 0.0036 lr: 0.02
2019-03-27 20:20:23 iteration: 26810 loss: 0.0072 lr: 0.02
2019-03-27 20:21:16 iteration: 26815 loss: 0.0048 lr: 0.02
2019-03-27 20:21:57 iteration: 26820 loss: 0.0063 lr: 0.02
2019-03-27 20:22:17 iteration: 26825 loss: 0.0056 lr: 0.02
2019-03-27 20:23:16 iteration: 26830 loss: 0.0029 lr: 0.02
2019-03-27 20:24:01 iteration: 26835 loss: 0.0050 lr: 0.02
2019-03-27 20:25:00 iteration: 26840 loss: 0.0047 lr: 0.02
2019-03-27 20:25:44 iteration: 26845 loss: 0.0035 lr: 0.02
2019-03-27 20:26:37 iteration: 26850 loss: 0.0040 lr: 0.02
2019-03-27 20:26:56 iteration: 26855 loss: 0.0033 lr: 0.02
2019-03-27 20:27:42 iteration: 26860 loss: 0.0031 lr: 0.02
2019-03-27 20:28:32 iteration: 26865 loss: 0.0048 lr: 0.02
2019-03-27 20:28:44 iteration: 26870 loss: 0.0035 lr: 0.02
2019-03-27 20:29:18 iteration: 26875 loss: 0.0048 lr: 0.02
2019-03-27 20:29:36 iteration: 26880 loss: 0.0048 lr: 0.02
2019-03-27 20:29:46 iteration: 26885 loss: 0.0045 lr: 0.02
2019-03-27 20:30:26 iteration: 26890 loss: 0.0031 lr: 0.02
2019-03-27 20:31:28 iteration: 26895 loss: 0.0029 lr: 0.02
2019-03-27 20:31:47 iteration: 26900 loss: 0.0041 lr: 0.02
2019-03-27 20:32:25 iteration: 26905 loss: 0.0043 lr: 0.02
2019-03-27 20:33:11 iteration: 26910 loss: 0.0033 lr: 0.02
2019-03-27 20:33:53 iteration: 26915 loss: 0.0052 lr: 0.02
2019-03-27 20:34:41 iteration: 26920 loss: 0.0039 lr: 0.02
2019-03-27 20:35:39 iteration: 26925 loss: 0.0031 lr: 0.02
2019-03-27 20:36:28 iteration: 26930 loss: 0.0063 lr: 0.02
2019-03-27 20:37:16 iteration: 26935 loss: 0.0070 lr: 0.02
2019-03-27 20:37:38 iteration: 26940 loss: 0.0053 lr: 0.02
2019-03-27 20:38:18 iteration: 26945 loss: 0.0037 lr: 0.02
2019-03-27 20:38:50 iteration: 26950 loss: 0.0039 lr: 0.02
2019-03-27 20:39:30 iteration: 26955 loss: 0.0036 lr: 0.02
2019-03-27 20:40:11 iteration: 26960 loss: 0.0027 lr: 0.02
2019-03-27 20:40:33 iteration: 26965 loss: 0.0050 lr: 0.02
2019-03-27 20:41:05 iteration: 26970 loss: 0.0036 lr: 0.02
2019-03-27 20:42:01 iteration: 26975 loss: 0.0042 lr: 0.02
2019-03-27 20:42:51 iteration: 26980 loss: 0.0063 lr: 0.02
2019-03-27 20:43:07 iteration: 26985 loss: 0.0045 lr: 0.02
2019-03-27 20:43:22 iteration: 26990 loss: 0.0053 lr: 0.02
2019-03-27 20:43:56 iteration: 26995 loss: 0.0051 lr: 0.02
2019-03-27 20:44:38 iteration: 27000 loss: 0.0086 lr: 0.02
2019-03-27 20:45:22 iteration: 27005 loss: 0.0038 lr: 0.02
2019-03-27 20:45:50 iteration: 27010 loss: 0.0069 lr: 0.02
2019-03-27 20:46:25 iteration: 27015 loss: 0.0039 lr: 0.02
2019-03-27 20:46:57 iteration: 27020 loss: 0.0042 lr: 0.02
2019-03-27 20:47:15 iteration: 27025 loss: 0.0053 lr: 0.02
2019-03-27 20:47:57 iteration: 27030 loss: 0.0043 lr: 0.02
2019-03-27 20:48:40 iteration: 27035 loss: 0.0055 lr: 0.02
2019-03-27 20:49:24 iteration: 27040 loss: 0.0039 lr: 0.02
2019-03-27 20:50:16 iteration: 27045 loss: 0.0044 lr: 0.02
2019-03-27 20:50:38 iteration: 27050 loss: 0.0044 lr: 0.02
2019-03-27 20:51:15 iteration: 27055 loss: 0.0037 lr: 0.02
2019-03-27 20:51:34 iteration: 27060 loss: 0.0054 lr: 0.02
2019-03-27 20:52:10 iteration: 27065 loss: 0.0045 lr: 0.02
2019-03-27 20:52:42 iteration: 27070 loss: 0.0044 lr: 0.02
2019-03-27 20:53:09 iteration: 27075 loss: 0.0035 lr: 0.02
2019-03-27 20:53:29 iteration: 27080 loss: 0.0053 lr: 0.02
2019-03-27 20:54:27 iteration: 27085 loss: 0.0050 lr: 0.02
2019-03-27 20:54:58 iteration: 27090 loss: 0.0034 lr: 0.02
2019-03-27 20:55:26 iteration: 27095 loss: 0.0061 lr: 0.02
2019-03-27 20:55:49 iteration: 27100 loss: 0.0042 lr: 0.02
2019-03-27 20:56:17 iteration: 27105 loss: 0.0040 lr: 0.02
2019-03-27 20:56:45 iteration: 27110 loss: 0.0051 lr: 0.02
2019-03-27 20:57:22 iteration: 27115 loss: 0.0067 lr: 0.02
2019-03-27 20:58:47 iteration: 27120 loss: 0.0046 lr: 0.02
2019-03-27 20:59:21 iteration: 27125 loss: 0.0034 lr: 0.02
2019-03-27 20:59:54 iteration: 27130 loss: 0.0042 lr: 0.02
2019-03-27 21:00:41 iteration: 27135 loss: 0.0040 lr: 0.02
2019-03-27 21:00:56 iteration: 27140 loss: 0.0056 lr: 0.02
2019-03-27 21:01:54 iteration: 27145 loss: 0.0061 lr: 0.02
2019-03-27 21:02:45 iteration: 27150 loss: 0.0039 lr: 0.02
2019-03-27 21:03:22 iteration: 27155 loss: 0.0056 lr: 0.02
2019-03-27 21:03:41 iteration: 27160 loss: 0.0072 lr: 0.02
2019-03-27 21:04:02 iteration: 27165 loss: 0.0049 lr: 0.02
2019-03-27 21:04:34 iteration: 27170 loss: 0.0053 lr: 0.02
2019-03-27 21:05:16 iteration: 27175 loss: 0.0061 lr: 0.02
2019-03-27 21:05:57 iteration: 27180 loss: 0.0040 lr: 0.02
2019-03-27 21:06:33 iteration: 27185 loss: 0.0059 lr: 0.02
2019-03-27 21:07:27 iteration: 27190 loss: 0.0047 lr: 0.02
2019-03-27 21:07:41 iteration: 27195 loss: 0.0043 lr: 0.02
2019-03-27 21:08:23 iteration: 27200 loss: 0.0034 lr: 0.02
2019-03-27 21:08:43 iteration: 27205 loss: 0.0091 lr: 0.02
2019-03-27 21:09:01 iteration: 27210 loss: 0.0039 lr: 0.02
2019-03-27 21:09:50 iteration: 27215 loss: 0.0044 lr: 0.02
2019-03-27 21:11:05 iteration: 27220 loss: 0.0048 lr: 0.02
2019-03-27 21:11:21 iteration: 27225 loss: 0.0069 lr: 0.02
2019-03-27 21:11:37 iteration: 27230 loss: 0.0054 lr: 0.02
2019-03-27 21:12:11 iteration: 27235 loss: 0.0053 lr: 0.02
2019-03-27 21:13:03 iteration: 27240 loss: 0.0040 lr: 0.02
2019-03-27 21:13:14 iteration: 27245 loss: 0.0062 lr: 0.02
2019-03-27 21:14:01 iteration: 27250 loss: 0.0040 lr: 0.02
2019-03-27 21:15:29 iteration: 27255 loss: 0.0032 lr: 0.02
2019-03-27 21:16:27 iteration: 27260 loss: 0.0053 lr: 0.02
2019-03-27 21:17:21 iteration: 27265 loss: 0.0039 lr: 0.02
2019-03-27 21:18:12 iteration: 27270 loss: 0.0034 lr: 0.02
2019-03-27 21:18:55 iteration: 27275 loss: 0.0045 lr: 0.02
2019-03-27 21:19:28 iteration: 27280 loss: 0.0044 lr: 0.02
2019-03-27 21:19:58 iteration: 27285 loss: 0.0051 lr: 0.02
2019-03-27 21:20:13 iteration: 27290 loss: 0.0046 lr: 0.02
2019-03-27 21:20:35 iteration: 27295 loss: 0.0062 lr: 0.02
2019-03-27 21:21:33 iteration: 27300 loss: 0.0033 lr: 0.02
2019-03-27 21:22:53 iteration: 27305 loss: 0.0034 lr: 0.02
2019-03-27 21:23:40 iteration: 27310 loss: 0.0036 lr: 0.02
2019-03-27 21:24:08 iteration: 27315 loss: 0.0047 lr: 0.02
2019-03-27 21:25:15 iteration: 27320 loss: 0.0045 lr: 0.02
2019-03-27 21:25:35 iteration: 27325 loss: 0.0052 lr: 0.02
2019-03-27 21:26:16 iteration: 27330 loss: 0.0040 lr: 0.02
2019-03-27 21:26:31 iteration: 27335 loss: 0.0064 lr: 0.02
2019-03-27 21:26:55 iteration: 27340 loss: 0.0033 lr: 0.02
2019-03-27 21:27:49 iteration: 27345 loss: 0.0045 lr: 0.02
2019-03-27 21:29:20 iteration: 27350 loss: 0.0033 lr: 0.02
2019-03-27 21:29:28 iteration: 27355 loss: 0.0048 lr: 0.02
2019-03-27 21:29:59 iteration: 27360 loss: 0.0039 lr: 0.02
2019-03-27 21:30:26 iteration: 27365 loss: 0.0048 lr: 0.02
2019-03-27 21:30:58 iteration: 27370 loss: 0.0049 lr: 0.02
2019-03-27 21:31:37 iteration: 27375 loss: 0.0034 lr: 0.02
2019-03-27 21:32:28 iteration: 27380 loss: 0.0066 lr: 0.02
2019-03-27 21:33:13 iteration: 27385 loss: 0.0055 lr: 0.02
2019-03-27 21:34:40 iteration: 27390 loss: 0.0063 lr: 0.02
2019-03-27 21:35:02 iteration: 27395 loss: 0.0051 lr: 0.02
2019-03-27 21:35:33 iteration: 27400 loss: 0.0049 lr: 0.02
2019-03-27 21:36:53 iteration: 27405 loss: 0.0048 lr: 0.02
2019-03-27 21:38:18 iteration: 27410 loss: 0.0036 lr: 0.02
2019-03-27 21:39:34 iteration: 27415 loss: 0.0038 lr: 0.02
2019-03-27 21:40:09 iteration: 27420 loss: 0.0035 lr: 0.02
2019-03-27 21:40:55 iteration: 27425 loss: 0.0036 lr: 0.02
2019-03-27 21:41:15 iteration: 27430 loss: 0.0044 lr: 0.02
2019-03-27 21:41:48 iteration: 27435 loss: 0.0051 lr: 0.02
2019-03-27 21:42:29 iteration: 27440 loss: 0.0025 lr: 0.02
2019-03-27 21:42:55 iteration: 27445 loss: 0.0054 lr: 0.02
2019-03-27 21:43:48 iteration: 27450 loss: 0.0053 lr: 0.02
2019-03-27 21:44:35 iteration: 27455 loss: 0.0039 lr: 0.02
2019-03-27 21:45:28 iteration: 27460 loss: 0.0042 lr: 0.02
2019-03-27 21:46:12 iteration: 27465 loss: 0.0050 lr: 0.02
2019-03-27 21:46:42 iteration: 27470 loss: 0.0036 lr: 0.02
2019-03-27 21:46:58 iteration: 27475 loss: 0.0048 lr: 0.02
2019-03-27 21:47:58 iteration: 27480 loss: 0.0062 lr: 0.02
2019-03-27 21:48:36 iteration: 27485 loss: 0.0054 lr: 0.02
2019-03-27 21:49:32 iteration: 27490 loss: 0.0044 lr: 0.02
2019-03-27 21:50:10 iteration: 27495 loss: 0.0047 lr: 0.02
2019-03-27 21:50:43 iteration: 27500 loss: 0.0066 lr: 0.02
2019-03-27 21:51:32 iteration: 27505 loss: 0.0051 lr: 0.02
2019-03-27 21:52:19 iteration: 27510 loss: 0.0049 lr: 0.02
2019-03-27 21:53:01 iteration: 27515 loss: 0.0043 lr: 0.02
2019-03-27 21:53:14 iteration: 27520 loss: 0.0055 lr: 0.02
2019-03-27 21:53:40 iteration: 27525 loss: 0.0041 lr: 0.02
2019-03-27 21:54:47 iteration: 27530 loss: 0.0039 lr: 0.02
2019-03-27 21:55:46 iteration: 27535 loss: 0.0043 lr: 0.02
2019-03-27 21:56:21 iteration: 27540 loss: 0.0038 lr: 0.02
2019-03-27 21:57:11 iteration: 27545 loss: 0.0062 lr: 0.02
2019-03-27 21:57:26 iteration: 27550 loss: 0.0047 lr: 0.02
2019-03-27 21:57:47 iteration: 27555 loss: 0.0045 lr: 0.02
2019-03-27 21:58:12 iteration: 27560 loss: 0.0043 lr: 0.02
2019-03-27 21:59:25 iteration: 27565 loss: 0.0042 lr: 0.02
2019-03-27 22:00:31 iteration: 27570 loss: 0.0040 lr: 0.02
2019-03-27 22:01:16 iteration: 27575 loss: 0.0034 lr: 0.02
2019-03-27 22:01:55 iteration: 27580 loss: 0.0034 lr: 0.02
2019-03-27 22:02:38 iteration: 27585 loss: 0.0036 lr: 0.02
2019-03-27 22:03:00 iteration: 27590 loss: 0.0041 lr: 0.02
2019-03-27 22:03:13 iteration: 27595 loss: 0.0045 lr: 0.02
2019-03-27 22:03:44 iteration: 27600 loss: 0.0041 lr: 0.02
2019-03-27 22:04:24 iteration: 27605 loss: 0.0032 lr: 0.02
2019-03-27 22:05:21 iteration: 27610 loss: 0.0059 lr: 0.02
2019-03-27 22:05:50 iteration: 27615 loss: 0.0042 lr: 0.02
2019-03-27 22:06:03 iteration: 27620 loss: 0.0051 lr: 0.02
2019-03-27 22:07:04 iteration: 27625 loss: 0.0037 lr: 0.02
2019-03-27 22:07:59 iteration: 27630 loss: 0.0062 lr: 0.02
2019-03-27 22:08:15 iteration: 27635 loss: 0.0040 lr: 0.02
2019-03-27 22:08:59 iteration: 27640 loss: 0.0043 lr: 0.02
2019-03-27 22:09:34 iteration: 27645 loss: 0.0052 lr: 0.02
2019-03-27 22:09:48 iteration: 27650 loss: 0.0038 lr: 0.02
2019-03-27 22:11:02 iteration: 27655 loss: 0.0040 lr: 0.02
2019-03-27 22:11:37 iteration: 27660 loss: 0.0044 lr: 0.02
2019-03-27 22:11:51 iteration: 27665 loss: 0.0043 lr: 0.02
2019-03-27 22:12:23 iteration: 27670 loss: 0.0046 lr: 0.02
2019-03-27 22:13:20 iteration: 27675 loss: 0.0041 lr: 0.02
2019-03-27 22:14:02 iteration: 27680 loss: 0.0043 lr: 0.02
2019-03-27 22:14:30 iteration: 27685 loss: 0.0047 lr: 0.02
2019-03-27 22:14:48 iteration: 27690 loss: 0.0053 lr: 0.02
2019-03-27 22:15:33 iteration: 27695 loss: 0.0032 lr: 0.02
2019-03-27 22:17:45 iteration: 27700 loss: 0.0037 lr: 0.02
2019-03-27 22:18:05 iteration: 27705 loss: 0.0042 lr: 0.02
2019-03-27 22:18:56 iteration: 27710 loss: 0.0046 lr: 0.02
2019-03-27 22:19:38 iteration: 27715 loss: 0.0064 lr: 0.02
2019-03-27 22:20:12 iteration: 27720 loss: 0.0037 lr: 0.02
2019-03-27 22:20:29 iteration: 27725 loss: 0.0055 lr: 0.02
2019-03-27 22:21:31 iteration: 27730 loss: 0.0027 lr: 0.02
2019-03-27 22:22:58 iteration: 27735 loss: 0.0045 lr: 0.02
2019-03-27 22:24:23 iteration: 27740 loss: 0.0052 lr: 0.02
2019-03-27 22:24:49 iteration: 27745 loss: 0.0057 lr: 0.02
2019-03-27 22:26:11 iteration: 27750 loss: 0.0036 lr: 0.02
2019-03-27 22:26:57 iteration: 27755 loss: 0.0048 lr: 0.02
2019-03-27 22:27:12 iteration: 27760 loss: 0.0042 lr: 0.02
2019-03-27 22:28:20 iteration: 27765 loss: 0.0032 lr: 0.02
2019-03-27 22:29:11 iteration: 27770 loss: 0.0045 lr: 0.02
2019-03-27 22:30:06 iteration: 27775 loss: 0.0041 lr: 0.02
2019-03-27 22:30:56 iteration: 27780 loss: 0.0050 lr: 0.02
2019-03-27 22:31:49 iteration: 27785 loss: 0.0037 lr: 0.02
2019-03-27 22:32:12 iteration: 27790 loss: 0.0032 lr: 0.02
2019-03-27 22:32:28 iteration: 27795 loss: 0.0044 lr: 0.02
2019-03-27 22:32:41 iteration: 27800 loss: 0.0062 lr: 0.02
2019-03-27 22:32:51 iteration: 27805 loss: 0.0056 lr: 0.02
2019-03-27 22:33:39 iteration: 27810 loss: 0.0061 lr: 0.02
2019-03-27 22:34:03 iteration: 27815 loss: 0.0058 lr: 0.02
2019-03-27 22:34:18 iteration: 27820 loss: 0.0047 lr: 0.02
2019-03-27 22:35:44 iteration: 27825 loss: 0.0059 lr: 0.02
2019-03-27 22:36:51 iteration: 27830 loss: 0.0051 lr: 0.02
2019-03-27 22:37:57 iteration: 27835 loss: 0.0034 lr: 0.02
2019-03-27 22:38:13 iteration: 27840 loss: 0.0048 lr: 0.02
2019-03-27 22:39:06 iteration: 27845 loss: 0.0048 lr: 0.02
2019-03-27 22:39:56 iteration: 27850 loss: 0.0040 lr: 0.02
2019-03-27 22:40:58 iteration: 27855 loss: 0.0031 lr: 0.02
2019-03-27 22:41:13 iteration: 27860 loss: 0.0044 lr: 0.02
2019-03-27 22:42:00 iteration: 27865 loss: 0.0028 lr: 0.02
2019-03-27 22:42:58 iteration: 27870 loss: 0.0049 lr: 0.02
2019-03-27 22:43:12 iteration: 27875 loss: 0.0057 lr: 0.02
2019-03-27 22:43:36 iteration: 27880 loss: 0.0050 lr: 0.02
2019-03-27 22:44:14 iteration: 27885 loss: 0.0045 lr: 0.02
2019-03-27 22:45:04 iteration: 27890 loss: 0.0038 lr: 0.02
2019-03-27 22:45:54 iteration: 27895 loss: 0.0037 lr: 0.02
2019-03-27 22:46:31 iteration: 27900 loss: 0.0045 lr: 0.02
2019-03-27 22:47:51 iteration: 27905 loss: 0.0029 lr: 0.02
2019-03-27 22:48:10 iteration: 27910 loss: 0.0054 lr: 0.02
2019-03-27 22:48:51 iteration: 27915 loss: 0.0037 lr: 0.02
2019-03-27 22:49:26 iteration: 27920 loss: 0.0035 lr: 0.02
2019-03-27 22:49:51 iteration: 27925 loss: 0.0031 lr: 0.02
2019-03-27 22:50:01 iteration: 27930 loss: 0.0074 lr: 0.02
2019-03-27 22:50:16 iteration: 27935 loss: 0.0068 lr: 0.02
2019-03-27 22:50:38 iteration: 27940 loss: 0.0040 lr: 0.02
2019-03-27 22:51:04 iteration: 27945 loss: 0.0046 lr: 0.02
2019-03-27 22:51:27 iteration: 27950 loss: 0.0050 lr: 0.02
2019-03-27 22:52:18 iteration: 27955 loss: 0.0034 lr: 0.02
2019-03-27 22:52:48 iteration: 27960 loss: 0.0056 lr: 0.02
2019-03-27 22:53:04 iteration: 27965 loss: 0.0039 lr: 0.02
2019-03-27 22:53:50 iteration: 27970 loss: 0.0043 lr: 0.02
2019-03-27 22:55:04 iteration: 27975 loss: 0.0040 lr: 0.02
2019-03-27 22:55:25 iteration: 27980 loss: 0.0038 lr: 0.02
2019-03-27 22:55:40 iteration: 27985 loss: 0.0039 lr: 0.02
2019-03-27 22:56:03 iteration: 27990 loss: 0.0036 lr: 0.02
2019-03-27 22:56:19 iteration: 27995 loss: 0.0057 lr: 0.02
2019-03-27 22:56:59 iteration: 28000 loss: 0.0043 lr: 0.02
2019-03-27 22:57:22 iteration: 28005 loss: 0.0049 lr: 0.02
2019-03-27 22:58:06 iteration: 28010 loss: 0.0059 lr: 0.02
2019-03-27 22:58:49 iteration: 28015 loss: 0.0047 lr: 0.02
2019-03-27 22:59:14 iteration: 28020 loss: 0.0063 lr: 0.02
2019-03-27 22:59:29 iteration: 28025 loss: 0.0062 lr: 0.02
2019-03-27 23:01:05 iteration: 28030 loss: 0.0043 lr: 0.02
2019-03-27 23:02:47 iteration: 28035 loss: 0.0044 lr: 0.02
2019-03-27 23:03:20 iteration: 28040 loss: 0.0052 lr: 0.02
2019-03-27 23:04:01 iteration: 28045 loss: 0.0053 lr: 0.02
2019-03-27 23:05:09 iteration: 28050 loss: 0.0060 lr: 0.02
2019-03-27 23:06:07 iteration: 28055 loss: 0.0031 lr: 0.02
2019-03-27 23:07:10 iteration: 28060 loss: 0.0043 lr: 0.02
2019-03-27 23:07:31 iteration: 28065 loss: 0.0053 lr: 0.02
2019-03-27 23:07:52 iteration: 28070 loss: 0.0045 lr: 0.02
2019-03-27 23:08:06 iteration: 28075 loss: 0.0054 lr: 0.02
2019-03-27 23:08:30 iteration: 28080 loss: 0.0038 lr: 0.02
2019-03-27 23:09:11 iteration: 28085 loss: 0.0041 lr: 0.02
2019-03-27 23:09:40 iteration: 28090 loss: 0.0040 lr: 0.02
2019-03-27 23:09:59 iteration: 28095 loss: 0.0047 lr: 0.02
2019-03-27 23:10:43 iteration: 28100 loss: 0.0042 lr: 0.02
2019-03-27 23:11:48 iteration: 28105 loss: 0.0042 lr: 0.02
2019-03-27 23:11:58 iteration: 28110 loss: 0.0049 lr: 0.02
2019-03-27 23:12:59 iteration: 28115 loss: 0.0035 lr: 0.02
2019-03-27 23:13:47 iteration: 28120 loss: 0.0053 lr: 0.02
2019-03-27 23:14:04 iteration: 28125 loss: 0.0045 lr: 0.02
2019-03-27 23:14:51 iteration: 28130 loss: 0.0046 lr: 0.02
2019-03-27 23:15:49 iteration: 28135 loss: 0.0036 lr: 0.02
2019-03-27 23:17:04 iteration: 28140 loss: 0.0035 lr: 0.02
2019-03-27 23:17:33 iteration: 28145 loss: 0.0038 lr: 0.02
2019-03-27 23:18:15 iteration: 28150 loss: 0.0038 lr: 0.02
2019-03-27 23:18:48 iteration: 28155 loss: 0.0044 lr: 0.02
2019-03-27 23:19:07 iteration: 28160 loss: 0.0049 lr: 0.02
2019-03-27 23:19:19 iteration: 28165 loss: 0.0070 lr: 0.02
2019-03-27 23:20:10 iteration: 28170 loss: 0.0038 lr: 0.02
2019-03-27 23:20:33 iteration: 28175 loss: 0.0040 lr: 0.02
2019-03-27 23:21:25 iteration: 28180 loss: 0.0039 lr: 0.02
2019-03-27 23:21:46 iteration: 28185 loss: 0.0062 lr: 0.02
2019-03-27 23:22:14 iteration: 28190 loss: 0.0061 lr: 0.02
2019-03-27 23:23:22 iteration: 28195 loss: 0.0059 lr: 0.02
2019-03-27 23:24:12 iteration: 28200 loss: 0.0042 lr: 0.02
2019-03-27 23:25:03 iteration: 28205 loss: 0.0044 lr: 0.02
2019-03-27 23:25:28 iteration: 28210 loss: 0.0048 lr: 0.02
2019-03-27 23:26:59 iteration: 28215 loss: 0.0043 lr: 0.02
2019-03-27 23:27:12 iteration: 28220 loss: 0.0060 lr: 0.02
2019-03-27 23:27:48 iteration: 28225 loss: 0.0050 lr: 0.02
2019-03-27 23:28:02 iteration: 28230 loss: 0.0065 lr: 0.02
2019-03-27 23:29:03 iteration: 28235 loss: 0.0041 lr: 0.02
2019-03-27 23:29:29 iteration: 28240 loss: 0.0048 lr: 0.02
2019-03-27 23:30:10 iteration: 28245 loss: 0.0043 lr: 0.02
2019-03-27 23:30:30 iteration: 28250 loss: 0.0034 lr: 0.02
2019-03-27 23:30:49 iteration: 28255 loss: 0.0065 lr: 0.02
2019-03-27 23:31:07 iteration: 28260 loss: 0.0039 lr: 0.02
2019-03-27 23:32:02 iteration: 28265 loss: 0.0047 lr: 0.02
2019-03-27 23:32:27 iteration: 28270 loss: 0.0040 lr: 0.02
2019-03-27 23:33:02 iteration: 28275 loss: 0.0045 lr: 0.02
2019-03-27 23:33:54 iteration: 28280 loss: 0.0031 lr: 0.02
2019-03-27 23:34:29 iteration: 28285 loss: 0.0038 lr: 0.02
2019-03-27 23:35:20 iteration: 28290 loss: 0.0055 lr: 0.02
2019-03-27 23:35:54 iteration: 28295 loss: 0.0079 lr: 0.02
2019-03-27 23:36:08 iteration: 28300 loss: 0.0038 lr: 0.02
2019-03-27 23:37:08 iteration: 28305 loss: 0.0045 lr: 0.02
2019-03-27 23:37:23 iteration: 28310 loss: 0.0054 lr: 0.02
2019-03-27 23:37:50 iteration: 28315 loss: 0.0046 lr: 0.02
2019-03-27 23:38:43 iteration: 28320 loss: 0.0051 lr: 0.02
2019-03-27 23:39:58 iteration: 28325 loss: 0.0055 lr: 0.02
2019-03-27 23:40:32 iteration: 28330 loss: 0.0053 lr: 0.02
2019-03-27 23:40:49 iteration: 28335 loss: 0.0048 lr: 0.02
2019-03-27 23:41:09 iteration: 28340 loss: 0.0050 lr: 0.02
2019-03-27 23:42:23 iteration: 28345 loss: 0.0038 lr: 0.02
2019-03-27 23:42:59 iteration: 28350 loss: 0.0039 lr: 0.02
2019-03-27 23:43:57 iteration: 28355 loss: 0.0044 lr: 0.02
2019-03-27 23:44:52 iteration: 28360 loss: 0.0039 lr: 0.02
2019-03-27 23:45:06 iteration: 28365 loss: 0.0049 lr: 0.02
2019-03-27 23:45:46 iteration: 28370 loss: 0.0035 lr: 0.02
2019-03-27 23:46:24 iteration: 28375 loss: 0.0035 lr: 0.02
2019-03-27 23:47:15 iteration: 28380 loss: 0.0040 lr: 0.02
2019-03-27 23:48:48 iteration: 28385 loss: 0.0031 lr: 0.02
2019-03-27 23:49:42 iteration: 28390 loss: 0.0039 lr: 0.02
2019-03-27 23:50:39 iteration: 28395 loss: 0.0037 lr: 0.02
2019-03-27 23:51:39 iteration: 28400 loss: 0.0036 lr: 0.02
2019-03-27 23:52:23 iteration: 28405 loss: 0.0049 lr: 0.02
2019-03-27 23:52:43 iteration: 28410 loss: 0.0043 lr: 0.02
2019-03-27 23:53:14 iteration: 28415 loss: 0.0037 lr: 0.02
2019-03-27 23:54:33 iteration: 28420 loss: 0.0037 lr: 0.02
2019-03-27 23:55:32 iteration: 28425 loss: 0.0043 lr: 0.02
2019-03-27 23:56:18 iteration: 28430 loss: 0.0051 lr: 0.02
2019-03-27 23:57:06 iteration: 28435 loss: 0.0033 lr: 0.02
2019-03-27 23:57:22 iteration: 28440 loss: 0.0046 lr: 0.02
2019-03-27 23:57:57 iteration: 28445 loss: 0.0044 lr: 0.02
2019-03-27 23:58:39 iteration: 28450 loss: 0.0054 lr: 0.02
2019-03-27 23:58:53 iteration: 28455 loss: 0.0060 lr: 0.02
2019-03-27 23:59:33 iteration: 28460 loss: 0.0051 lr: 0.02
2019-03-28 00:00:28 iteration: 28465 loss: 0.0037 lr: 0.02
2019-03-28 00:01:01 iteration: 28470 loss: 0.0037 lr: 0.02
2019-03-28 00:01:38 iteration: 28475 loss: 0.0038 lr: 0.02
2019-03-28 00:02:13 iteration: 28480 loss: 0.0050 lr: 0.02
2019-03-28 00:03:20 iteration: 28485 loss: 0.0039 lr: 0.02
2019-03-28 00:03:40 iteration: 28490 loss: 0.0043 lr: 0.02
2019-03-28 00:04:01 iteration: 28495 loss: 0.0077 lr: 0.02
2019-03-28 00:04:10 iteration: 28500 loss: 0.0069 lr: 0.02
2019-03-28 00:04:34 iteration: 28505 loss: 0.0031 lr: 0.02
2019-03-28 00:04:56 iteration: 28510 loss: 0.0048 lr: 0.02
2019-03-28 00:05:33 iteration: 28515 loss: 0.0054 lr: 0.02
2019-03-28 00:05:52 iteration: 28520 loss: 0.0038 lr: 0.02
2019-03-28 00:06:03 iteration: 28525 loss: 0.0047 lr: 0.02
2019-03-28 00:07:18 iteration: 28530 loss: 0.0031 lr: 0.02
2019-03-28 00:07:40 iteration: 28535 loss: 0.0053 lr: 0.02
2019-03-28 00:08:04 iteration: 28540 loss: 0.0047 lr: 0.02
2019-03-28 00:08:50 iteration: 28545 loss: 0.0049 lr: 0.02
2019-03-28 00:09:54 iteration: 28550 loss: 0.0043 lr: 0.02
2019-03-28 00:10:23 iteration: 28555 loss: 0.0028 lr: 0.02
2019-03-28 00:11:07 iteration: 28560 loss: 0.0048 lr: 0.02
2019-03-28 00:11:36 iteration: 28565 loss: 0.0039 lr: 0.02
2019-03-28 00:12:03 iteration: 28570 loss: 0.0035 lr: 0.02
2019-03-28 00:12:43 iteration: 28575 loss: 0.0041 lr: 0.02
2019-03-28 00:13:50 iteration: 28580 loss: 0.0059 lr: 0.02
2019-03-28 00:14:08 iteration: 28585 loss: 0.0049 lr: 0.02
2019-03-28 00:15:46 iteration: 28590 loss: 0.0033 lr: 0.02
2019-03-28 00:16:14 iteration: 28595 loss: 0.0045 lr: 0.02
2019-03-28 00:16:33 iteration: 28600 loss: 0.0042 lr: 0.02
2019-03-28 00:17:22 iteration: 28605 loss: 0.0040 lr: 0.02
2019-03-28 00:17:48 iteration: 28610 loss: 0.0032 lr: 0.02
2019-03-28 00:18:10 iteration: 28615 loss: 0.0039 lr: 0.02
2019-03-28 00:18:34 iteration: 28620 loss: 0.0044 lr: 0.02
2019-03-28 00:19:01 iteration: 28625 loss: 0.0034 lr: 0.02
2019-03-28 00:19:24 iteration: 28630 loss: 0.0043 lr: 0.02
2019-03-28 00:20:33 iteration: 28635 loss: 0.0035 lr: 0.02
2019-03-28 00:21:31 iteration: 28640 loss: 0.0034 lr: 0.02
2019-03-28 00:21:52 iteration: 28645 loss: 0.0054 lr: 0.02
2019-03-28 00:22:40 iteration: 28650 loss: 0.0049 lr: 0.02
2019-03-28 00:23:00 iteration: 28655 loss: 0.0055 lr: 0.02
2019-03-28 00:23:33 iteration: 28660 loss: 0.0039 lr: 0.02
2019-03-28 00:24:09 iteration: 28665 loss: 0.0038 lr: 0.02
2019-03-28 00:24:25 iteration: 28670 loss: 0.0062 lr: 0.02
2019-03-28 00:25:06 iteration: 28675 loss: 0.0046 lr: 0.02
2019-03-28 00:25:23 iteration: 28680 loss: 0.0058 lr: 0.02
2019-03-28 00:26:33 iteration: 28685 loss: 0.0051 lr: 0.02
2019-03-28 00:27:53 iteration: 28690 loss: 0.0032 lr: 0.02
2019-03-28 00:29:24 iteration: 28695 loss: 0.0028 lr: 0.02
2019-03-28 00:29:44 iteration: 28700 loss: 0.0047 lr: 0.02
2019-03-28 00:29:57 iteration: 28705 loss: 0.0046 lr: 0.02
2019-03-28 00:31:01 iteration: 28710 loss: 0.0036 lr: 0.02
2019-03-28 00:31:18 iteration: 28715 loss: 0.0066 lr: 0.02
2019-03-28 00:32:02 iteration: 28720 loss: 0.0044 lr: 0.02
2019-03-28 00:32:22 iteration: 28725 loss: 0.0077 lr: 0.02
2019-03-28 00:33:47 iteration: 28730 loss: 0.0036 lr: 0.02
2019-03-28 00:34:22 iteration: 28735 loss: 0.0034 lr: 0.02
2019-03-28 00:35:35 iteration: 28740 loss: 0.0046 lr: 0.02
2019-03-28 00:37:04 iteration: 28745 loss: 0.0046 lr: 0.02
2019-03-28 00:38:10 iteration: 28750 loss: 0.0053 lr: 0.02
2019-03-28 00:39:31 iteration: 28755 loss: 0.0033 lr: 0.02
2019-03-28 00:39:50 iteration: 28760 loss: 0.0049 lr: 0.02
2019-03-28 00:41:50 iteration: 28765 loss: 0.0029 lr: 0.02
2019-03-28 00:42:35 iteration: 28770 loss: 0.0041 lr: 0.02
2019-03-28 00:43:12 iteration: 28775 loss: 0.0041 lr: 0.02
2019-03-28 00:43:49 iteration: 28780 loss: 0.0050 lr: 0.02
2019-03-28 00:44:04 iteration: 28785 loss: 0.0043 lr: 0.02
2019-03-28 00:44:15 iteration: 28790 loss: 0.0046 lr: 0.02
2019-03-28 00:44:55 iteration: 28795 loss: 0.0056 lr: 0.02
2019-03-28 00:45:53 iteration: 28800 loss: 0.0042 lr: 0.02
2019-03-28 00:46:48 iteration: 28805 loss: 0.0053 lr: 0.02
2019-03-28 00:47:34 iteration: 28810 loss: 0.0057 lr: 0.02
2019-03-28 00:47:58 iteration: 28815 loss: 0.0042 lr: 0.02
2019-03-28 00:48:51 iteration: 28820 loss: 0.0057 lr: 0.02
2019-03-28 00:49:13 iteration: 28825 loss: 0.0042 lr: 0.02
2019-03-28 00:49:57 iteration: 28830 loss: 0.0039 lr: 0.02
2019-03-28 00:50:42 iteration: 28835 loss: 0.0043 lr: 0.02
2019-03-28 00:51:22 iteration: 28840 loss: 0.0038 lr: 0.02
2019-03-28 00:51:37 iteration: 28845 loss: 0.0052 lr: 0.02
2019-03-28 00:51:56 iteration: 28850 loss: 0.0052 lr: 0.02
2019-03-28 00:52:25 iteration: 28855 loss: 0.0043 lr: 0.02
2019-03-28 00:53:14 iteration: 28860 loss: 0.0057 lr: 0.02
2019-03-28 00:53:35 iteration: 28865 loss: 0.0043 lr: 0.02
2019-03-28 00:54:16 iteration: 28870 loss: 0.0042 lr: 0.02
2019-03-28 00:55:07 iteration: 28875 loss: 0.0046 lr: 0.02
2019-03-28 00:55:23 iteration: 28880 loss: 0.0044 lr: 0.02
2019-03-28 00:55:54 iteration: 28885 loss: 0.0041 lr: 0.02
2019-03-28 00:56:40 iteration: 28890 loss: 0.0051 lr: 0.02
2019-03-28 00:56:58 iteration: 28895 loss: 0.0059 lr: 0.02
2019-03-28 00:57:50 iteration: 28900 loss: 0.0043 lr: 0.02
2019-03-28 00:58:46 iteration: 28905 loss: 0.0045 lr: 0.02
2019-03-28 00:59:16 iteration: 28910 loss: 0.0047 lr: 0.02
2019-03-28 00:59:30 iteration: 28915 loss: 0.0064 lr: 0.02
2019-03-28 01:00:23 iteration: 28920 loss: 0.0043 lr: 0.02
2019-03-28 01:01:03 iteration: 28925 loss: 0.0051 lr: 0.02
2019-03-28 01:01:17 iteration: 28930 loss: 0.0056 lr: 0.02
2019-03-28 01:01:38 iteration: 28935 loss: 0.0049 lr: 0.02
2019-03-28 01:03:09 iteration: 28940 loss: 0.0035 lr: 0.02
2019-03-28 01:04:02 iteration: 28945 loss: 0.0039 lr: 0.02
2019-03-28 01:04:17 iteration: 28950 loss: 0.0060 lr: 0.02
2019-03-28 01:05:11 iteration: 28955 loss: 0.0035 lr: 0.02
2019-03-28 01:05:43 iteration: 28960 loss: 0.0044 lr: 0.02
2019-03-28 01:06:13 iteration: 28965 loss: 0.0070 lr: 0.02
2019-03-28 01:06:28 iteration: 28970 loss: 0.0049 lr: 0.02
2019-03-28 01:07:23 iteration: 28975 loss: 0.0039 lr: 0.02
2019-03-28 01:09:27 iteration: 28980 loss: 0.0029 lr: 0.02
2019-03-28 01:10:15 iteration: 28985 loss: 0.0043 lr: 0.02
2019-03-28 01:10:40 iteration: 28990 loss: 0.0051 lr: 0.02
2019-03-28 01:11:10 iteration: 28995 loss: 0.0033 lr: 0.02
2019-03-28 01:11:49 iteration: 29000 loss: 0.0041 lr: 0.02
2019-03-28 01:12:22 iteration: 29005 loss: 0.0039 lr: 0.02
2019-03-28 01:13:04 iteration: 29010 loss: 0.0042 lr: 0.02
2019-03-28 01:14:04 iteration: 29015 loss: 0.0035 lr: 0.02
2019-03-28 01:14:42 iteration: 29020 loss: 0.0035 lr: 0.02
2019-03-28 01:15:21 iteration: 29025 loss: 0.0085 lr: 0.02
2019-03-28 01:15:39 iteration: 29030 loss: 0.0044 lr: 0.02
2019-03-28 01:17:06 iteration: 29035 loss: 0.0044 lr: 0.02
2019-03-28 01:17:32 iteration: 29040 loss: 0.0049 lr: 0.02
2019-03-28 01:18:39 iteration: 29045 loss: 0.0044 lr: 0.02
2019-03-28 01:19:05 iteration: 29050 loss: 0.0043 lr: 0.02
2019-03-28 01:19:15 iteration: 29055 loss: 0.0056 lr: 0.02
2019-03-28 01:19:51 iteration: 29060 loss: 0.0032 lr: 0.02
2019-03-28 01:20:38 iteration: 29065 loss: 0.0064 lr: 0.02
2019-03-28 01:20:55 iteration: 29070 loss: 0.0055 lr: 0.02
2019-03-28 01:21:15 iteration: 29075 loss: 0.0043 lr: 0.02
2019-03-28 01:22:04 iteration: 29080 loss: 0.0038 lr: 0.02
2019-03-28 01:22:45 iteration: 29085 loss: 0.0052 lr: 0.02
2019-03-28 01:23:18 iteration: 29090 loss: 0.0043 lr: 0.02
2019-03-28 01:23:50 iteration: 29095 loss: 0.0045 lr: 0.02
2019-03-28 01:24:14 iteration: 29100 loss: 0.0044 lr: 0.02
2019-03-28 01:24:48 iteration: 29105 loss: 0.0040 lr: 0.02
2019-03-28 01:25:44 iteration: 29110 loss: 0.0040 lr: 0.02
2019-03-28 01:27:01 iteration: 29115 loss: 0.0031 lr: 0.02
2019-03-28 01:27:12 iteration: 29120 loss: 0.0054 lr: 0.02
2019-03-28 01:28:05 iteration: 29125 loss: 0.0057 lr: 0.02
2019-03-28 01:29:06 iteration: 29130 loss: 0.0042 lr: 0.02
2019-03-28 01:29:16 iteration: 29135 loss: 0.0055 lr: 0.02
2019-03-28 01:30:41 iteration: 29140 loss: 0.0058 lr: 0.02
2019-03-28 01:31:37 iteration: 29145 loss: 0.0056 lr: 0.02
2019-03-28 01:32:15 iteration: 29150 loss: 0.0047 lr: 0.02
2019-03-28 01:32:46 iteration: 29155 loss: 0.0043 lr: 0.02
2019-03-28 01:33:40 iteration: 29160 loss: 0.0059 lr: 0.02
2019-03-28 01:34:04 iteration: 29165 loss: 0.0053 lr: 0.02
2019-03-28 01:34:49 iteration: 29170 loss: 0.0043 lr: 0.02
2019-03-28 01:35:43 iteration: 29175 loss: 0.0047 lr: 0.02
2019-03-28 01:36:09 iteration: 29180 loss: 0.0068 lr: 0.02
2019-03-28 01:36:24 iteration: 29185 loss: 0.0048 lr: 0.02
2019-03-28 01:36:46 iteration: 29190 loss: 0.0038 lr: 0.02
2019-03-28 01:37:20 iteration: 29195 loss: 0.0041 lr: 0.02
2019-03-28 01:37:48 iteration: 29200 loss: 0.0033 lr: 0.02
2019-03-28 01:38:07 iteration: 29205 loss: 0.0056 lr: 0.02
2019-03-28 01:38:41 iteration: 29210 loss: 0.0046 lr: 0.02
2019-03-28 01:39:03 iteration: 29215 loss: 0.0044 lr: 0.02
2019-03-28 01:39:23 iteration: 29220 loss: 0.0049 lr: 0.02
2019-03-28 01:40:23 iteration: 29225 loss: 0.0037 lr: 0.02
2019-03-28 01:41:19 iteration: 29230 loss: 0.0043 lr: 0.02
2019-03-28 01:41:36 iteration: 29235 loss: 0.0048 lr: 0.02
2019-03-28 01:42:33 iteration: 29240 loss: 0.0033 lr: 0.02
2019-03-28 01:43:05 iteration: 29245 loss: 0.0043 lr: 0.02
2019-03-28 01:43:56 iteration: 29250 loss: 0.0038 lr: 0.02
2019-03-28 01:44:48 iteration: 29255 loss: 0.0052 lr: 0.02
2019-03-28 01:45:34 iteration: 29260 loss: 0.0048 lr: 0.02
2019-03-28 01:45:42 iteration: 29265 loss: 0.0059 lr: 0.02
2019-03-28 01:46:36 iteration: 29270 loss: 0.0043 lr: 0.02
2019-03-28 01:47:27 iteration: 29275 loss: 0.0051 lr: 0.02
2019-03-28 01:48:12 iteration: 29280 loss: 0.0048 lr: 0.02
2019-03-28 01:48:41 iteration: 29285 loss: 0.0043 lr: 0.02
2019-03-28 01:49:33 iteration: 29290 loss: 0.0048 lr: 0.02
2019-03-28 01:50:01 iteration: 29295 loss: 0.0082 lr: 0.02
2019-03-28 01:51:36 iteration: 29300 loss: 0.0032 lr: 0.02
2019-03-28 01:51:54 iteration: 29305 loss: 0.0049 lr: 0.02
2019-03-28 01:52:14 iteration: 29310 loss: 0.0044 lr: 0.02
2019-03-28 01:53:23 iteration: 29315 loss: 0.0024 lr: 0.02
2019-03-28 01:53:41 iteration: 29320 loss: 0.0044 lr: 0.02
2019-03-28 01:53:59 iteration: 29325 loss: 0.0043 lr: 0.02
2019-03-28 01:54:14 iteration: 29330 loss: 0.0048 lr: 0.02
2019-03-28 01:55:08 iteration: 29335 loss: 0.0043 lr: 0.02
2019-03-28 01:55:58 iteration: 29340 loss: 0.0032 lr: 0.02
2019-03-28 01:56:19 iteration: 29345 loss: 0.0039 lr: 0.02
2019-03-28 01:56:57 iteration: 29350 loss: 0.0033 lr: 0.02
2019-03-28 01:57:25 iteration: 29355 loss: 0.0066 lr: 0.02
2019-03-28 01:57:45 iteration: 29360 loss: 0.0062 lr: 0.02
2019-03-28 01:58:25 iteration: 29365 loss: 0.0054 lr: 0.02
2019-03-28 01:59:27 iteration: 29370 loss: 0.0037 lr: 0.02
2019-03-28 01:59:41 iteration: 29375 loss: 0.0043 lr: 0.02
2019-03-28 02:00:30 iteration: 29380 loss: 0.0053 lr: 0.02
2019-03-28 02:01:10 iteration: 29385 loss: 0.0028 lr: 0.02
2019-03-28 02:02:12 iteration: 29390 loss: 0.0038 lr: 0.02
2019-03-28 02:03:30 iteration: 29395 loss: 0.0027 lr: 0.02
2019-03-28 02:04:21 iteration: 29400 loss: 0.0036 lr: 0.02
2019-03-28 02:04:37 iteration: 29405 loss: 0.0047 lr: 0.02
2019-03-28 02:04:53 iteration: 29410 loss: 0.0050 lr: 0.02
2019-03-28 02:05:22 iteration: 29415 loss: 0.0047 lr: 0.02
2019-03-28 02:06:11 iteration: 29420 loss: 0.0030 lr: 0.02
2019-03-28 02:06:31 iteration: 29425 loss: 0.0062 lr: 0.02
2019-03-28 02:07:08 iteration: 29430 loss: 0.0042 lr: 0.02
2019-03-28 02:08:07 iteration: 29435 loss: 0.0042 lr: 0.02
2019-03-28 02:08:52 iteration: 29440 loss: 0.0033 lr: 0.02
2019-03-28 02:09:14 iteration: 29445 loss: 0.0044 lr: 0.02
2019-03-28 02:09:53 iteration: 29450 loss: 0.0052 lr: 0.02
2019-03-28 02:10:19 iteration: 29455 loss: 0.0053 lr: 0.02
2019-03-28 02:11:17 iteration: 29460 loss: 0.0038 lr: 0.02
2019-03-28 02:11:32 iteration: 29465 loss: 0.0048 lr: 0.02
2019-03-28 02:11:51 iteration: 29470 loss: 0.0054 lr: 0.02
2019-03-28 02:12:38 iteration: 29475 loss: 0.0028 lr: 0.02
2019-03-28 02:13:01 iteration: 29480 loss: 0.0056 lr: 0.02
2019-03-28 02:13:30 iteration: 29485 loss: 0.0040 lr: 0.02
2019-03-28 02:14:09 iteration: 29490 loss: 0.0034 lr: 0.02
2019-03-28 02:14:21 iteration: 29495 loss: 0.0068 lr: 0.02
2019-03-28 02:15:01 iteration: 29500 loss: 0.0049 lr: 0.02
2019-03-28 02:15:14 iteration: 29505 loss: 0.0047 lr: 0.02
2019-03-28 02:15:31 iteration: 29510 loss: 0.0040 lr: 0.02
2019-03-28 02:16:07 iteration: 29515 loss: 0.0078 lr: 0.02
2019-03-28 02:17:10 iteration: 29520 loss: 0.0036 lr: 0.02
2019-03-28 02:17:36 iteration: 29525 loss: 0.0047 lr: 0.02
2019-03-28 02:17:58 iteration: 29530 loss: 0.0034 lr: 0.02
2019-03-28 02:18:39 iteration: 29535 loss: 0.0036 lr: 0.02
2019-03-28 02:19:44 iteration: 29540 loss: 0.0041 lr: 0.02
2019-03-28 02:20:39 iteration: 29545 loss: 0.0060 lr: 0.02
2019-03-28 02:21:13 iteration: 29550 loss: 0.0048 lr: 0.02
2019-03-28 02:21:40 iteration: 29555 loss: 0.0055 lr: 0.02
2019-03-28 02:22:22 iteration: 29560 loss: 0.0039 lr: 0.02
2019-03-28 02:22:40 iteration: 29565 loss: 0.0051 lr: 0.02
2019-03-28 02:23:03 iteration: 29570 loss: 0.0047 lr: 0.02
2019-03-28 02:24:26 iteration: 29575 loss: 0.0037 lr: 0.02
2019-03-28 02:25:20 iteration: 29580 loss: 0.0040 lr: 0.02
2019-03-28 02:25:58 iteration: 29585 loss: 0.0053 lr: 0.02
2019-03-28 02:26:16 iteration: 29590 loss: 0.0039 lr: 0.02
2019-03-28 02:26:31 iteration: 29595 loss: 0.0041 lr: 0.02
2019-03-28 02:27:19 iteration: 29600 loss: 0.0045 lr: 0.02
2019-03-28 02:27:35 iteration: 29605 loss: 0.0052 lr: 0.02
2019-03-28 02:28:12 iteration: 29610 loss: 0.0041 lr: 0.02
2019-03-28 02:28:49 iteration: 29615 loss: 0.0035 lr: 0.02
2019-03-28 02:29:35 iteration: 29620 loss: 0.0039 lr: 0.02
2019-03-28 02:30:15 iteration: 29625 loss: 0.0035 lr: 0.02
2019-03-28 02:30:29 iteration: 29630 loss: 0.0055 lr: 0.02
2019-03-28 02:30:48 iteration: 29635 loss: 0.0037 lr: 0.02
2019-03-28 02:31:06 iteration: 29640 loss: 0.0056 lr: 0.02
2019-03-28 02:31:27 iteration: 29645 loss: 0.0056 lr: 0.02
2019-03-28 02:31:36 iteration: 29650 loss: 0.0030 lr: 0.02
2019-03-28 02:32:38 iteration: 29655 loss: 0.0042 lr: 0.02
2019-03-28 02:33:17 iteration: 29660 loss: 0.0062 lr: 0.02
2019-03-28 02:34:38 iteration: 29665 loss: 0.0056 lr: 0.02
2019-03-28 02:35:59 iteration: 29670 loss: 0.0037 lr: 0.02
2019-03-28 02:36:14 iteration: 29675 loss: 0.0041 lr: 0.02
2019-03-28 02:36:41 iteration: 29680 loss: 0.0039 lr: 0.02
2019-03-28 02:37:01 iteration: 29685 loss: 0.0045 lr: 0.02
2019-03-28 02:38:10 iteration: 29690 loss: 0.0040 lr: 0.02
2019-03-28 02:39:12 iteration: 29695 loss: 0.0047 lr: 0.02
2019-03-28 02:39:52 iteration: 29700 loss: 0.0047 lr: 0.02
2019-03-28 02:41:08 iteration: 29705 loss: 0.0045 lr: 0.02
2019-03-28 02:41:33 iteration: 29710 loss: 0.0062 lr: 0.02
2019-03-28 02:41:46 iteration: 29715 loss: 0.0065 lr: 0.02
2019-03-28 02:42:47 iteration: 29720 loss: 0.0059 lr: 0.02
2019-03-28 02:43:04 iteration: 29725 loss: 0.0061 lr: 0.02
2019-03-28 02:43:25 iteration: 29730 loss: 0.0054 lr: 0.02
2019-03-28 02:44:54 iteration: 29735 loss: 0.0038 lr: 0.02
2019-03-28 02:45:24 iteration: 29740 loss: 0.0043 lr: 0.02
2019-03-28 02:46:01 iteration: 29745 loss: 0.0036 lr: 0.02
2019-03-28 02:47:14 iteration: 29750 loss: 0.0043 lr: 0.02
2019-03-28 02:47:51 iteration: 29755 loss: 0.0050 lr: 0.02
2019-03-28 02:48:12 iteration: 29760 loss: 0.0055 lr: 0.02
2019-03-28 02:49:03 iteration: 29765 loss: 0.0037 lr: 0.02
2019-03-28 02:49:53 iteration: 29770 loss: 0.0040 lr: 0.02
2019-03-28 02:50:28 iteration: 29775 loss: 0.0038 lr: 0.02
2019-03-28 02:51:42 iteration: 29780 loss: 0.0039 lr: 0.02
2019-03-28 02:52:17 iteration: 29785 loss: 0.0050 lr: 0.02
2019-03-28 02:52:40 iteration: 29790 loss: 0.0036 lr: 0.02
2019-03-28 02:52:56 iteration: 29795 loss: 0.0036 lr: 0.02
2019-03-28 02:53:22 iteration: 29800 loss: 0.0047 lr: 0.02
2019-03-28 02:53:41 iteration: 29805 loss: 0.0056 lr: 0.02
2019-03-28 02:54:41 iteration: 29810 loss: 0.0037 lr: 0.02
2019-03-28 02:55:05 iteration: 29815 loss: 0.0046 lr: 0.02
2019-03-28 02:56:18 iteration: 29820 loss: 0.0039 lr: 0.02
2019-03-28 02:56:32 iteration: 29825 loss: 0.0047 lr: 0.02
2019-03-28 02:57:16 iteration: 29830 loss: 0.0043 lr: 0.02
2019-03-28 02:57:50 iteration: 29835 loss: 0.0043 lr: 0.02
2019-03-28 02:58:55 iteration: 29840 loss: 0.0042 lr: 0.02
2019-03-28 02:59:13 iteration: 29845 loss: 0.0034 lr: 0.02
2019-03-28 02:59:21 iteration: 29850 loss: 0.0054 lr: 0.02
2019-03-28 02:59:36 iteration: 29855 loss: 0.0045 lr: 0.02
2019-03-28 03:00:02 iteration: 29860 loss: 0.0041 lr: 0.02
2019-03-28 03:00:17 iteration: 29865 loss: 0.0054 lr: 0.02
2019-03-28 03:01:05 iteration: 29870 loss: 0.0037 lr: 0.02
2019-03-28 03:01:22 iteration: 29875 loss: 0.0061 lr: 0.02
2019-03-28 03:01:51 iteration: 29880 loss: 0.0035 lr: 0.02
2019-03-28 03:02:35 iteration: 29885 loss: 0.0041 lr: 0.02
2019-03-28 03:03:15 iteration: 29890 loss: 0.0048 lr: 0.02
2019-03-28 03:03:53 iteration: 29895 loss: 0.0042 lr: 0.02
2019-03-28 03:04:08 iteration: 29900 loss: 0.0049 lr: 0.02
2019-03-28 03:05:12 iteration: 29905 loss: 0.0035 lr: 0.02
2019-03-28 03:05:20 iteration: 29910 loss: 0.0055 lr: 0.02
2019-03-28 03:06:36 iteration: 29915 loss: 0.0072 lr: 0.02
2019-03-28 03:06:58 iteration: 29920 loss: 0.0039 lr: 0.02
2019-03-28 03:07:41 iteration: 29925 loss: 0.0061 lr: 0.02
2019-03-28 03:08:02 iteration: 29930 loss: 0.0040 lr: 0.02
2019-03-28 03:08:34 iteration: 29935 loss: 0.0083 lr: 0.02
2019-03-28 03:08:57 iteration: 29940 loss: 0.0043 lr: 0.02
2019-03-28 03:09:38 iteration: 29945 loss: 0.0051 lr: 0.02
2019-03-28 03:09:51 iteration: 29950 loss: 0.0048 lr: 0.02
2019-03-28 03:10:31 iteration: 29955 loss: 0.0036 lr: 0.02
2019-03-28 03:11:14 iteration: 29960 loss: 0.0038 lr: 0.02
2019-03-28 03:11:33 iteration: 29965 loss: 0.0057 lr: 0.02
2019-03-28 03:11:45 iteration: 29970 loss: 0.0054 lr: 0.02
2019-03-28 03:13:03 iteration: 29975 loss: 0.0034 lr: 0.02
2019-03-28 03:13:34 iteration: 29980 loss: 0.0048 lr: 0.02
2019-03-28 03:13:52 iteration: 29985 loss: 0.0045 lr: 0.02
2019-03-28 03:14:27 iteration: 29990 loss: 0.0049 lr: 0.02
2019-03-28 03:14:46 iteration: 29995 loss: 0.0038 lr: 0.02
2019-03-28 03:15:17 iteration: 30000 loss: 0.0063 lr: 0.02
2019-03-28 03:15:55 iteration: 30005 loss: 0.0045 lr: 0.02
2019-03-28 03:16:49 iteration: 30010 loss: 0.0025 lr: 0.02
2019-03-28 03:17:10 iteration: 30015 loss: 0.0073 lr: 0.02
2019-03-28 03:17:28 iteration: 30020 loss: 0.0049 lr: 0.02
2019-03-28 03:18:11 iteration: 30025 loss: 0.0043 lr: 0.02
2019-03-28 03:19:18 iteration: 30030 loss: 0.0029 lr: 0.02
2019-03-28 03:19:33 iteration: 30035 loss: 0.0066 lr: 0.02
2019-03-28 03:19:59 iteration: 30040 loss: 0.0044 lr: 0.02
2019-03-28 03:20:22 iteration: 30045 loss: 0.0041 lr: 0.02
2019-03-28 03:20:59 iteration: 30050 loss: 0.0040 lr: 0.02
2019-03-28 03:21:17 iteration: 30055 loss: 0.0046 lr: 0.02
2019-03-28 03:21:52 iteration: 30060 loss: 0.0058 lr: 0.02
2019-03-28 03:22:09 iteration: 30065 loss: 0.0054 lr: 0.02
2019-03-28 03:23:21 iteration: 30070 loss: 0.0037 lr: 0.02
2019-03-28 03:24:11 iteration: 30075 loss: 0.0032 lr: 0.02
2019-03-28 03:25:24 iteration: 30080 loss: 0.0032 lr: 0.02
2019-03-28 03:26:30 iteration: 30085 loss: 0.0042 lr: 0.02
2019-03-28 03:27:22 iteration: 30090 loss: 0.0046 lr: 0.02
2019-03-28 03:28:05 iteration: 30095 loss: 0.0051 lr: 0.02
2019-03-28 03:28:45 iteration: 30100 loss: 0.0053 lr: 0.02
2019-03-28 03:29:02 iteration: 30105 loss: 0.0042 lr: 0.02
2019-03-28 03:30:03 iteration: 30110 loss: 0.0047 lr: 0.02
2019-03-28 03:30:43 iteration: 30115 loss: 0.0044 lr: 0.02
2019-03-28 03:31:29 iteration: 30120 loss: 0.0044 lr: 0.02
2019-03-28 03:32:37 iteration: 30125 loss: 0.0047 lr: 0.02
2019-03-28 03:33:18 iteration: 30130 loss: 0.0044 lr: 0.02
2019-03-28 03:33:30 iteration: 30135 loss: 0.0044 lr: 0.02
2019-03-28 03:34:19 iteration: 30140 loss: 0.0034 lr: 0.02
2019-03-28 03:35:16 iteration: 30145 loss: 0.0042 lr: 0.02
2019-03-28 03:35:34 iteration: 30150 loss: 0.0049 lr: 0.02
2019-03-28 03:36:02 iteration: 30155 loss: 0.0040 lr: 0.02
2019-03-28 03:36:47 iteration: 30160 loss: 0.0045 lr: 0.02
2019-03-28 03:37:10 iteration: 30165 loss: 0.0060 lr: 0.02
2019-03-28 03:37:53 iteration: 30170 loss: 0.0066 lr: 0.02
2019-03-28 03:38:20 iteration: 30175 loss: 0.0036 lr: 0.02
2019-03-28 03:38:45 iteration: 30180 loss: 0.0042 lr: 0.02
2019-03-28 03:39:01 iteration: 30185 loss: 0.0061 lr: 0.02
2019-03-28 03:39:54 iteration: 30190 loss: 0.0038 lr: 0.02
2019-03-28 03:40:11 iteration: 30195 loss: 0.0056 lr: 0.02
2019-03-28 03:40:22 iteration: 30200 loss: 0.0060 lr: 0.02
2019-03-28 03:41:32 iteration: 30205 loss: 0.0031 lr: 0.02
2019-03-28 03:41:49 iteration: 30210 loss: 0.0047 lr: 0.02
2019-03-28 03:42:02 iteration: 30215 loss: 0.0069 lr: 0.02
2019-03-28 03:42:33 iteration: 30220 loss: 0.0048 lr: 0.02
2019-03-28 03:42:43 iteration: 30225 loss: 0.0051 lr: 0.02
2019-03-28 03:43:53 iteration: 30230 loss: 0.0033 lr: 0.02
2019-03-28 03:44:23 iteration: 30235 loss: 0.0045 lr: 0.02
2019-03-28 03:45:01 iteration: 30240 loss: 0.0042 lr: 0.02
2019-03-28 03:46:08 iteration: 30245 loss: 0.0064 lr: 0.02
2019-03-28 03:46:24 iteration: 30250 loss: 0.0054 lr: 0.02
2019-03-28 03:47:24 iteration: 30255 loss: 0.0046 lr: 0.02
2019-03-28 03:48:47 iteration: 30260 loss: 0.0063 lr: 0.02
2019-03-28 03:48:58 iteration: 30265 loss: 0.0047 lr: 0.02
2019-03-28 03:49:47 iteration: 30270 loss: 0.0036 lr: 0.02
2019-03-28 03:50:10 iteration: 30275 loss: 0.0045 lr: 0.02
2019-03-28 03:50:51 iteration: 30280 loss: 0.0043 lr: 0.02
2019-03-28 03:51:30 iteration: 30285 loss: 0.0028 lr: 0.02
2019-03-28 03:51:46 iteration: 30290 loss: 0.0063 lr: 0.02
2019-03-28 03:52:00 iteration: 30295 loss: 0.0061 lr: 0.02
2019-03-28 03:52:17 iteration: 30300 loss: 0.0044 lr: 0.02
2019-03-28 03:53:08 iteration: 30305 loss: 0.0041 lr: 0.02
2019-03-28 03:54:18 iteration: 30310 loss: 0.0039 lr: 0.02
2019-03-28 03:54:47 iteration: 30315 loss: 0.0041 lr: 0.02
2019-03-28 03:55:53 iteration: 30320 loss: 0.0040 lr: 0.02
2019-03-28 03:56:27 iteration: 30325 loss: 0.0039 lr: 0.02
2019-03-28 03:56:51 iteration: 30330 loss: 0.0039 lr: 0.02
2019-03-28 03:57:32 iteration: 30335 loss: 0.0031 lr: 0.02
2019-03-28 03:58:22 iteration: 30340 loss: 0.0047 lr: 0.02
2019-03-28 03:58:54 iteration: 30345 loss: 0.0034 lr: 0.02
2019-03-28 03:59:51 iteration: 30350 loss: 0.0038 lr: 0.02
2019-03-28 04:00:52 iteration: 30355 loss: 0.0050 lr: 0.02
2019-03-28 04:01:36 iteration: 30360 loss: 0.0041 lr: 0.02
2019-03-28 04:01:58 iteration: 30365 loss: 0.0041 lr: 0.02
2019-03-28 04:02:33 iteration: 30370 loss: 0.0051 lr: 0.02
2019-03-28 04:03:21 iteration: 30375 loss: 0.0037 lr: 0.02
2019-03-28 04:04:28 iteration: 30380 loss: 0.0033 lr: 0.02
2019-03-28 04:05:30 iteration: 30385 loss: 0.0041 lr: 0.02
2019-03-28 04:05:48 iteration: 30390 loss: 0.0048 lr: 0.02
2019-03-28 04:06:15 iteration: 30395 loss: 0.0039 lr: 0.02
2019-03-28 04:07:02 iteration: 30400 loss: 0.0031 lr: 0.02
2019-03-28 04:07:31 iteration: 30405 loss: 0.0036 lr: 0.02
2019-03-28 04:08:16 iteration: 30410 loss: 0.0035 lr: 0.02
2019-03-28 04:08:30 iteration: 30415 loss: 0.0042 lr: 0.02
2019-03-28 04:08:59 iteration: 30420 loss: 0.0062 lr: 0.02
2019-03-28 04:09:24 iteration: 30425 loss: 0.0041 lr: 0.02
2019-03-28 04:09:39 iteration: 30430 loss: 0.0058 lr: 0.02
2019-03-28 04:10:05 iteration: 30435 loss: 0.0050 lr: 0.02
2019-03-28 04:10:28 iteration: 30440 loss: 0.0046 lr: 0.02
2019-03-28 04:10:50 iteration: 30445 loss: 0.0072 lr: 0.02
2019-03-28 04:11:35 iteration: 30450 loss: 0.0034 lr: 0.02
2019-03-28 04:12:08 iteration: 30455 loss: 0.0048 lr: 0.02
2019-03-28 04:12:22 iteration: 30460 loss: 0.0042 lr: 0.02
2019-03-28 04:13:16 iteration: 30465 loss: 0.0029 lr: 0.02
2019-03-28 04:14:01 iteration: 30470 loss: 0.0052 lr: 0.02
2019-03-28 04:14:26 iteration: 30475 loss: 0.0043 lr: 0.02
2019-03-28 04:15:16 iteration: 30480 loss: 0.0031 lr: 0.02
2019-03-28 04:15:44 iteration: 30485 loss: 0.0116 lr: 0.02
2019-03-28 04:16:21 iteration: 30490 loss: 0.0042 lr: 0.02
2019-03-28 04:16:43 iteration: 30495 loss: 0.0033 lr: 0.02
2019-03-28 04:17:13 iteration: 30500 loss: 0.0046 lr: 0.02
2019-03-28 04:17:43 iteration: 30505 loss: 0.0048 lr: 0.02
2019-03-28 04:18:43 iteration: 30510 loss: 0.0037 lr: 0.02
2019-03-28 04:18:59 iteration: 30515 loss: 0.0047 lr: 0.02
2019-03-28 04:19:49 iteration: 30520 loss: 0.0038 lr: 0.02
2019-03-28 04:20:59 iteration: 30525 loss: 0.0040 lr: 0.02
2019-03-28 04:21:08 iteration: 30530 loss: 0.0057 lr: 0.02
2019-03-28 04:21:55 iteration: 30535 loss: 0.0041 lr: 0.02
2019-03-28 04:23:13 iteration: 30540 loss: 0.0045 lr: 0.02
2019-03-28 04:23:31 iteration: 30545 loss: 0.0044 lr: 0.02
2019-03-28 04:23:55 iteration: 30550 loss: 0.0038 lr: 0.02
2019-03-28 04:24:44 iteration: 30555 loss: 0.0045 lr: 0.02
2019-03-28 04:24:56 iteration: 30560 loss: 0.0062 lr: 0.02
2019-03-28 04:25:43 iteration: 30565 loss: 0.0046 lr: 0.02
2019-03-28 04:25:57 iteration: 30570 loss: 0.0069 lr: 0.02
2019-03-28 04:26:37 iteration: 30575 loss: 0.0046 lr: 0.02
2019-03-28 04:26:56 iteration: 30580 loss: 0.0053 lr: 0.02
2019-03-28 04:28:52 iteration: 30585 loss: 0.0031 lr: 0.02
2019-03-28 04:29:18 iteration: 30590 loss: 0.0039 lr: 0.02
2019-03-28 04:29:38 iteration: 30595 loss: 0.0051 lr: 0.02
2019-03-28 04:30:28 iteration: 30600 loss: 0.0051 lr: 0.02
2019-03-28 04:30:45 iteration: 30605 loss: 0.0037 lr: 0.02
2019-03-28 04:31:20 iteration: 30610 loss: 0.0042 lr: 0.02
2019-03-28 04:31:48 iteration: 30615 loss: 0.0042 lr: 0.02
2019-03-28 04:32:33 iteration: 30620 loss: 0.0030 lr: 0.02
2019-03-28 04:32:52 iteration: 30625 loss: 0.0065 lr: 0.02
2019-03-28 04:33:15 iteration: 30630 loss: 0.0037 lr: 0.02
2019-03-28 04:33:34 iteration: 30635 loss: 0.0056 lr: 0.02
2019-03-28 04:34:17 iteration: 30640 loss: 0.0042 lr: 0.02
2019-03-28 04:35:01 iteration: 30645 loss: 0.0044 lr: 0.02
2019-03-28 04:35:23 iteration: 30650 loss: 0.0051 lr: 0.02
2019-03-28 04:35:57 iteration: 30655 loss: 0.0037 lr: 0.02
2019-03-28 04:36:25 iteration: 30660 loss: 0.0050 lr: 0.02
2019-03-28 04:36:59 iteration: 30665 loss: 0.0052 lr: 0.02
2019-03-28 04:37:26 iteration: 30670 loss: 0.0035 lr: 0.02
2019-03-28 04:38:16 iteration: 30675 loss: 0.0031 lr: 0.02
2019-03-28 04:38:29 iteration: 30680 loss: 0.0046 lr: 0.02
2019-03-28 04:39:34 iteration: 30685 loss: 0.0053 lr: 0.02
2019-03-28 04:40:54 iteration: 30690 loss: 0.0059 lr: 0.02
2019-03-28 04:41:14 iteration: 30695 loss: 0.0034 lr: 0.02
2019-03-28 04:41:34 iteration: 30700 loss: 0.0059 lr: 0.02
2019-03-28 04:42:19 iteration: 30705 loss: 0.0037 lr: 0.02
2019-03-28 04:43:36 iteration: 30710 loss: 0.0035 lr: 0.02
2019-03-28 04:43:52 iteration: 30715 loss: 0.0079 lr: 0.02
2019-03-28 04:44:01 iteration: 30720 loss: 0.0050 lr: 0.02
2019-03-28 04:44:43 iteration: 30725 loss: 0.0041 lr: 0.02
2019-03-28 04:45:03 iteration: 30730 loss: 0.0082 lr: 0.02
2019-03-28 04:45:48 iteration: 30735 loss: 0.0031 lr: 0.02
2019-03-28 04:45:58 iteration: 30740 loss: 0.0054 lr: 0.02
2019-03-28 04:46:34 iteration: 30745 loss: 0.0034 lr: 0.02
2019-03-28 04:47:32 iteration: 30750 loss: 0.0035 lr: 0.02
2019-03-28 04:48:22 iteration: 30755 loss: 0.0035 lr: 0.02
2019-03-28 04:48:34 iteration: 30760 loss: 0.0050 lr: 0.02
2019-03-28 04:48:47 iteration: 30765 loss: 0.0044 lr: 0.02
2019-03-28 04:49:00 iteration: 30770 loss: 0.0060 lr: 0.02
2019-03-28 04:50:22 iteration: 30775 loss: 0.0031 lr: 0.02
2019-03-28 04:51:12 iteration: 30780 loss: 0.0047 lr: 0.02
2019-03-28 04:52:05 iteration: 30785 loss: 0.0036 lr: 0.02
2019-03-28 04:52:17 iteration: 30790 loss: 0.0049 lr: 0.02
2019-03-28 04:52:30 iteration: 30795 loss: 0.0053 lr: 0.02
2019-03-28 04:52:49 iteration: 30800 loss: 0.0047 lr: 0.02
2019-03-28 04:53:21 iteration: 30805 loss: 0.0045 lr: 0.02
2019-03-28 04:53:47 iteration: 30810 loss: 0.0056 lr: 0.02
2019-03-28 04:54:07 iteration: 30815 loss: 0.0050 lr: 0.02
2019-03-28 04:54:38 iteration: 30820 loss: 0.0027 lr: 0.02
2019-03-28 04:55:19 iteration: 30825 loss: 0.0063 lr: 0.02
2019-03-28 04:55:37 iteration: 30830 loss: 0.0049 lr: 0.02
2019-03-28 04:55:49 iteration: 30835 loss: 0.0058 lr: 0.02
2019-03-28 04:56:36 iteration: 30840 loss: 0.0047 lr: 0.02
2019-03-28 04:56:47 iteration: 30845 loss: 0.0063 lr: 0.02
2019-03-28 04:57:41 iteration: 30850 loss: 0.0034 lr: 0.02
2019-03-28 04:58:15 iteration: 30855 loss: 0.0037 lr: 0.02
2019-03-28 04:59:37 iteration: 30860 loss: 0.0037 lr: 0.02
2019-03-28 05:00:26 iteration: 30865 loss: 0.0045 lr: 0.02
2019-03-28 05:00:38 iteration: 30870 loss: 0.0040 lr: 0.02
2019-03-28 05:01:20 iteration: 30875 loss: 0.0034 lr: 0.02
2019-03-28 05:02:12 iteration: 30880 loss: 0.0038 lr: 0.02
2019-03-28 05:02:45 iteration: 30885 loss: 0.0035 lr: 0.02
2019-03-28 05:03:20 iteration: 30890 loss: 0.0024 lr: 0.02
2019-03-28 05:03:56 iteration: 30895 loss: 0.0035 lr: 0.02
2019-03-28 05:05:02 iteration: 30900 loss: 0.0039 lr: 0.02
2019-03-28 05:05:40 iteration: 30905 loss: 0.0056 lr: 0.02
2019-03-28 05:06:02 iteration: 30910 loss: 0.0046 lr: 0.02
2019-03-28 05:06:22 iteration: 30915 loss: 0.0063 lr: 0.02
2019-03-28 05:07:11 iteration: 30920 loss: 0.0055 lr: 0.02
2019-03-28 05:07:58 iteration: 30925 loss: 0.0034 lr: 0.02
2019-03-28 05:08:58 iteration: 30930 loss: 0.0028 lr: 0.02
2019-03-28 05:10:08 iteration: 30935 loss: 0.0029 lr: 0.02
2019-03-28 05:10:38 iteration: 30940 loss: 0.0037 lr: 0.02
2019-03-28 05:10:51 iteration: 30945 loss: 0.0075 lr: 0.02
2019-03-28 05:11:10 iteration: 30950 loss: 0.0037 lr: 0.02
2019-03-28 05:11:26 iteration: 30955 loss: 0.0054 lr: 0.02
2019-03-28 05:12:02 iteration: 30960 loss: 0.0048 lr: 0.02
2019-03-28 05:12:53 iteration: 30965 loss: 0.0095 lr: 0.02
2019-03-28 05:13:31 iteration: 30970 loss: 0.0050 lr: 0.02
2019-03-28 05:13:59 iteration: 30975 loss: 0.0044 lr: 0.02
2019-03-28 05:14:23 iteration: 30980 loss: 0.0049 lr: 0.02
2019-03-28 05:14:48 iteration: 30985 loss: 0.0068 lr: 0.02
2019-03-28 05:15:19 iteration: 30990 loss: 0.0036 lr: 0.02
2019-03-28 05:16:19 iteration: 30995 loss: 0.0053 lr: 0.02
2019-03-28 05:17:01 iteration: 31000 loss: 0.0039 lr: 0.02
2019-03-28 05:17:57 iteration: 31005 loss: 0.0027 lr: 0.02
2019-03-28 05:18:43 iteration: 31010 loss: 0.0043 lr: 0.02
2019-03-28 05:19:00 iteration: 31015 loss: 0.0047 lr: 0.02
2019-03-28 05:19:59 iteration: 31020 loss: 0.0039 lr: 0.02
2019-03-28 05:21:03 iteration: 31025 loss: 0.0067 lr: 0.02
2019-03-28 05:21:48 iteration: 31030 loss: 0.0034 lr: 0.02
2019-03-28 05:22:08 iteration: 31035 loss: 0.0041 lr: 0.02
2019-03-28 05:22:32 iteration: 31040 loss: 0.0052 lr: 0.02
2019-03-28 05:23:36 iteration: 31045 loss: 0.0033 lr: 0.02
2019-03-28 05:24:05 iteration: 31050 loss: 0.0045 lr: 0.02
2019-03-28 05:24:36 iteration: 31055 loss: 0.0036 lr: 0.02
2019-03-28 05:24:54 iteration: 31060 loss: 0.0051 lr: 0.02
2019-03-28 05:25:09 iteration: 31065 loss: 0.0047 lr: 0.02
2019-03-28 05:25:27 iteration: 31070 loss: 0.0039 lr: 0.02
2019-03-28 05:26:41 iteration: 31075 loss: 0.0036 lr: 0.02
2019-03-28 05:27:00 iteration: 31080 loss: 0.0060 lr: 0.02
2019-03-28 05:28:00 iteration: 31085 loss: 0.0047 lr: 0.02
2019-03-28 05:28:39 iteration: 31090 loss: 0.0035 lr: 0.02
2019-03-28 05:28:50 iteration: 31095 loss: 0.0053 lr: 0.02
2019-03-28 05:29:14 iteration: 31100 loss: 0.0049 lr: 0.02
2019-03-28 05:29:40 iteration: 31105 loss: 0.0054 lr: 0.02
2019-03-28 05:30:09 iteration: 31110 loss: 0.0052 lr: 0.02
2019-03-28 05:30:56 iteration: 31115 loss: 0.0036 lr: 0.02
2019-03-28 05:31:38 iteration: 31120 loss: 0.0050 lr: 0.02
2019-03-28 05:32:01 iteration: 31125 loss: 0.0044 lr: 0.02
2019-03-28 05:32:44 iteration: 31130 loss: 0.0052 lr: 0.02
2019-03-28 05:33:35 iteration: 31135 loss: 0.0061 lr: 0.02
2019-03-28 05:34:17 iteration: 31140 loss: 0.0035 lr: 0.02
2019-03-28 05:35:36 iteration: 31145 loss: 0.0043 lr: 0.02
2019-03-28 05:36:10 iteration: 31150 loss: 0.0031 lr: 0.02
2019-03-28 05:36:25 iteration: 31155 loss: 0.0046 lr: 0.02
2019-03-28 05:37:18 iteration: 31160 loss: 0.0043 lr: 0.02
2019-03-28 05:37:34 iteration: 31165 loss: 0.0045 lr: 0.02
2019-03-28 05:37:45 iteration: 31170 loss: 0.0064 lr: 0.02
2019-03-28 05:38:28 iteration: 31175 loss: 0.0043 lr: 0.02
2019-03-28 05:38:48 iteration: 31180 loss: 0.0059 lr: 0.02
2019-03-28 05:39:02 iteration: 31185 loss: 0.0048 lr: 0.02
2019-03-28 05:39:20 iteration: 31190 loss: 0.0046 lr: 0.02
2019-03-28 05:39:34 iteration: 31195 loss: 0.0055 lr: 0.02
2019-03-28 05:41:24 iteration: 31200 loss: 0.0034 lr: 0.02
2019-03-28 05:42:34 iteration: 31205 loss: 0.0042 lr: 0.02
2019-03-28 05:42:47 iteration: 31210 loss: 0.0042 lr: 0.02
2019-03-28 05:43:38 iteration: 31215 loss: 0.0041 lr: 0.02
2019-03-28 05:45:03 iteration: 31220 loss: 0.0031 lr: 0.02
2019-03-28 05:45:32 iteration: 31225 loss: 0.0041 lr: 0.02
2019-03-28 05:46:12 iteration: 31230 loss: 0.0039 lr: 0.02
2019-03-28 05:46:27 iteration: 31235 loss: 0.0060 lr: 0.02
2019-03-28 05:47:12 iteration: 31240 loss: 0.0048 lr: 0.02
2019-03-28 05:47:47 iteration: 31245 loss: 0.0052 lr: 0.02
2019-03-28 05:48:43 iteration: 31250 loss: 0.0036 lr: 0.02
2019-03-28 05:49:28 iteration: 31255 loss: 0.0047 lr: 0.02
2019-03-28 05:50:10 iteration: 31260 loss: 0.0031 lr: 0.02
2019-03-28 05:50:26 iteration: 31265 loss: 0.0078 lr: 0.02
2019-03-28 05:50:40 iteration: 31270 loss: 0.0060 lr: 0.02
2019-03-28 05:52:00 iteration: 31275 loss: 0.0026 lr: 0.02
2019-03-28 05:52:24 iteration: 31280 loss: 0.0058 lr: 0.02
2019-03-28 05:53:35 iteration: 31285 loss: 0.0044 lr: 0.02
2019-03-28 05:54:04 iteration: 31290 loss: 0.0033 lr: 0.02
2019-03-28 05:54:48 iteration: 31295 loss: 0.0038 lr: 0.02
2019-03-28 05:56:28 iteration: 31300 loss: 0.0040 lr: 0.02
2019-03-28 05:57:20 iteration: 31305 loss: 0.0060 lr: 0.02
2019-03-28 05:57:41 iteration: 31310 loss: 0.0047 lr: 0.02
2019-03-28 05:58:27 iteration: 31315 loss: 0.0064 lr: 0.02
2019-03-28 05:59:01 iteration: 31320 loss: 0.0054 lr: 0.02
2019-03-28 05:59:15 iteration: 31325 loss: 0.0063 lr: 0.02
2019-03-28 06:00:10 iteration: 31330 loss: 0.0040 lr: 0.02
2019-03-28 06:00:53 iteration: 31335 loss: 0.0044 lr: 0.02
2019-03-28 06:01:18 iteration: 31340 loss: 0.0028 lr: 0.02
2019-03-28 06:01:46 iteration: 31345 loss: 0.0034 lr: 0.02
2019-03-28 06:02:33 iteration: 31350 loss: 0.0045 lr: 0.02
2019-03-28 06:02:46 iteration: 31355 loss: 0.0063 lr: 0.02
2019-03-28 06:03:52 iteration: 31360 loss: 0.0051 lr: 0.02
2019-03-28 06:04:09 iteration: 31365 loss: 0.0045 lr: 0.02
2019-03-28 06:05:28 iteration: 31370 loss: 0.0037 lr: 0.02
2019-03-28 06:06:03 iteration: 31375 loss: 0.0081 lr: 0.02
2019-03-28 06:06:41 iteration: 31380 loss: 0.0061 lr: 0.02
2019-03-28 06:07:34 iteration: 31385 loss: 0.0037 lr: 0.02
2019-03-28 06:08:49 iteration: 31390 loss: 0.0038 lr: 0.02
2019-03-28 06:09:41 iteration: 31395 loss: 0.0029 lr: 0.02
2019-03-28 06:10:34 iteration: 31400 loss: 0.0048 lr: 0.02
2019-03-28 06:10:53 iteration: 31405 loss: 0.0039 lr: 0.02
2019-03-28 06:11:43 iteration: 31410 loss: 0.0037 lr: 0.02
2019-03-28 06:12:16 iteration: 31415 loss: 0.0037 lr: 0.02
2019-03-28 06:13:07 iteration: 31420 loss: 0.0038 lr: 0.02
2019-03-28 06:13:45 iteration: 31425 loss: 0.0037 lr: 0.02
2019-03-28 06:14:01 iteration: 31430 loss: 0.0049 lr: 0.02
2019-03-28 06:14:18 iteration: 31435 loss: 0.0050 lr: 0.02
2019-03-28 06:14:39 iteration: 31440 loss: 0.0053 lr: 0.02
2019-03-28 06:15:04 iteration: 31445 loss: 0.0034 lr: 0.02
2019-03-28 06:15:24 iteration: 31450 loss: 0.0037 lr: 0.02
2019-03-28 06:15:40 iteration: 31455 loss: 0.0042 lr: 0.02
2019-03-28 06:16:18 iteration: 31460 loss: 0.0041 lr: 0.02
2019-03-28 06:16:33 iteration: 31465 loss: 0.0060 lr: 0.02
2019-03-28 06:16:49 iteration: 31470 loss: 0.0046 lr: 0.02
2019-03-28 06:17:08 iteration: 31475 loss: 0.0056 lr: 0.02
2019-03-28 06:17:55 iteration: 31480 loss: 0.0028 lr: 0.02
2019-03-28 06:18:06 iteration: 31485 loss: 0.0068 lr: 0.02
2019-03-28 06:18:48 iteration: 31490 loss: 0.0043 lr: 0.02
2019-03-28 06:19:25 iteration: 31495 loss: 0.0062 lr: 0.02
2019-03-28 06:20:12 iteration: 31500 loss: 0.0043 lr: 0.02
2019-03-28 06:20:22 iteration: 31505 loss: 0.0048 lr: 0.02
2019-03-28 06:21:07 iteration: 31510 loss: 0.0053 lr: 0.02
2019-03-28 06:22:28 iteration: 31515 loss: 0.0052 lr: 0.02
2019-03-28 06:23:12 iteration: 31520 loss: 0.0038 lr: 0.02
2019-03-28 06:23:59 iteration: 31525 loss: 0.0036 lr: 0.02
2019-03-28 06:24:50 iteration: 31530 loss: 0.0049 lr: 0.02
2019-03-28 06:25:06 iteration: 31535 loss: 0.0057 lr: 0.02
2019-03-28 06:25:23 iteration: 31540 loss: 0.0042 lr: 0.02
2019-03-28 06:26:08 iteration: 31545 loss: 0.0042 lr: 0.02
2019-03-28 06:26:31 iteration: 31550 loss: 0.0054 lr: 0.02
2019-03-28 06:26:56 iteration: 31555 loss: 0.0041 lr: 0.02
2019-03-28 06:27:49 iteration: 31560 loss: 0.0046 lr: 0.02
2019-03-28 06:28:11 iteration: 31565 loss: 0.0039 lr: 0.02
2019-03-28 06:28:29 iteration: 31570 loss: 0.0043 lr: 0.02
2019-03-28 06:29:00 iteration: 31575 loss: 0.0034 lr: 0.02
2019-03-28 06:30:01 iteration: 31580 loss: 0.0034 lr: 0.02
2019-03-28 06:30:36 iteration: 31585 loss: 0.0059 lr: 0.02
2019-03-28 06:30:50 iteration: 31590 loss: 0.0052 lr: 0.02
2019-03-28 06:31:40 iteration: 31595 loss: 0.0034 lr: 0.02
2019-03-28 06:32:27 iteration: 31600 loss: 0.0033 lr: 0.02
2019-03-28 06:33:35 iteration: 31605 loss: 0.0047 lr: 0.02
2019-03-28 06:33:50 iteration: 31610 loss: 0.0040 lr: 0.02
2019-03-28 06:34:10 iteration: 31615 loss: 0.0040 lr: 0.02
2019-03-28 06:35:18 iteration: 31620 loss: 0.0033 lr: 0.02
2019-03-28 06:35:59 iteration: 31625 loss: 0.0037 lr: 0.02
2019-03-28 06:37:01 iteration: 31630 loss: 0.0053 lr: 0.02
2019-03-28 06:37:29 iteration: 31635 loss: 0.0040 lr: 0.02
2019-03-28 06:38:23 iteration: 31640 loss: 0.0042 lr: 0.02
2019-03-28 06:39:07 iteration: 31645 loss: 0.0043 lr: 0.02
2019-03-28 06:39:57 iteration: 31650 loss: 0.0044 lr: 0.02
2019-03-28 06:40:24 iteration: 31655 loss: 0.0034 lr: 0.02
2019-03-28 06:41:17 iteration: 31660 loss: 0.0054 lr: 0.02
2019-03-28 06:41:31 iteration: 31665 loss: 0.0056 lr: 0.02
2019-03-28 06:43:36 iteration: 31670 loss: 0.0027 lr: 0.02
2019-03-28 06:43:54 iteration: 31675 loss: 0.0053 lr: 0.02
2019-03-28 06:44:11 iteration: 31680 loss: 0.0052 lr: 0.02
2019-03-28 06:44:53 iteration: 31685 loss: 0.0050 lr: 0.02
2019-03-28 06:45:20 iteration: 31690 loss: 0.0040 lr: 0.02
2019-03-28 06:46:07 iteration: 31695 loss: 0.0066 lr: 0.02
2019-03-28 06:47:07 iteration: 31700 loss: 0.0041 lr: 0.02
2019-03-28 06:47:41 iteration: 31705 loss: 0.0039 lr: 0.02
2019-03-28 06:48:29 iteration: 31710 loss: 0.0041 lr: 0.02
2019-03-28 06:49:47 iteration: 31715 loss: 0.0041 lr: 0.02
2019-03-28 06:50:05 iteration: 31720 loss: 0.0045 lr: 0.02
2019-03-28 06:50:28 iteration: 31725 loss: 0.0051 lr: 0.02
2019-03-28 06:51:12 iteration: 31730 loss: 0.0035 lr: 0.02
2019-03-28 06:51:50 iteration: 31735 loss: 0.0055 lr: 0.02
2019-03-28 06:52:28 iteration: 31740 loss: 0.0030 lr: 0.02
2019-03-28 06:52:47 iteration: 31745 loss: 0.0044 lr: 0.02
2019-03-28 06:53:31 iteration: 31750 loss: 0.0040 lr: 0.02
2019-03-28 06:53:44 iteration: 31755 loss: 0.0048 lr: 0.02
2019-03-28 06:54:20 iteration: 31760 loss: 0.0041 lr: 0.02
2019-03-28 06:54:49 iteration: 31765 loss: 0.0040 lr: 0.02
2019-03-28 06:55:16 iteration: 31770 loss: 0.0030 lr: 0.02
2019-03-28 06:55:29 iteration: 31775 loss: 0.0061 lr: 0.02
2019-03-28 06:55:49 iteration: 31780 loss: 0.0055 lr: 0.02
2019-03-28 06:56:18 iteration: 31785 loss: 0.0034 lr: 0.02
2019-03-28 06:56:43 iteration: 31790 loss: 0.0046 lr: 0.02
2019-03-28 06:57:01 iteration: 31795 loss: 0.0047 lr: 0.02
2019-03-28 06:57:51 iteration: 31800 loss: 0.0031 lr: 0.02
2019-03-28 06:58:08 iteration: 31805 loss: 0.0056 lr: 0.02
2019-03-28 06:59:03 iteration: 31810 loss: 0.0035 lr: 0.02
2019-03-28 06:59:16 iteration: 31815 loss: 0.0049 lr: 0.02
2019-03-28 07:00:07 iteration: 31820 loss: 0.0048 lr: 0.02
2019-03-28 07:00:43 iteration: 31825 loss: 0.0038 lr: 0.02
2019-03-28 07:01:02 iteration: 31830 loss: 0.0052 lr: 0.02
2019-03-28 07:01:35 iteration: 31835 loss: 0.0047 lr: 0.02
2019-03-28 07:01:57 iteration: 31840 loss: 0.0052 lr: 0.02
2019-03-28 07:02:38 iteration: 31845 loss: 0.0045 lr: 0.02
2019-03-28 07:04:07 iteration: 31850 loss: 0.0043 lr: 0.02
2019-03-28 07:04:20 iteration: 31855 loss: 0.0049 lr: 0.02
2019-03-28 07:04:50 iteration: 31860 loss: 0.0052 lr: 0.02
2019-03-28 07:05:42 iteration: 31865 loss: 0.0060 lr: 0.02
2019-03-28 07:05:56 iteration: 31870 loss: 0.0054 lr: 0.02
2019-03-28 07:06:47 iteration: 31875 loss: 0.0035 lr: 0.02
2019-03-28 07:07:00 iteration: 31880 loss: 0.0056 lr: 0.02
2019-03-28 07:07:29 iteration: 31885 loss: 0.0035 lr: 0.02
2019-03-28 07:07:44 iteration: 31890 loss: 0.0050 lr: 0.02
2019-03-28 07:08:41 iteration: 31895 loss: 0.0037 lr: 0.02
2019-03-28 07:08:58 iteration: 31900 loss: 0.0081 lr: 0.02
2019-03-28 07:09:09 iteration: 31905 loss: 0.0050 lr: 0.02
2019-03-28 07:09:32 iteration: 31910 loss: 0.0049 lr: 0.02
2019-03-28 07:10:06 iteration: 31915 loss: 0.0030 lr: 0.02
2019-03-28 07:10:30 iteration: 31920 loss: 0.0039 lr: 0.02
2019-03-28 07:11:26 iteration: 31925 loss: 0.0029 lr: 0.02
2019-03-28 07:12:39 iteration: 31930 loss: 0.0032 lr: 0.02
2019-03-28 07:12:55 iteration: 31935 loss: 0.0057 lr: 0.02
2019-03-28 07:13:40 iteration: 31940 loss: 0.0041 lr: 0.02
2019-03-28 07:14:40 iteration: 31945 loss: 0.0038 lr: 0.02
2019-03-28 07:14:56 iteration: 31950 loss: 0.0047 lr: 0.02
2019-03-28 07:15:40 iteration: 31955 loss: 0.0033 lr: 0.02
2019-03-28 07:15:54 iteration: 31960 loss: 0.0046 lr: 0.02
2019-03-28 07:16:18 iteration: 31965 loss: 0.0056 lr: 0.02
2019-03-28 07:16:45 iteration: 31970 loss: 0.0045 lr: 0.02
2019-03-28 07:17:00 iteration: 31975 loss: 0.0045 lr: 0.02
2019-03-28 07:18:18 iteration: 31980 loss: 0.0034 lr: 0.02
2019-03-28 07:18:34 iteration: 31985 loss: 0.0061 lr: 0.02
2019-03-28 07:18:54 iteration: 31990 loss: 0.0048 lr: 0.02
2019-03-28 07:20:19 iteration: 31995 loss: 0.0031 lr: 0.02
2019-03-28 07:21:04 iteration: 32000 loss: 0.0043 lr: 0.02
2019-03-28 07:21:53 iteration: 32005 loss: 0.0045 lr: 0.02
2019-03-28 07:22:12 iteration: 32010 loss: 0.0042 lr: 0.02
2019-03-28 07:22:40 iteration: 32015 loss: 0.0040 lr: 0.02
2019-03-28 07:23:24 iteration: 32020 loss: 0.0045 lr: 0.02
2019-03-28 07:23:46 iteration: 32025 loss: 0.0052 lr: 0.02
2019-03-28 07:24:18 iteration: 32030 loss: 0.0055 lr: 0.02
2019-03-28 07:24:40 iteration: 32035 loss: 0.0052 lr: 0.02
2019-03-28 07:26:02 iteration: 32040 loss: 0.0040 lr: 0.02
2019-03-28 07:26:39 iteration: 32045 loss: 0.0040 lr: 0.02
2019-03-28 07:27:25 iteration: 32050 loss: 0.0042 lr: 0.02
2019-03-28 07:28:01 iteration: 32055 loss: 0.0042 lr: 0.02
2019-03-28 07:28:22 iteration: 32060 loss: 0.0046 lr: 0.02
2019-03-28 07:29:35 iteration: 32065 loss: 0.0033 lr: 0.02
2019-03-28 07:29:53 iteration: 32070 loss: 0.0045 lr: 0.02
2019-03-28 07:30:10 iteration: 32075 loss: 0.0067 lr: 0.02
2019-03-28 07:30:38 iteration: 32080 loss: 0.0033 lr: 0.02
2019-03-28 07:31:09 iteration: 32085 loss: 0.0047 lr: 0.02
2019-03-28 07:31:34 iteration: 32090 loss: 0.0040 lr: 0.02
2019-03-28 07:32:21 iteration: 32095 loss: 0.0031 lr: 0.02
2019-03-28 07:32:30 iteration: 32100 loss: 0.0055 lr: 0.02
2019-03-28 07:33:15 iteration: 32105 loss: 0.0066 lr: 0.02
2019-03-28 07:34:24 iteration: 32110 loss: 0.0037 lr: 0.02
2019-03-28 07:34:47 iteration: 32115 loss: 0.0045 lr: 0.02
2019-03-28 07:35:12 iteration: 32120 loss: 0.0040 lr: 0.02
2019-03-28 07:35:28 iteration: 32125 loss: 0.0038 lr: 0.02
2019-03-28 07:35:56 iteration: 32130 loss: 0.0042 lr: 0.02
2019-03-28 07:36:26 iteration: 32135 loss: 0.0032 lr: 0.02
2019-03-28 07:36:53 iteration: 32140 loss: 0.0044 lr: 0.02
2019-03-28 07:37:39 iteration: 32145 loss: 0.0049 lr: 0.02
2019-03-28 07:38:12 iteration: 32150 loss: 0.0034 lr: 0.02
2019-03-28 07:38:44 iteration: 32155 loss: 0.0038 lr: 0.02
2019-03-28 07:39:28 iteration: 32160 loss: 0.0037 lr: 0.02
2019-03-28 07:39:57 iteration: 32165 loss: 0.0046 lr: 0.02
2019-03-28 07:40:09 iteration: 32170 loss: 0.0093 lr: 0.02
2019-03-28 07:40:56 iteration: 32175 loss: 0.0041 lr: 0.02
2019-03-28 07:41:40 iteration: 32180 loss: 0.0038 lr: 0.02
2019-03-28 07:42:14 iteration: 32185 loss: 0.0033 lr: 0.02
2019-03-28 07:42:37 iteration: 32190 loss: 0.0043 lr: 0.02
2019-03-28 07:43:28 iteration: 32195 loss: 0.0058 lr: 0.02
2019-03-28 07:44:19 iteration: 32200 loss: 0.0035 lr: 0.02
2019-03-28 07:44:37 iteration: 32205 loss: 0.0051 lr: 0.02
2019-03-28 07:45:09 iteration: 32210 loss: 0.0041 lr: 0.02
2019-03-28 07:46:14 iteration: 32215 loss: 0.0035 lr: 0.02
2019-03-28 07:46:59 iteration: 32220 loss: 0.0047 lr: 0.02
2019-03-28 07:48:11 iteration: 32225 loss: 0.0033 lr: 0.02
2019-03-28 07:48:38 iteration: 32230 loss: 0.0072 lr: 0.02
2019-03-28 07:49:06 iteration: 32235 loss: 0.0054 lr: 0.02
2019-03-28 07:49:54 iteration: 32240 loss: 0.0047 lr: 0.02
2019-03-28 07:50:10 iteration: 32245 loss: 0.0043 lr: 0.02
2019-03-28 07:50:33 iteration: 32250 loss: 0.0037 lr: 0.02
2019-03-28 07:51:15 iteration: 32255 loss: 0.0042 lr: 0.02
2019-03-28 07:51:40 iteration: 32260 loss: 0.0044 lr: 0.02
2019-03-28 07:52:52 iteration: 32265 loss: 0.0040 lr: 0.02
2019-03-28 07:53:32 iteration: 32270 loss: 0.0030 lr: 0.02
2019-03-28 07:54:00 iteration: 32275 loss: 0.0045 lr: 0.02
2019-03-28 07:54:19 iteration: 32280 loss: 0.0047 lr: 0.02
2019-03-28 07:54:38 iteration: 32285 loss: 0.0048 lr: 0.02
2019-03-28 07:55:22 iteration: 32290 loss: 0.0038 lr: 0.02
2019-03-28 07:56:07 iteration: 32295 loss: 0.0042 lr: 0.02
2019-03-28 07:56:36 iteration: 32300 loss: 0.0043 lr: 0.02
2019-03-28 07:57:09 iteration: 32305 loss: 0.0049 lr: 0.02
2019-03-28 07:57:32 iteration: 32310 loss: 0.0069 lr: 0.02
2019-03-28 07:58:06 iteration: 32315 loss: 0.0030 lr: 0.02
2019-03-28 07:58:26 iteration: 32320 loss: 0.0042 lr: 0.02
2019-03-28 07:59:24 iteration: 32325 loss: 0.0036 lr: 0.02
2019-03-28 07:59:43 iteration: 32330 loss: 0.0079 lr: 0.02
2019-03-28 08:00:48 iteration: 32335 loss: 0.0059 lr: 0.02
2019-03-28 08:01:15 iteration: 32340 loss: 0.0046 lr: 0.02
2019-03-28 08:01:40 iteration: 32345 loss: 0.0043 lr: 0.02
2019-03-28 08:02:42 iteration: 32350 loss: 0.0048 lr: 0.02
2019-03-28 08:03:02 iteration: 32355 loss: 0.0043 lr: 0.02
2019-03-28 08:03:46 iteration: 32360 loss: 0.0049 lr: 0.02
2019-03-28 08:04:34 iteration: 32365 loss: 0.0043 lr: 0.02
2019-03-28 08:04:57 iteration: 32370 loss: 0.0043 lr: 0.02
2019-03-28 08:05:17 iteration: 32375 loss: 0.0062 lr: 0.02
2019-03-28 08:06:06 iteration: 32380 loss: 0.0040 lr: 0.02
2019-03-28 08:06:48 iteration: 32385 loss: 0.0059 lr: 0.02
2019-03-28 08:07:03 iteration: 32390 loss: 0.0049 lr: 0.02
2019-03-28 08:07:46 iteration: 32395 loss: 0.0042 lr: 0.02
2019-03-28 08:08:39 iteration: 32400 loss: 0.0050 lr: 0.02
2019-03-28 08:09:52 iteration: 32405 loss: 0.0048 lr: 0.02
2019-03-28 08:10:33 iteration: 32410 loss: 0.0034 lr: 0.02
2019-03-28 08:11:14 iteration: 32415 loss: 0.0041 lr: 0.02
2019-03-28 08:11:48 iteration: 32420 loss: 0.0050 lr: 0.02
2019-03-28 08:12:35 iteration: 32425 loss: 0.0040 lr: 0.02
2019-03-28 08:13:33 iteration: 32430 loss: 0.0029 lr: 0.02
2019-03-28 08:14:26 iteration: 32435 loss: 0.0037 lr: 0.02
2019-03-28 08:15:10 iteration: 32440 loss: 0.0038 lr: 0.02
2019-03-28 08:15:27 iteration: 32445 loss: 0.0051 lr: 0.02
2019-03-28 08:17:34 iteration: 32450 loss: 0.0033 lr: 0.02
2019-03-28 08:17:49 iteration: 32455 loss: 0.0034 lr: 0.02
2019-03-28 08:18:37 iteration: 32460 loss: 0.0031 lr: 0.02
2019-03-28 08:18:57 iteration: 32465 loss: 0.0037 lr: 0.02
2019-03-28 08:19:11 iteration: 32470 loss: 0.0046 lr: 0.02
2019-03-28 08:19:41 iteration: 32475 loss: 0.0049 lr: 0.02
2019-03-28 08:20:03 iteration: 32480 loss: 0.0057 lr: 0.02
2019-03-28 08:20:18 iteration: 32485 loss: 0.0044 lr: 0.02
2019-03-28 08:21:13 iteration: 32490 loss: 0.0036 lr: 0.02
2019-03-28 08:21:33 iteration: 32495 loss: 0.0047 lr: 0.02
2019-03-28 08:21:59 iteration: 32500 loss: 0.0034 lr: 0.02
2019-03-28 08:22:26 iteration: 32505 loss: 0.0032 lr: 0.02
2019-03-28 08:23:16 iteration: 32510 loss: 0.0041 lr: 0.02
2019-03-28 08:23:37 iteration: 32515 loss: 0.0058 lr: 0.02
2019-03-28 08:23:57 iteration: 32520 loss: 0.0043 lr: 0.02
2019-03-28 08:24:20 iteration: 32525 loss: 0.0036 lr: 0.02
2019-03-28 08:25:11 iteration: 32530 loss: 0.0038 lr: 0.02
2019-03-28 08:25:34 iteration: 32535 loss: 0.0044 lr: 0.02
2019-03-28 08:25:55 iteration: 32540 loss: 0.0061 lr: 0.02
2019-03-28 08:26:44 iteration: 32545 loss: 0.0038 lr: 0.02
2019-03-28 08:27:30 iteration: 32550 loss: 0.0031 lr: 0.02
2019-03-28 08:27:55 iteration: 32555 loss: 0.0033 lr: 0.02
2019-03-28 08:28:30 iteration: 32560 loss: 0.0050 lr: 0.02
2019-03-28 08:29:23 iteration: 32565 loss: 0.0044 lr: 0.02
2019-03-28 08:30:21 iteration: 32570 loss: 0.0029 lr: 0.02
2019-03-28 08:30:53 iteration: 32575 loss: 0.0049 lr: 0.02
2019-03-28 08:31:35 iteration: 32580 loss: 0.0036 lr: 0.02
2019-03-28 08:32:06 iteration: 32585 loss: 0.0095 lr: 0.02
2019-03-28 08:32:40 iteration: 32590 loss: 0.0040 lr: 0.02
2019-03-28 08:33:53 iteration: 32595 loss: 0.0045 lr: 0.02
2019-03-28 08:34:13 iteration: 32600 loss: 0.0039 lr: 0.02
2019-03-28 08:34:41 iteration: 32605 loss: 0.0073 lr: 0.02
2019-03-28 08:35:09 iteration: 32610 loss: 0.0050 lr: 0.02
2019-03-28 08:35:56 iteration: 32615 loss: 0.0035 lr: 0.02
2019-03-28 08:36:29 iteration: 32620 loss: 0.0052 lr: 0.02
2019-03-28 08:36:50 iteration: 32625 loss: 0.0041 lr: 0.02
2019-03-28 08:37:05 iteration: 32630 loss: 0.0044 lr: 0.02
2019-03-28 08:37:47 iteration: 32635 loss: 0.0044 lr: 0.02
2019-03-28 08:38:08 iteration: 32640 loss: 0.0058 lr: 0.02
2019-03-28 08:38:45 iteration: 32645 loss: 0.0040 lr: 0.02
2019-03-28 08:39:14 iteration: 32650 loss: 0.0045 lr: 0.02
2019-03-28 08:40:40 iteration: 32655 loss: 0.0033 lr: 0.02
2019-03-28 08:40:55 iteration: 32660 loss: 0.0074 lr: 0.02
2019-03-28 08:41:15 iteration: 32665 loss: 0.0042 lr: 0.02
2019-03-28 08:42:09 iteration: 32670 loss: 0.0031 lr: 0.02
2019-03-28 08:42:55 iteration: 32675 loss: 0.0043 lr: 0.02
2019-03-28 08:44:07 iteration: 32680 loss: 0.0043 lr: 0.02
2019-03-28 08:44:37 iteration: 32685 loss: 0.0044 lr: 0.02
2019-03-28 08:44:58 iteration: 32690 loss: 0.0042 lr: 0.02
2019-03-28 08:46:02 iteration: 32695 loss: 0.0055 lr: 0.02
2019-03-28 08:46:49 iteration: 32700 loss: 0.0045 lr: 0.02
2019-03-28 08:47:15 iteration: 32705 loss: 0.0083 lr: 0.02
2019-03-28 08:48:10 iteration: 32710 loss: 0.0040 lr: 0.02
2019-03-28 08:48:40 iteration: 32715 loss: 0.0034 lr: 0.02
2019-03-28 08:49:55 iteration: 32720 loss: 0.0041 lr: 0.02
2019-03-28 08:50:16 iteration: 32725 loss: 0.0057 lr: 0.02
2019-03-28 08:51:13 iteration: 32730 loss: 0.0046 lr: 0.02
2019-03-28 08:52:10 iteration: 32735 loss: 0.0034 lr: 0.02
2019-03-28 08:52:25 iteration: 32740 loss: 0.0063 lr: 0.02
2019-03-28 08:53:46 iteration: 32745 loss: 0.0053 lr: 0.02
2019-03-28 08:54:37 iteration: 32750 loss: 0.0043 lr: 0.02
2019-03-28 08:54:58 iteration: 32755 loss: 0.0054 lr: 0.02
2019-03-28 08:55:20 iteration: 32760 loss: 0.0041 lr: 0.02
2019-03-28 08:55:38 iteration: 32765 loss: 0.0050 lr: 0.02
2019-03-28 08:56:22 iteration: 32770 loss: 0.0038 lr: 0.02
2019-03-28 08:56:51 iteration: 32775 loss: 0.0053 lr: 0.02
2019-03-28 08:57:56 iteration: 32780 loss: 0.0030 lr: 0.02
2019-03-28 08:59:11 iteration: 32785 loss: 0.0041 lr: 0.02
2019-03-28 09:00:08 iteration: 32790 loss: 0.0048 lr: 0.02
2019-03-28 09:00:56 iteration: 32795 loss: 0.0048 lr: 0.02
2019-03-28 09:01:23 iteration: 32800 loss: 0.0042 lr: 0.02
2019-03-28 09:02:03 iteration: 32805 loss: 0.0059 lr: 0.02
2019-03-28 09:02:50 iteration: 32810 loss: 0.0036 lr: 0.02
2019-03-28 09:03:17 iteration: 32815 loss: 0.0035 lr: 0.02
2019-03-28 09:03:33 iteration: 32820 loss: 0.0051 lr: 0.02
2019-03-28 09:04:48 iteration: 32825 loss: 0.0029 lr: 0.02
2019-03-28 09:05:41 iteration: 32830 loss: 0.0043 lr: 0.02
2019-03-28 09:06:14 iteration: 32835 loss: 0.0043 lr: 0.02
2019-03-28 09:06:49 iteration: 32840 loss: 0.0037 lr: 0.02
2019-03-28 09:07:37 iteration: 32845 loss: 0.0031 lr: 0.02
2019-03-28 09:08:42 iteration: 32850 loss: 0.0048 lr: 0.02
2019-03-28 09:09:28 iteration: 32855 loss: 0.0038 lr: 0.02
2019-03-28 09:10:16 iteration: 32860 loss: 0.0038 lr: 0.02
2019-03-28 09:10:36 iteration: 32865 loss: 0.0042 lr: 0.02
2019-03-28 09:11:16 iteration: 32870 loss: 0.0055 lr: 0.02
2019-03-28 09:11:57 iteration: 32875 loss: 0.0049 lr: 0.02
2019-03-28 09:12:28 iteration: 32880 loss: 0.0055 lr: 0.02
2019-03-28 09:12:57 iteration: 32885 loss: 0.0035 lr: 0.02
2019-03-28 09:13:25 iteration: 32890 loss: 0.0037 lr: 0.02
2019-03-28 09:13:55 iteration: 32895 loss: 0.0046 lr: 0.02
2019-03-28 09:14:27 iteration: 32900 loss: 0.0056 lr: 0.02
2019-03-28 09:14:59 iteration: 32905 loss: 0.0056 lr: 0.02
2019-03-28 09:15:25 iteration: 32910 loss: 0.0037 lr: 0.02
2019-03-28 09:15:40 iteration: 32915 loss: 0.0048 lr: 0.02
2019-03-28 09:16:00 iteration: 32920 loss: 0.0037 lr: 0.02
2019-03-28 09:17:10 iteration: 32925 loss: 0.0036 lr: 0.02
2019-03-28 09:17:57 iteration: 32930 loss: 0.0051 lr: 0.02
2019-03-28 09:19:32 iteration: 32935 loss: 0.0027 lr: 0.02
2019-03-28 09:20:52 iteration: 32940 loss: 0.0044 lr: 0.02
2019-03-28 09:21:48 iteration: 32945 loss: 0.0032 lr: 0.02
2019-03-28 09:22:15 iteration: 32950 loss: 0.0050 lr: 0.02
2019-03-28 09:23:02 iteration: 32955 loss: 0.0036 lr: 0.02
2019-03-28 09:23:14 iteration: 32960 loss: 0.0029 lr: 0.02
2019-03-28 09:23:30 iteration: 32965 loss: 0.0097 lr: 0.02
2019-03-28 09:24:04 iteration: 32970 loss: 0.0042 lr: 0.02
2019-03-28 09:24:43 iteration: 32975 loss: 0.0045 lr: 0.02
2019-03-28 09:24:52 iteration: 32980 loss: 0.0059 lr: 0.02
2019-03-28 09:25:25 iteration: 32985 loss: 0.0062 lr: 0.02
2019-03-28 09:26:16 iteration: 32990 loss: 0.0060 lr: 0.02
2019-03-28 09:26:36 iteration: 32995 loss: 0.0055 lr: 0.02
2019-03-28 09:27:24 iteration: 33000 loss: 0.0042 lr: 0.02
2019-03-28 09:28:20 iteration: 33005 loss: 0.0051 lr: 0.02
2019-03-28 09:29:13 iteration: 33010 loss: 0.0036 lr: 0.02
2019-03-28 09:29:28 iteration: 33015 loss: 0.0053 lr: 0.02
2019-03-28 09:30:27 iteration: 33020 loss: 0.0026 lr: 0.02
2019-03-28 09:30:45 iteration: 33025 loss: 0.0043 lr: 0.02
2019-03-28 09:31:43 iteration: 33030 loss: 0.0047 lr: 0.02
2019-03-28 09:32:29 iteration: 33035 loss: 0.0034 lr: 0.02
2019-03-28 09:33:19 iteration: 33040 loss: 0.0032 lr: 0.02
2019-03-28 09:33:40 iteration: 33045 loss: 0.0056 lr: 0.02
2019-03-28 09:34:25 iteration: 33050 loss: 0.0037 lr: 0.02
2019-03-28 09:35:09 iteration: 33055 loss: 0.0049 lr: 0.02
2019-03-28 09:36:47 iteration: 33060 loss: 0.0034 lr: 0.02
2019-03-28 09:37:35 iteration: 33065 loss: 0.0046 lr: 0.02
2019-03-28 09:38:22 iteration: 33070 loss: 0.0029 lr: 0.02
2019-03-28 09:39:29 iteration: 33075 loss: 0.0028 lr: 0.02
2019-03-28 09:40:39 iteration: 33080 loss: 0.0034 lr: 0.02
2019-03-28 09:41:10 iteration: 33085 loss: 0.0058 lr: 0.02
2019-03-28 09:41:59 iteration: 33090 loss: 0.0035 lr: 0.02
2019-03-28 09:42:50 iteration: 33095 loss: 0.0049 lr: 0.02
2019-03-28 09:43:05 iteration: 33100 loss: 0.0050 lr: 0.02
2019-03-28 09:43:32 iteration: 33105 loss: 0.0059 lr: 0.02
2019-03-28 09:43:41 iteration: 33110 loss: 0.0056 lr: 0.02
2019-03-28 09:44:06 iteration: 33115 loss: 0.0055 lr: 0.02
2019-03-28 09:45:37 iteration: 33120 loss: 0.0044 lr: 0.02
2019-03-28 09:46:19 iteration: 33125 loss: 0.0030 lr: 0.02
2019-03-28 09:47:01 iteration: 33130 loss: 0.0032 lr: 0.02
2019-03-28 09:47:22 iteration: 33135 loss: 0.0040 lr: 0.02
2019-03-28 09:47:55 iteration: 33140 loss: 0.0042 lr: 0.02
2019-03-28 09:48:20 iteration: 33145 loss: 0.0041 lr: 0.02
2019-03-28 09:49:09 iteration: 33150 loss: 0.0028 lr: 0.02
2019-03-28 09:49:35 iteration: 33155 loss: 0.0038 lr: 0.02
2019-03-28 09:49:50 iteration: 33160 loss: 0.0044 lr: 0.02
2019-03-28 09:50:45 iteration: 33165 loss: 0.0050 lr: 0.02
2019-03-28 09:51:02 iteration: 33170 loss: 0.0049 lr: 0.02
2019-03-28 09:51:39 iteration: 33175 loss: 0.0043 lr: 0.02
2019-03-28 09:52:45 iteration: 33180 loss: 0.0028 lr: 0.02
2019-03-28 09:53:32 iteration: 33185 loss: 0.0046 lr: 0.02
2019-03-28 09:54:30 iteration: 33190 loss: 0.0043 lr: 0.02
2019-03-28 09:55:05 iteration: 33195 loss: 0.0039 lr: 0.02
2019-03-28 09:55:56 iteration: 33200 loss: 0.0024 lr: 0.02
2019-03-28 09:56:29 iteration: 33205 loss: 0.0047 lr: 0.02
2019-03-28 09:57:31 iteration: 33210 loss: 0.0037 lr: 0.02
2019-03-28 09:57:56 iteration: 33215 loss: 0.0049 lr: 0.02
2019-03-28 09:58:12 iteration: 33220 loss: 0.0054 lr: 0.02
2019-03-28 09:58:25 iteration: 33225 loss: 0.0047 lr: 0.02
2019-03-28 09:59:09 iteration: 33230 loss: 0.0044 lr: 0.02
2019-03-28 09:59:34 iteration: 33235 loss: 0.0081 lr: 0.02
2019-03-28 10:00:12 iteration: 33240 loss: 0.0034 lr: 0.02
2019-03-28 10:00:23 iteration: 33245 loss: 0.0051 lr: 0.02
2019-03-28 10:01:33 iteration: 33250 loss: 0.0035 lr: 0.02
2019-03-28 10:02:15 iteration: 33255 loss: 0.0050 lr: 0.02
2019-03-28 10:02:34 iteration: 33260 loss: 0.0046 lr: 0.02
2019-03-28 10:02:50 iteration: 33265 loss: 0.0054 lr: 0.02
2019-03-28 10:03:30 iteration: 33270 loss: 0.0053 lr: 0.02
2019-03-28 10:04:12 iteration: 33275 loss: 0.0042 lr: 0.02
2019-03-28 10:04:23 iteration: 33280 loss: 0.0035 lr: 0.02
2019-03-28 10:05:35 iteration: 33285 loss: 0.0031 lr: 0.02
2019-03-28 10:06:14 iteration: 33290 loss: 0.0053 lr: 0.02
2019-03-28 10:06:42 iteration: 33295 loss: 0.0042 lr: 0.02
2019-03-28 10:07:00 iteration: 33300 loss: 0.0061 lr: 0.02
2019-03-28 10:07:21 iteration: 33305 loss: 0.0037 lr: 0.02
2019-03-28 10:08:11 iteration: 33310 loss: 0.0043 lr: 0.02
2019-03-28 10:09:47 iteration: 33315 loss: 0.0036 lr: 0.02
2019-03-28 10:10:07 iteration: 33320 loss: 0.0046 lr: 0.02
2019-03-28 10:10:36 iteration: 33325 loss: 0.0043 lr: 0.02
2019-03-28 10:10:48 iteration: 33330 loss: 0.0057 lr: 0.02
2019-03-28 10:11:31 iteration: 33335 loss: 0.0037 lr: 0.02
2019-03-28 10:13:10 iteration: 33340 loss: 0.0036 lr: 0.02
2019-03-28 10:13:33 iteration: 33345 loss: 0.0031 lr: 0.02
2019-03-28 10:14:17 iteration: 33350 loss: 0.0044 lr: 0.02
2019-03-28 10:15:10 iteration: 33355 loss: 0.0042 lr: 0.02
2019-03-28 10:15:28 iteration: 33360 loss: 0.0048 lr: 0.02
2019-03-28 10:16:20 iteration: 33365 loss: 0.0047 lr: 0.02
2019-03-28 10:16:48 iteration: 33370 loss: 0.0048 lr: 0.02
2019-03-28 10:17:39 iteration: 33375 loss: 0.0032 lr: 0.02
2019-03-28 10:17:52 iteration: 33380 loss: 0.0046 lr: 0.02
2019-03-28 10:19:02 iteration: 33385 loss: 0.0032 lr: 0.02
2019-03-28 10:19:54 iteration: 33390 loss: 0.0054 lr: 0.02
2019-03-28 10:20:42 iteration: 33395 loss: 0.0040 lr: 0.02
2019-03-28 10:22:25 iteration: 33400 loss: 0.0039 lr: 0.02
2019-03-28 10:23:16 iteration: 33405 loss: 0.0034 lr: 0.02
2019-03-28 10:23:54 iteration: 33410 loss: 0.0033 lr: 0.02
2019-03-28 10:24:55 iteration: 33415 loss: 0.0045 lr: 0.02
2019-03-28 10:26:25 iteration: 33420 loss: 0.0028 lr: 0.02
2019-03-28 10:26:41 iteration: 33425 loss: 0.0042 lr: 0.02
2019-03-28 10:26:50 iteration: 33430 loss: 0.0062 lr: 0.02
2019-03-28 10:27:16 iteration: 33435 loss: 0.0034 lr: 0.02
2019-03-28 10:27:30 iteration: 33440 loss: 0.0045 lr: 0.02
2019-03-28 10:27:42 iteration: 33445 loss: 0.0047 lr: 0.02
2019-03-28 10:27:57 iteration: 33450 loss: 0.0047 lr: 0.02
2019-03-28 10:29:31 iteration: 33455 loss: 0.0029 lr: 0.02
2019-03-28 10:30:14 iteration: 33460 loss: 0.0057 lr: 0.02
2019-03-28 10:30:46 iteration: 33465 loss: 0.0047 lr: 0.02
2019-03-28 10:31:46 iteration: 33470 loss: 0.0046 lr: 0.02
2019-03-28 10:32:36 iteration: 33475 loss: 0.0052 lr: 0.02
2019-03-28 10:33:06 iteration: 33480 loss: 0.0040 lr: 0.02
2019-03-28 10:34:11 iteration: 33485 loss: 0.0039 lr: 0.02
2019-03-28 10:35:08 iteration: 33490 loss: 0.0071 lr: 0.02
2019-03-28 10:35:21 iteration: 33495 loss: 0.0049 lr: 0.02
2019-03-28 10:35:39 iteration: 33500 loss: 0.0046 lr: 0.02
2019-03-28 10:36:02 iteration: 33505 loss: 0.0048 lr: 0.02
2019-03-28 10:36:15 iteration: 33510 loss: 0.0054 lr: 0.02
2019-03-28 10:36:57 iteration: 33515 loss: 0.0059 lr: 0.02
2019-03-28 10:37:48 iteration: 33520 loss: 0.0044 lr: 0.02
2019-03-28 10:38:07 iteration: 33525 loss: 0.0059 lr: 0.02
2019-03-28 10:38:59 iteration: 33530 loss: 0.0033 lr: 0.02
2019-03-28 10:40:01 iteration: 33535 loss: 0.0042 lr: 0.02
2019-03-28 10:40:55 iteration: 33540 loss: 0.0027 lr: 0.02
2019-03-28 10:41:07 iteration: 33545 loss: 0.0048 lr: 0.02
2019-03-28 10:41:26 iteration: 33550 loss: 0.0055 lr: 0.02
2019-03-28 10:42:02 iteration: 33555 loss: 0.0046 lr: 0.02
2019-03-28 10:42:15 iteration: 33560 loss: 0.0061 lr: 0.02
2019-03-28 10:42:35 iteration: 33565 loss: 0.0063 lr: 0.02
2019-03-28 10:42:52 iteration: 33570 loss: 0.0051 lr: 0.02
2019-03-28 10:43:42 iteration: 33575 loss: 0.0042 lr: 0.02
2019-03-28 10:43:58 iteration: 33580 loss: 0.0053 lr: 0.02
2019-03-28 10:44:50 iteration: 33585 loss: 0.0031 lr: 0.02
2019-03-28 10:45:19 iteration: 33590 loss: 0.0041 lr: 0.02
2019-03-28 10:45:42 iteration: 33595 loss: 0.0032 lr: 0.02
2019-03-28 10:45:58 iteration: 33600 loss: 0.0064 lr: 0.02
2019-03-28 10:47:09 iteration: 33605 loss: 0.0041 lr: 0.02
2019-03-28 10:47:32 iteration: 33610 loss: 0.0047 lr: 0.02
2019-03-28 10:47:48 iteration: 33615 loss: 0.0057 lr: 0.02
2019-03-28 10:48:52 iteration: 33620 loss: 0.0037 lr: 0.02
2019-03-28 10:49:45 iteration: 33625 loss: 0.0030 lr: 0.02
2019-03-28 10:50:24 iteration: 33630 loss: 0.0050 lr: 0.02
2019-03-28 10:50:56 iteration: 33635 loss: 0.0038 lr: 0.02
2019-03-28 10:51:16 iteration: 33640 loss: 0.0042 lr: 0.02
2019-03-28 10:51:56 iteration: 33645 loss: 0.0044 lr: 0.02
2019-03-28 10:52:47 iteration: 33650 loss: 0.0032 lr: 0.02
2019-03-28 10:53:54 iteration: 33655 loss: 0.0043 lr: 0.02
2019-03-28 10:54:47 iteration: 33660 loss: 0.0035 lr: 0.02
2019-03-28 10:55:38 iteration: 33665 loss: 0.0042 lr: 0.02
2019-03-28 10:55:52 iteration: 33670 loss: 0.0048 lr: 0.02
2019-03-28 10:56:44 iteration: 33675 loss: 0.0037 lr: 0.02
2019-03-28 10:57:24 iteration: 33680 loss: 0.0052 lr: 0.02
2019-03-28 10:58:26 iteration: 33685 loss: 0.0031 lr: 0.02
2019-03-28 10:58:43 iteration: 33690 loss: 0.0040 lr: 0.02
2019-03-28 11:00:04 iteration: 33695 loss: 0.0051 lr: 0.02
2019-03-28 11:01:17 iteration: 33700 loss: 0.0041 lr: 0.02
2019-03-28 11:01:57 iteration: 33705 loss: 0.0044 lr: 0.02
2019-03-28 11:02:32 iteration: 33710 loss: 0.0053 lr: 0.02
2019-03-28 11:03:11 iteration: 33715 loss: 0.0039 lr: 0.02
2019-03-28 11:03:25 iteration: 33720 loss: 0.0058 lr: 0.02
2019-03-28 11:04:05 iteration: 33725 loss: 0.0050 lr: 0.02
2019-03-28 11:04:18 iteration: 33730 loss: 0.0043 lr: 0.02
2019-03-28 11:04:44 iteration: 33735 loss: 0.0034 lr: 0.02
2019-03-28 11:06:32 iteration: 33740 loss: 0.0053 lr: 0.02
2019-03-28 11:07:10 iteration: 33745 loss: 0.0040 lr: 0.02
2019-03-28 11:07:59 iteration: 33750 loss: 0.0034 lr: 0.02
2019-03-28 11:08:25 iteration: 33755 loss: 0.0047 lr: 0.02
2019-03-28 11:09:10 iteration: 33760 loss: 0.0025 lr: 0.02
2019-03-28 11:09:32 iteration: 33765 loss: 0.0051 lr: 0.02
2019-03-28 11:09:54 iteration: 33770 loss: 0.0045 lr: 0.02
2019-03-28 11:10:28 iteration: 33775 loss: 0.0045 lr: 0.02
2019-03-28 11:11:30 iteration: 33780 loss: 0.0049 lr: 0.02
2019-03-28 11:12:19 iteration: 33785 loss: 0.0048 lr: 0.02
2019-03-28 11:12:41 iteration: 33790 loss: 0.0065 lr: 0.02
2019-03-28 11:12:55 iteration: 33795 loss: 0.0050 lr: 0.02
2019-03-28 11:13:37 iteration: 33800 loss: 0.0037 lr: 0.02
2019-03-28 11:14:07 iteration: 33805 loss: 0.0043 lr: 0.02
2019-03-28 11:14:26 iteration: 33810 loss: 0.0079 lr: 0.02
2019-03-28 11:14:41 iteration: 33815 loss: 0.0058 lr: 0.02
2019-03-28 11:15:23 iteration: 33820 loss: 0.0033 lr: 0.02
2019-03-28 11:16:05 iteration: 33825 loss: 0.0046 lr: 0.02
2019-03-28 11:16:42 iteration: 33830 loss: 0.0053 lr: 0.02
2019-03-28 11:17:25 iteration: 33835 loss: 0.0042 lr: 0.02
2019-03-28 11:17:44 iteration: 33840 loss: 0.0045 lr: 0.02
2019-03-28 11:18:35 iteration: 33845 loss: 0.0046 lr: 0.02
2019-03-28 11:19:08 iteration: 33850 loss: 0.0044 lr: 0.02
2019-03-28 11:21:12 iteration: 33855 loss: 0.0036 lr: 0.02
2019-03-28 11:22:09 iteration: 33860 loss: 0.0033 lr: 0.02
2019-03-28 11:22:44 iteration: 33865 loss: 0.0057 lr: 0.02
2019-03-28 11:24:13 iteration: 33870 loss: 0.0029 lr: 0.02
2019-03-28 11:24:32 iteration: 33875 loss: 0.0046 lr: 0.02
2019-03-28 11:24:59 iteration: 33880 loss: 0.0045 lr: 0.02
2019-03-28 11:26:02 iteration: 33885 loss: 0.0053 lr: 0.02
2019-03-28 11:27:10 iteration: 33890 loss: 0.0038 lr: 0.02
2019-03-28 11:28:01 iteration: 33895 loss: 0.0045 lr: 0.02
2019-03-28 11:28:59 iteration: 33900 loss: 0.0039 lr: 0.02
2019-03-28 11:29:30 iteration: 33905 loss: 0.0040 lr: 0.02
2019-03-28 11:30:54 iteration: 33910 loss: 0.0033 lr: 0.02
2019-03-28 11:31:38 iteration: 33915 loss: 0.0034 lr: 0.02
2019-03-28 11:32:13 iteration: 33920 loss: 0.0042 lr: 0.02
2019-03-28 11:32:44 iteration: 33925 loss: 0.0029 lr: 0.02
2019-03-28 11:33:24 iteration: 33930 loss: 0.0055 lr: 0.02
2019-03-28 11:34:14 iteration: 33935 loss: 0.0034 lr: 0.02
2019-03-28 11:34:51 iteration: 33940 loss: 0.0036 lr: 0.02
2019-03-28 11:35:25 iteration: 33945 loss: 0.0052 lr: 0.02
2019-03-28 11:36:01 iteration: 33950 loss: 0.0035 lr: 0.02
2019-03-28 11:37:24 iteration: 33955 loss: 0.0047 lr: 0.02
2019-03-28 11:38:28 iteration: 33960 loss: 0.0043 lr: 0.02
2019-03-28 11:38:48 iteration: 33965 loss: 0.0069 lr: 0.02
2019-03-28 11:39:03 iteration: 33970 loss: 0.0041 lr: 0.02
2019-03-28 11:39:25 iteration: 33975 loss: 0.0039 lr: 0.02
2019-03-28 11:39:44 iteration: 33980 loss: 0.0059 lr: 0.02
2019-03-28 11:40:37 iteration: 33985 loss: 0.0027 lr: 0.02
2019-03-28 11:41:12 iteration: 33990 loss: 0.0049 lr: 0.02
2019-03-28 11:42:12 iteration: 33995 loss: 0.0043 lr: 0.02
2019-03-28 11:42:34 iteration: 34000 loss: 0.0038 lr: 0.02
2019-03-28 11:42:53 iteration: 34005 loss: 0.0039 lr: 0.02
2019-03-28 11:43:42 iteration: 34010 loss: 0.0050 lr: 0.02
2019-03-28 11:44:07 iteration: 34015 loss: 0.0040 lr: 0.02
2019-03-28 11:44:54 iteration: 34020 loss: 0.0040 lr: 0.02
2019-03-28 11:45:37 iteration: 34025 loss: 0.0038 lr: 0.02
2019-03-28 11:46:39 iteration: 34030 loss: 0.0036 lr: 0.02
2019-03-28 11:47:03 iteration: 34035 loss: 0.0049 lr: 0.02
2019-03-28 11:47:22 iteration: 34040 loss: 0.0056 lr: 0.02
2019-03-28 11:47:50 iteration: 34045 loss: 0.0044 lr: 0.02
2019-03-28 11:48:12 iteration: 34050 loss: 0.0049 lr: 0.02
2019-03-28 11:48:46 iteration: 34055 loss: 0.0054 lr: 0.02
2019-03-28 11:49:09 iteration: 34060 loss: 0.0050 lr: 0.02
2019-03-28 11:49:34 iteration: 34065 loss: 0.0055 lr: 0.02
2019-03-28 11:50:00 iteration: 34070 loss: 0.0041 lr: 0.02
2019-03-28 11:51:09 iteration: 34075 loss: 0.0040 lr: 0.02
2019-03-28 11:51:35 iteration: 34080 loss: 0.0030 lr: 0.02
2019-03-28 11:52:08 iteration: 34085 loss: 0.0036 lr: 0.02
2019-03-28 11:52:18 iteration: 34090 loss: 0.0056 lr: 0.02
2019-03-28 11:52:33 iteration: 34095 loss: 0.0046 lr: 0.02
2019-03-28 11:53:36 iteration: 34100 loss: 0.0037 lr: 0.02
2019-03-28 11:54:18 iteration: 34105 loss: 0.0041 lr: 0.02
2019-03-28 11:55:07 iteration: 34110 loss: 0.0045 lr: 0.02
2019-03-28 11:55:36 iteration: 34115 loss: 0.0054 lr: 0.02
2019-03-28 11:56:28 iteration: 34120 loss: 0.0049 lr: 0.02
2019-03-28 11:57:12 iteration: 34125 loss: 0.0039 lr: 0.02
2019-03-28 11:57:31 iteration: 34130 loss: 0.0047 lr: 0.02
2019-03-28 11:57:44 iteration: 34135 loss: 0.0044 lr: 0.02
2019-03-28 11:58:50 iteration: 34140 loss: 0.0060 lr: 0.02
2019-03-28 11:59:50 iteration: 34145 loss: 0.0028 lr: 0.02
2019-03-28 12:00:30 iteration: 34150 loss: 0.0040 lr: 0.02
2019-03-28 12:00:48 iteration: 34155 loss: 0.0054 lr: 0.02
2019-03-28 12:01:14 iteration: 34160 loss: 0.0038 lr: 0.02
2019-03-28 12:01:49 iteration: 34165 loss: 0.0052 lr: 0.02
2019-03-28 12:02:06 iteration: 34170 loss: 0.0041 lr: 0.02
2019-03-28 12:03:06 iteration: 34175 loss: 0.0041 lr: 0.02
2019-03-28 12:03:42 iteration: 34180 loss: 0.0044 lr: 0.02
2019-03-28 12:04:17 iteration: 34185 loss: 0.0045 lr: 0.02
2019-03-28 12:04:56 iteration: 34190 loss: 0.0040 lr: 0.02
2019-03-28 12:05:23 iteration: 34195 loss: 0.0043 lr: 0.02
2019-03-28 12:06:20 iteration: 34200 loss: 0.0033 lr: 0.02
2019-03-28 12:06:57 iteration: 34205 loss: 0.0054 lr: 0.02
2019-03-28 12:07:13 iteration: 34210 loss: 0.0051 lr: 0.02
2019-03-28 12:08:35 iteration: 34215 loss: 0.0033 lr: 0.02
2019-03-28 12:09:28 iteration: 34220 loss: 0.0030 lr: 0.02
2019-03-28 12:10:00 iteration: 34225 loss: 0.0035 lr: 0.02
2019-03-28 12:10:17 iteration: 34230 loss: 0.0055 lr: 0.02
2019-03-28 12:10:57 iteration: 34235 loss: 0.0046 lr: 0.02
2019-03-28 12:11:16 iteration: 34240 loss: 0.0033 lr: 0.02
2019-03-28 12:11:43 iteration: 34245 loss: 0.0043 lr: 0.02
2019-03-28 12:11:55 iteration: 34250 loss: 0.0043 lr: 0.02
2019-03-28 12:13:15 iteration: 34255 loss: 0.0056 lr: 0.02
2019-03-28 12:13:31 iteration: 34260 loss: 0.0043 lr: 0.02
2019-03-28 12:14:29 iteration: 34265 loss: 0.0035 lr: 0.02
2019-03-28 12:14:47 iteration: 34270 loss: 0.0055 lr: 0.02
2019-03-28 12:16:06 iteration: 34275 loss: 0.0039 lr: 0.02
2019-03-28 12:17:31 iteration: 34280 loss: 0.0041 lr: 0.02
2019-03-28 12:17:41 iteration: 34285 loss: 0.0048 lr: 0.02
2019-03-28 12:18:04 iteration: 34290 loss: 0.0035 lr: 0.02
2019-03-28 12:18:52 iteration: 34295 loss: 0.0047 lr: 0.02
2019-03-28 12:20:01 iteration: 34300 loss: 0.0037 lr: 0.02
2019-03-28 12:20:49 iteration: 34305 loss: 0.0039 lr: 0.02
2019-03-28 12:21:31 iteration: 34310 loss: 0.0058 lr: 0.02
2019-03-28 12:22:23 iteration: 34315 loss: 0.0034 lr: 0.02
2019-03-28 12:23:30 iteration: 34320 loss: 0.0060 lr: 0.02
2019-03-28 12:23:54 iteration: 34325 loss: 0.0041 lr: 0.02
2019-03-28 12:24:51 iteration: 34330 loss: 0.0046 lr: 0.02
2019-03-28 12:25:44 iteration: 34335 loss: 0.0044 lr: 0.02
2019-03-28 12:26:02 iteration: 34340 loss: 0.0043 lr: 0.02
2019-03-28 12:26:31 iteration: 34345 loss: 0.0039 lr: 0.02
2019-03-28 12:27:37 iteration: 34350 loss: 0.0041 lr: 0.02
2019-03-28 12:28:36 iteration: 34355 loss: 0.0050 lr: 0.02
2019-03-28 12:29:37 iteration: 34360 loss: 0.0041 lr: 0.02
2019-03-28 12:30:15 iteration: 34365 loss: 0.0055 lr: 0.02
2019-03-28 12:30:31 iteration: 34370 loss: 0.0053 lr: 0.02
2019-03-28 12:31:21 iteration: 34375 loss: 0.0041 lr: 0.02
2019-03-28 12:31:38 iteration: 34380 loss: 0.0064 lr: 0.02
2019-03-28 12:31:53 iteration: 34385 loss: 0.0053 lr: 0.02
2019-03-28 12:32:37 iteration: 34390 loss: 0.0032 lr: 0.02
2019-03-28 12:33:33 iteration: 34395 loss: 0.0051 lr: 0.02
2019-03-28 12:33:50 iteration: 34400 loss: 0.0042 lr: 0.02
2019-03-28 12:34:39 iteration: 34405 loss: 0.0056 lr: 0.02
2019-03-28 12:34:55 iteration: 34410 loss: 0.0047 lr: 0.02
2019-03-28 12:35:06 iteration: 34415 loss: 0.0053 lr: 0.02
2019-03-28 12:35:37 iteration: 34420 loss: 0.0033 lr: 0.02
2019-03-28 12:36:19 iteration: 34425 loss: 0.0049 lr: 0.02
2019-03-28 12:36:57 iteration: 34430 loss: 0.0045 lr: 0.02
2019-03-28 12:37:34 iteration: 34435 loss: 0.0048 lr: 0.02
2019-03-28 12:38:07 iteration: 34440 loss: 0.0036 lr: 0.02
2019-03-28 12:38:52 iteration: 34445 loss: 0.0031 lr: 0.02
2019-03-28 12:39:13 iteration: 34450 loss: 0.0058 lr: 0.02
2019-03-28 12:39:41 iteration: 34455 loss: 0.0040 lr: 0.02
2019-03-28 12:39:59 iteration: 34460 loss: 0.0054 lr: 0.02
2019-03-28 12:40:28 iteration: 34465 loss: 0.0050 lr: 0.02
2019-03-28 12:41:04 iteration: 34470 loss: 0.0029 lr: 0.02
2019-03-28 12:42:07 iteration: 34475 loss: 0.0042 lr: 0.02
2019-03-28 12:42:41 iteration: 34480 loss: 0.0043 lr: 0.02
2019-03-28 12:43:17 iteration: 34485 loss: 0.0036 lr: 0.02
2019-03-28 12:43:38 iteration: 34490 loss: 0.0060 lr: 0.02
2019-03-28 12:44:16 iteration: 34495 loss: 0.0066 lr: 0.02
2019-03-28 12:45:01 iteration: 34500 loss: 0.0058 lr: 0.02
2019-03-28 12:46:08 iteration: 34505 loss: 0.0040 lr: 0.02
2019-03-28 12:46:49 iteration: 34510 loss: 0.0031 lr: 0.02
2019-03-28 12:47:53 iteration: 34515 loss: 0.0034 lr: 0.02
2019-03-28 12:48:56 iteration: 34520 loss: 0.0036 lr: 0.02
2019-03-28 12:49:36 iteration: 34525 loss: 0.0026 lr: 0.02
2019-03-28 12:50:56 iteration: 34530 loss: 0.0029 lr: 0.02
2019-03-28 12:51:49 iteration: 34535 loss: 0.0043 lr: 0.02
2019-03-28 12:52:43 iteration: 34540 loss: 0.0042 lr: 0.02
2019-03-28 12:52:59 iteration: 34545 loss: 0.0042 lr: 0.02
2019-03-28 12:53:08 iteration: 34550 loss: 0.0059 lr: 0.02
2019-03-28 12:54:12 iteration: 34555 loss: 0.0070 lr: 0.02
2019-03-28 12:54:59 iteration: 34560 loss: 0.0054 lr: 0.02
2019-03-28 12:56:25 iteration: 34565 loss: 0.0035 lr: 0.02
2019-03-28 12:57:17 iteration: 34570 loss: 0.0030 lr: 0.02
2019-03-28 12:57:43 iteration: 34575 loss: 0.0042 lr: 0.02
2019-03-28 12:58:25 iteration: 34580 loss: 0.0066 lr: 0.02
2019-03-28 12:59:10 iteration: 34585 loss: 0.0034 lr: 0.02
2019-03-28 12:59:31 iteration: 34590 loss: 0.0034 lr: 0.02
2019-03-28 12:59:46 iteration: 34595 loss: 0.0046 lr: 0.02
2019-03-28 13:00:15 iteration: 34600 loss: 0.0043 lr: 0.02
2019-03-28 13:01:04 iteration: 34605 loss: 0.0037 lr: 0.02
2019-03-28 13:01:15 iteration: 34610 loss: 0.0097 lr: 0.02
2019-03-28 13:02:03 iteration: 34615 loss: 0.0031 lr: 0.02
2019-03-28 13:03:07 iteration: 34620 loss: 0.0043 lr: 0.02
2019-03-28 13:03:58 iteration: 34625 loss: 0.0041 lr: 0.02
2019-03-28 13:05:10 iteration: 34630 loss: 0.0040 lr: 0.02
2019-03-28 13:05:29 iteration: 34635 loss: 0.0048 lr: 0.02
2019-03-28 13:06:05 iteration: 34640 loss: 0.0044 lr: 0.02
2019-03-28 13:06:31 iteration: 34645 loss: 0.0032 lr: 0.02
2019-03-28 13:06:53 iteration: 34650 loss: 0.0038 lr: 0.02
2019-03-28 13:08:02 iteration: 34655 loss: 0.0036 lr: 0.02
2019-03-28 13:08:31 iteration: 34660 loss: 0.0042 lr: 0.02
2019-03-28 13:09:05 iteration: 34665 loss: 0.0065 lr: 0.02
2019-03-28 13:09:26 iteration: 34670 loss: 0.0051 lr: 0.02
2019-03-28 13:09:52 iteration: 34675 loss: 0.0051 lr: 0.02
2019-03-28 13:11:05 iteration: 34680 loss: 0.0033 lr: 0.02
2019-03-28 13:11:29 iteration: 34685 loss: 0.0039 lr: 0.02
2019-03-28 13:11:52 iteration: 34690 loss: 0.0064 lr: 0.02
2019-03-28 13:12:45 iteration: 34695 loss: 0.0037 lr: 0.02
2019-03-28 13:13:00 iteration: 34700 loss: 0.0050 lr: 0.02
2019-03-28 13:13:21 iteration: 34705 loss: 0.0048 lr: 0.02
2019-03-28 13:13:35 iteration: 34710 loss: 0.0044 lr: 0.02
2019-03-28 13:14:16 iteration: 34715 loss: 0.0062 lr: 0.02
2019-03-28 13:14:48 iteration: 34720 loss: 0.0041 lr: 0.02
2019-03-28 13:15:20 iteration: 34725 loss: 0.0040 lr: 0.02
2019-03-28 13:15:56 iteration: 34730 loss: 0.0055 lr: 0.02
2019-03-28 13:16:50 iteration: 34735 loss: 0.0035 lr: 0.02
2019-03-28 13:18:15 iteration: 34740 loss: 0.0041 lr: 0.02
2019-03-28 13:18:38 iteration: 34745 loss: 0.0054 lr: 0.02
2019-03-28 13:19:07 iteration: 34750 loss: 0.0040 lr: 0.02
2019-03-28 13:19:58 iteration: 34755 loss: 0.0046 lr: 0.02
2019-03-28 13:20:48 iteration: 34760 loss: 0.0048 lr: 0.02
2019-03-28 13:21:38 iteration: 34765 loss: 0.0051 lr: 0.02
2019-03-28 13:22:03 iteration: 34770 loss: 0.0043 lr: 0.02
2019-03-28 13:22:38 iteration: 34775 loss: 0.0044 lr: 0.02
2019-03-28 13:23:18 iteration: 34780 loss: 0.0056 lr: 0.02
2019-03-28 13:24:00 iteration: 34785 loss: 0.0041 lr: 0.02
2019-03-28 13:24:37 iteration: 34790 loss: 0.0042 lr: 0.02
2019-03-28 13:25:12 iteration: 34795 loss: 0.0040 lr: 0.02
2019-03-28 13:25:22 iteration: 34800 loss: 0.0036 lr: 0.02
2019-03-28 13:25:51 iteration: 34805 loss: 0.0042 lr: 0.02
2019-03-28 13:26:10 iteration: 34810 loss: 0.0054 lr: 0.02
2019-03-28 13:26:29 iteration: 34815 loss: 0.0053 lr: 0.02
2019-03-28 13:28:34 iteration: 34820 loss: 0.0026 lr: 0.02
2019-03-28 13:29:01 iteration: 34825 loss: 0.0052 lr: 0.02
2019-03-28 13:29:17 iteration: 34830 loss: 0.0043 lr: 0.02
2019-03-28 13:29:40 iteration: 34835 loss: 0.0063 lr: 0.02
2019-03-28 13:30:02 iteration: 34840 loss: 0.0052 lr: 0.02
2019-03-28 13:30:47 iteration: 34845 loss: 0.0030 lr: 0.02
2019-03-28 13:31:08 iteration: 34850 loss: 0.0040 lr: 0.02
2019-03-28 13:31:43 iteration: 34855 loss: 0.0041 lr: 0.02
2019-03-28 13:32:46 iteration: 34860 loss: 0.0039 lr: 0.02
2019-03-28 13:33:02 iteration: 34865 loss: 0.0038 lr: 0.02
2019-03-28 13:33:53 iteration: 34870 loss: 0.0047 lr: 0.02
2019-03-28 13:34:24 iteration: 34875 loss: 0.0045 lr: 0.02
2019-03-28 13:34:35 iteration: 34880 loss: 0.0052 lr: 0.02
2019-03-28 13:35:09 iteration: 34885 loss: 0.0076 lr: 0.02
2019-03-28 13:35:49 iteration: 34890 loss: 0.0034 lr: 0.02
2019-03-28 13:36:22 iteration: 34895 loss: 0.0039 lr: 0.02
2019-03-28 13:37:16 iteration: 34900 loss: 0.0064 lr: 0.02
2019-03-28 13:37:37 iteration: 34905 loss: 0.0041 lr: 0.02
2019-03-28 13:38:00 iteration: 34910 loss: 0.0053 lr: 0.02
2019-03-28 13:39:16 iteration: 34915 loss: 0.0032 lr: 0.02
2019-03-28 13:39:59 iteration: 34920 loss: 0.0037 lr: 0.02
2019-03-28 13:40:20 iteration: 34925 loss: 0.0060 lr: 0.02
2019-03-28 13:40:37 iteration: 34930 loss: 0.0035 lr: 0.02
2019-03-28 13:41:46 iteration: 34935 loss: 0.0065 lr: 0.02
2019-03-28 13:42:30 iteration: 34940 loss: 0.0048 lr: 0.02
2019-03-28 13:42:51 iteration: 34945 loss: 0.0036 lr: 0.02
2019-03-28 13:43:40 iteration: 34950 loss: 0.0045 lr: 0.02
2019-03-28 13:44:41 iteration: 34955 loss: 0.0029 lr: 0.02
2019-03-28 13:44:52 iteration: 34960 loss: 0.0039 lr: 0.02
2019-03-28 13:45:25 iteration: 34965 loss: 0.0041 lr: 0.02
2019-03-28 13:46:12 iteration: 34970 loss: 0.0036 lr: 0.02
2019-03-28 13:46:47 iteration: 34975 loss: 0.0045 lr: 0.02
2019-03-28 13:48:21 iteration: 34980 loss: 0.0029 lr: 0.02
2019-03-28 13:48:44 iteration: 34985 loss: 0.0034 lr: 0.02
2019-03-28 13:48:54 iteration: 34990 loss: 0.0051 lr: 0.02
2019-03-28 13:49:54 iteration: 34995 loss: 0.0048 lr: 0.02
2019-03-28 13:50:39 iteration: 35000 loss: 0.0072 lr: 0.02
2019-03-28 13:51:09 iteration: 35005 loss: 0.0041 lr: 0.02
2019-03-28 13:51:34 iteration: 35010 loss: 0.0034 lr: 0.02
2019-03-28 13:51:52 iteration: 35015 loss: 0.0043 lr: 0.02
2019-03-28 13:52:39 iteration: 35020 loss: 0.0034 lr: 0.02
2019-03-28 13:53:29 iteration: 35025 loss: 0.0035 lr: 0.02
2019-03-28 13:53:57 iteration: 35030 loss: 0.0041 lr: 0.02
2019-03-28 13:54:41 iteration: 35035 loss: 0.0039 lr: 0.02
2019-03-28 13:55:40 iteration: 35040 loss: 0.0043 lr: 0.02
2019-03-28 13:55:56 iteration: 35045 loss: 0.0062 lr: 0.02
2019-03-28 13:56:12 iteration: 35050 loss: 0.0055 lr: 0.02
2019-03-28 13:57:32 iteration: 35055 loss: 0.0043 lr: 0.02
2019-03-28 13:57:53 iteration: 35060 loss: 0.0069 lr: 0.02
2019-03-28 13:58:16 iteration: 35065 loss: 0.0040 lr: 0.02
2019-03-28 13:58:48 iteration: 35070 loss: 0.0041 lr: 0.02
2019-03-28 13:59:37 iteration: 35075 loss: 0.0032 lr: 0.02
2019-03-28 14:00:00 iteration: 35080 loss: 0.0055 lr: 0.02
2019-03-28 14:01:40 iteration: 35085 loss: 0.0045 lr: 0.02
2019-03-28 14:02:14 iteration: 35090 loss: 0.0035 lr: 0.02
2019-03-28 14:03:28 iteration: 35095 loss: 0.0030 lr: 0.02
2019-03-28 14:03:48 iteration: 35100 loss: 0.0046 lr: 0.02
2019-03-28 14:04:31 iteration: 35105 loss: 0.0034 lr: 0.02
2019-03-28 14:05:07 iteration: 35110 loss: 0.0043 lr: 0.02
2019-03-28 14:06:11 iteration: 35115 loss: 0.0031 lr: 0.02
2019-03-28 14:06:56 iteration: 35120 loss: 0.0051 lr: 0.02
2019-03-28 14:07:49 iteration: 35125 loss: 0.0034 lr: 0.02
2019-03-28 14:08:18 iteration: 35130 loss: 0.0048 lr: 0.02
2019-03-28 14:08:36 iteration: 35135 loss: 0.0044 lr: 0.02
2019-03-28 14:09:33 iteration: 35140 loss: 0.0038 lr: 0.02
2019-03-28 14:10:11 iteration: 35145 loss: 0.0040 lr: 0.02
2019-03-28 14:10:38 iteration: 35150 loss: 0.0040 lr: 0.02
2019-03-28 14:10:50 iteration: 35155 loss: 0.0081 lr: 0.02
2019-03-28 14:11:25 iteration: 35160 loss: 0.0031 lr: 0.02
2019-03-28 14:12:04 iteration: 35165 loss: 0.0049 lr: 0.02
2019-03-28 14:12:48 iteration: 35170 loss: 0.0032 lr: 0.02
2019-03-28 14:14:16 iteration: 35175 loss: 0.0032 lr: 0.02
2019-03-28 14:15:06 iteration: 35180 loss: 0.0045 lr: 0.02
2019-03-28 14:15:32 iteration: 35185 loss: 0.0054 lr: 0.02
2019-03-28 14:16:25 iteration: 35190 loss: 0.0041 lr: 0.02
2019-03-28 14:16:53 iteration: 35195 loss: 0.0040 lr: 0.02
2019-03-28 14:17:10 iteration: 35200 loss: 0.0040 lr: 0.02
2019-03-28 14:17:36 iteration: 35205 loss: 0.0050 lr: 0.02
2019-03-28 14:18:04 iteration: 35210 loss: 0.0042 lr: 0.02
2019-03-28 14:18:32 iteration: 35215 loss: 0.0067 lr: 0.02
2019-03-28 14:19:05 iteration: 35220 loss: 0.0032 lr: 0.02
2019-03-28 14:19:30 iteration: 35225 loss: 0.0048 lr: 0.02
2019-03-28 14:19:38 iteration: 35230 loss: 0.0049 lr: 0.02
2019-03-28 14:20:36 iteration: 35235 loss: 0.0046 lr: 0.02
2019-03-28 14:21:08 iteration: 35240 loss: 0.0054 lr: 0.02
2019-03-28 14:21:39 iteration: 35245 loss: 0.0038 lr: 0.02
2019-03-28 14:23:28 iteration: 35250 loss: 0.0034 lr: 0.02
2019-03-28 14:24:15 iteration: 35255 loss: 0.0032 lr: 0.02
2019-03-28 14:24:35 iteration: 35260 loss: 0.0044 lr: 0.02
2019-03-28 14:24:58 iteration: 35265 loss: 0.0030 lr: 0.02
2019-03-28 14:25:28 iteration: 35270 loss: 0.0043 lr: 0.02
2019-03-28 14:26:02 iteration: 35275 loss: 0.0045 lr: 0.02
2019-03-28 14:26:38 iteration: 35280 loss: 0.0043 lr: 0.02
2019-03-28 14:26:52 iteration: 35285 loss: 0.0039 lr: 0.02
2019-03-28 14:28:25 iteration: 35290 loss: 0.0034 lr: 0.02
2019-03-28 14:29:47 iteration: 35295 loss: 0.0032 lr: 0.02
2019-03-28 14:30:03 iteration: 35300 loss: 0.0044 lr: 0.02
2019-03-28 14:30:26 iteration: 35305 loss: 0.0044 lr: 0.02
2019-03-28 14:31:33 iteration: 35310 loss: 0.0041 lr: 0.02
2019-03-28 14:31:52 iteration: 35315 loss: 0.0047 lr: 0.02
2019-03-28 14:32:58 iteration: 35320 loss: 0.0033 lr: 0.02
2019-03-28 14:33:47 iteration: 35325 loss: 0.0052 lr: 0.02
2019-03-28 14:34:21 iteration: 35330 loss: 0.0042 lr: 0.02
2019-03-28 14:35:04 iteration: 35335 loss: 0.0051 lr: 0.02
2019-03-28 14:36:18 iteration: 35340 loss: 0.0031 lr: 0.02
2019-03-28 14:36:34 iteration: 35345 loss: 0.0062 lr: 0.02
2019-03-28 14:36:56 iteration: 35350 loss: 0.0047 lr: 0.02
2019-03-28 14:37:38 iteration: 35355 loss: 0.0043 lr: 0.02
2019-03-28 14:38:30 iteration: 35360 loss: 0.0045 lr: 0.02
2019-03-28 14:38:51 iteration: 35365 loss: 0.0049 lr: 0.02
2019-03-28 14:39:36 iteration: 35370 loss: 0.0057 lr: 0.02
2019-03-28 14:40:35 iteration: 35375 loss: 0.0047 lr: 0.02
2019-03-28 14:41:39 iteration: 35380 loss: 0.0043 lr: 0.02
2019-03-28 14:42:39 iteration: 35385 loss: 0.0034 lr: 0.02
2019-03-28 14:43:57 iteration: 35390 loss: 0.0035 lr: 0.02
2019-03-28 14:44:42 iteration: 35395 loss: 0.0049 lr: 0.02
2019-03-28 14:45:35 iteration: 35400 loss: 0.0039 lr: 0.02
2019-03-28 14:46:15 iteration: 35405 loss: 0.0037 lr: 0.02
2019-03-28 14:47:49 iteration: 35410 loss: 0.0031 lr: 0.02
2019-03-28 14:48:09 iteration: 35415 loss: 0.0058 lr: 0.02
2019-03-28 14:48:20 iteration: 35420 loss: 0.0043 lr: 0.02
2019-03-28 14:49:37 iteration: 35425 loss: 0.0025 lr: 0.02
2019-03-28 14:49:53 iteration: 35430 loss: 0.0044 lr: 0.02
2019-03-28 14:51:01 iteration: 35435 loss: 0.0049 lr: 0.02
2019-03-28 14:51:24 iteration: 35440 loss: 0.0034 lr: 0.02
2019-03-28 14:52:03 iteration: 35445 loss: 0.0047 lr: 0.02
2019-03-28 14:52:40 iteration: 35450 loss: 0.0042 lr: 0.02
2019-03-28 14:53:30 iteration: 35455 loss: 0.0038 lr: 0.02
2019-03-28 14:53:46 iteration: 35460 loss: 0.0053 lr: 0.02
2019-03-28 14:55:24 iteration: 35465 loss: 0.0034 lr: 0.02
2019-03-28 14:55:40 iteration: 35470 loss: 0.0044 lr: 0.02
2019-03-28 14:55:55 iteration: 35475 loss: 0.0039 lr: 0.02
2019-03-28 14:56:07 iteration: 35480 loss: 0.0059 lr: 0.02
2019-03-28 14:56:31 iteration: 35485 loss: 0.0076 lr: 0.02
2019-03-28 14:57:32 iteration: 35490 loss: 0.0042 lr: 0.02
2019-03-28 14:58:14 iteration: 35495 loss: 0.0047 lr: 0.02
2019-03-28 14:59:20 iteration: 35500 loss: 0.0030 lr: 0.02
2019-03-28 14:59:54 iteration: 35505 loss: 0.0049 lr: 0.02
2019-03-28 15:00:29 iteration: 35510 loss: 0.0077 lr: 0.02
2019-03-28 15:01:51 iteration: 35515 loss: 0.0024 lr: 0.02
2019-03-28 15:02:19 iteration: 35520 loss: 0.0043 lr: 0.02
2019-03-28 15:02:42 iteration: 35525 loss: 0.0046 lr: 0.02
2019-03-28 15:03:44 iteration: 35530 loss: 0.0037 lr: 0.02
2019-03-28 15:04:15 iteration: 35535 loss: 0.0040 lr: 0.02
2019-03-28 15:04:44 iteration: 35540 loss: 0.0050 lr: 0.02
2019-03-28 15:05:22 iteration: 35545 loss: 0.0045 lr: 0.02
2019-03-28 15:05:58 iteration: 35550 loss: 0.0042 lr: 0.02
2019-03-28 15:06:50 iteration: 35555 loss: 0.0040 lr: 0.02
2019-03-28 15:07:03 iteration: 35560 loss: 0.0041 lr: 0.02
2019-03-28 15:07:20 iteration: 35565 loss: 0.0049 lr: 0.02
2019-03-28 15:08:41 iteration: 35570 loss: 0.0038 lr: 0.02
2019-03-28 15:08:55 iteration: 35575 loss: 0.0060 lr: 0.02
2019-03-28 15:09:19 iteration: 35580 loss: 0.0043 lr: 0.02
2019-03-28 15:09:41 iteration: 35585 loss: 0.0052 lr: 0.02
2019-03-28 15:11:09 iteration: 35590 loss: 0.0040 lr: 0.02
2019-03-28 15:11:49 iteration: 35595 loss: 0.0030 lr: 0.02
2019-03-28 15:12:54 iteration: 35600 loss: 0.0054 lr: 0.02
2019-03-28 15:13:31 iteration: 35605 loss: 0.0045 lr: 0.02
2019-03-28 15:13:59 iteration: 35610 loss: 0.0038 lr: 0.02
2019-03-28 15:14:25 iteration: 35615 loss: 0.0046 lr: 0.02
2019-03-28 15:14:51 iteration: 35620 loss: 0.0043 lr: 0.02
2019-03-28 15:15:38 iteration: 35625 loss: 0.0045 lr: 0.02
2019-03-28 15:16:13 iteration: 35630 loss: 0.0039 lr: 0.02
2019-03-28 15:16:25 iteration: 35635 loss: 0.0046 lr: 0.02
2019-03-28 15:16:53 iteration: 35640 loss: 0.0052 lr: 0.02
2019-03-28 15:18:03 iteration: 35645 loss: 0.0034 lr: 0.02
2019-03-28 15:19:06 iteration: 35650 loss: 0.0060 lr: 0.02
2019-03-28 15:19:21 iteration: 35655 loss: 0.0053 lr: 0.02
2019-03-28 15:20:07 iteration: 35660 loss: 0.0037 lr: 0.02
2019-03-28 15:21:05 iteration: 35665 loss: 0.0042 lr: 0.02
2019-03-28 15:21:43 iteration: 35670 loss: 0.0029 lr: 0.02
2019-03-28 15:22:08 iteration: 35675 loss: 0.0041 lr: 0.02
2019-03-28 15:22:55 iteration: 35680 loss: 0.0029 lr: 0.02
2019-03-28 15:23:24 iteration: 35685 loss: 0.0050 lr: 0.02
2019-03-28 15:23:44 iteration: 35690 loss: 0.0040 lr: 0.02
2019-03-28 15:24:51 iteration: 35695 loss: 0.0041 lr: 0.02
2019-03-28 15:25:23 iteration: 35700 loss: 0.0037 lr: 0.02
2019-03-28 15:26:23 iteration: 35705 loss: 0.0026 lr: 0.02
2019-03-28 15:27:24 iteration: 35710 loss: 0.0023 lr: 0.02
2019-03-28 15:27:44 iteration: 35715 loss: 0.0036 lr: 0.02
2019-03-28 15:28:32 iteration: 35720 loss: 0.0040 lr: 0.02
2019-03-28 15:28:46 iteration: 35725 loss: 0.0038 lr: 0.02
2019-03-28 15:29:07 iteration: 35730 loss: 0.0033 lr: 0.02
2019-03-28 15:30:01 iteration: 35735 loss: 0.0048 lr: 0.02
2019-03-28 15:30:13 iteration: 35740 loss: 0.0064 lr: 0.02
2019-03-28 15:30:39 iteration: 35745 loss: 0.0047 lr: 0.02
2019-03-28 15:31:31 iteration: 35750 loss: 0.0033 lr: 0.02
2019-03-28 15:32:20 iteration: 35755 loss: 0.0036 lr: 0.02
2019-03-28 15:33:43 iteration: 35760 loss: 0.0034 lr: 0.02
2019-03-28 15:34:25 iteration: 35765 loss: 0.0048 lr: 0.02
2019-03-28 15:34:44 iteration: 35770 loss: 0.0040 lr: 0.02
2019-03-28 15:34:57 iteration: 35775 loss: 0.0056 lr: 0.02
2019-03-28 15:35:43 iteration: 35780 loss: 0.0046 lr: 0.02
2019-03-28 15:36:28 iteration: 35785 loss: 0.0075 lr: 0.02
2019-03-28 15:36:59 iteration: 35790 loss: 0.0043 lr: 0.02
2019-03-28 15:37:37 iteration: 35795 loss: 0.0040 lr: 0.02
2019-03-28 15:38:26 iteration: 35800 loss: 0.0065 lr: 0.02
2019-03-28 15:39:01 iteration: 35805 loss: 0.0028 lr: 0.02
2019-03-28 15:39:21 iteration: 35810 loss: 0.0050 lr: 0.02
2019-03-28 15:40:18 iteration: 35815 loss: 0.0042 lr: 0.02
2019-03-28 15:40:36 iteration: 35820 loss: 0.0062 lr: 0.02
2019-03-28 15:41:19 iteration: 35825 loss: 0.0035 lr: 0.02
2019-03-28 15:41:37 iteration: 35830 loss: 0.0055 lr: 0.02
2019-03-28 15:41:50 iteration: 35835 loss: 0.0054 lr: 0.02
2019-03-28 15:42:06 iteration: 35840 loss: 0.0055 lr: 0.02
2019-03-28 15:42:23 iteration: 35845 loss: 0.0046 lr: 0.02
2019-03-28 15:43:02 iteration: 35850 loss: 0.0045 lr: 0.02
2019-03-28 15:43:37 iteration: 35855 loss: 0.0031 lr: 0.02
2019-03-28 15:44:38 iteration: 35860 loss: 0.0036 lr: 0.02
2019-03-28 15:45:27 iteration: 35865 loss: 0.0038 lr: 0.02
2019-03-28 15:45:44 iteration: 35870 loss: 0.0059 lr: 0.02
2019-03-28 15:46:45 iteration: 35875 loss: 0.0051 lr: 0.02
2019-03-28 15:47:11 iteration: 35880 loss: 0.0031 lr: 0.02
2019-03-28 15:47:23 iteration: 35885 loss: 0.0059 lr: 0.02
2019-03-28 15:48:13 iteration: 35890 loss: 0.0060 lr: 0.02
2019-03-28 15:48:56 iteration: 35895 loss: 0.0038 lr: 0.02
2019-03-28 15:50:27 iteration: 35900 loss: 0.0029 lr: 0.02
2019-03-28 15:50:45 iteration: 35905 loss: 0.0039 lr: 0.02
2019-03-28 15:51:06 iteration: 35910 loss: 0.0045 lr: 0.02
2019-03-28 15:52:20 iteration: 35915 loss: 0.0034 lr: 0.02
2019-03-28 15:52:44 iteration: 35920 loss: 0.0100 lr: 0.02
2019-03-28 15:53:33 iteration: 35925 loss: 0.0041 lr: 0.02
2019-03-28 15:53:55 iteration: 35930 loss: 0.0048 lr: 0.02
2019-03-28 15:54:37 iteration: 35935 loss: 0.0037 lr: 0.02
2019-03-28 15:55:38 iteration: 35940 loss: 0.0039 lr: 0.02
2019-03-28 15:55:52 iteration: 35945 loss: 0.0038 lr: 0.02
2019-03-28 15:56:13 iteration: 35950 loss: 0.0033 lr: 0.02
2019-03-28 15:56:55 iteration: 35955 loss: 0.0053 lr: 0.02
2019-03-28 15:57:19 iteration: 35960 loss: 0.0046 lr: 0.02
2019-03-28 15:57:39 iteration: 35965 loss: 0.0062 lr: 0.02
2019-03-28 15:57:56 iteration: 35970 loss: 0.0049 lr: 0.02
2019-03-28 16:00:17 iteration: 35975 loss: 0.0031 lr: 0.02
2019-03-28 16:00:33 iteration: 35980 loss: 0.0041 lr: 0.02
2019-03-28 16:00:51 iteration: 35985 loss: 0.0060 lr: 0.02
2019-03-28 16:02:07 iteration: 35990 loss: 0.0033 lr: 0.02
2019-03-28 16:02:42 iteration: 35995 loss: 0.0031 lr: 0.02
2019-03-28 16:03:00 iteration: 36000 loss: 0.0044 lr: 0.02
2019-03-28 16:03:28 iteration: 36005 loss: 0.0048 lr: 0.02
2019-03-28 16:04:02 iteration: 36010 loss: 0.0042 lr: 0.02
2019-03-28 16:04:34 iteration: 36015 loss: 0.0035 lr: 0.02
2019-03-28 16:04:52 iteration: 36020 loss: 0.0033 lr: 0.02
2019-03-28 16:05:19 iteration: 36025 loss: 0.0039 lr: 0.02
2019-03-28 16:05:33 iteration: 36030 loss: 0.0066 lr: 0.02
2019-03-28 16:06:09 iteration: 36035 loss: 0.0039 lr: 0.02
2019-03-28 16:06:25 iteration: 36040 loss: 0.0038 lr: 0.02
2019-03-28 16:06:57 iteration: 36045 loss: 0.0041 lr: 0.02
2019-03-28 16:07:09 iteration: 36050 loss: 0.0059 lr: 0.02
2019-03-28 16:07:46 iteration: 36055 loss: 0.0073 lr: 0.02
2019-03-28 16:08:00 iteration: 36060 loss: 0.0042 lr: 0.02
2019-03-28 16:09:03 iteration: 36065 loss: 0.0036 lr: 0.02
2019-03-28 16:09:53 iteration: 36070 loss: 0.0035 lr: 0.02
2019-03-28 16:10:13 iteration: 36075 loss: 0.0053 lr: 0.02
2019-03-28 16:11:03 iteration: 36080 loss: 0.0030 lr: 0.02
2019-03-28 16:11:32 iteration: 36085 loss: 0.0047 lr: 0.02
2019-03-28 16:11:52 iteration: 36090 loss: 0.0028 lr: 0.02
2019-03-28 16:12:21 iteration: 36095 loss: 0.0044 lr: 0.02
2019-03-28 16:12:37 iteration: 36100 loss: 0.0048 lr: 0.02
2019-03-28 16:13:34 iteration: 36105 loss: 0.0039 lr: 0.02
2019-03-28 16:14:08 iteration: 36110 loss: 0.0046 lr: 0.02
2019-03-28 16:14:51 iteration: 36115 loss: 0.0040 lr: 0.02
2019-03-28 16:15:03 iteration: 36120 loss: 0.0041 lr: 0.02
2019-03-28 16:15:19 iteration: 36125 loss: 0.0038 lr: 0.02
2019-03-28 16:16:13 iteration: 36130 loss: 0.0031 lr: 0.02
2019-03-28 16:17:14 iteration: 36135 loss: 0.0051 lr: 0.02
2019-03-28 16:18:44 iteration: 36140 loss: 0.0033 lr: 0.02
2019-03-28 16:19:33 iteration: 36145 loss: 0.0058 lr: 0.02
2019-03-28 16:19:53 iteration: 36150 loss: 0.0038 lr: 0.02
2019-03-28 16:20:08 iteration: 36155 loss: 0.0052 lr: 0.02
2019-03-28 16:21:51 iteration: 36160 loss: 0.0028 lr: 0.02
2019-03-28 16:22:56 iteration: 36165 loss: 0.0062 lr: 0.02
2019-03-28 16:23:16 iteration: 36170 loss: 0.0038 lr: 0.02
2019-03-28 16:24:55 iteration: 36175 loss: 0.0031 lr: 0.02
2019-03-28 16:25:11 iteration: 36180 loss: 0.0061 lr: 0.02
2019-03-28 16:26:26 iteration: 36185 loss: 0.0048 lr: 0.02
2019-03-28 16:27:06 iteration: 36190 loss: 0.0033 lr: 0.02
2019-03-28 16:27:44 iteration: 36195 loss: 0.0032 lr: 0.02
2019-03-28 16:28:04 iteration: 36200 loss: 0.0060 lr: 0.02
2019-03-28 16:28:38 iteration: 36205 loss: 0.0036 lr: 0.02
2019-03-28 16:29:41 iteration: 36210 loss: 0.0034 lr: 0.02
2019-03-28 16:30:15 iteration: 36215 loss: 0.0044 lr: 0.02
2019-03-28 16:31:05 iteration: 36220 loss: 0.0041 lr: 0.02
2019-03-28 16:31:54 iteration: 36225 loss: 0.0054 lr: 0.02
2019-03-28 16:32:27 iteration: 36230 loss: 0.0062 lr: 0.02
2019-03-28 16:34:04 iteration: 36235 loss: 0.0033 lr: 0.02
2019-03-28 16:34:46 iteration: 36240 loss: 0.0054 lr: 0.02
2019-03-28 16:35:39 iteration: 36245 loss: 0.0040 lr: 0.02
2019-03-28 16:36:01 iteration: 36250 loss: 0.0049 lr: 0.02
2019-03-28 16:36:37 iteration: 36255 loss: 0.0033 lr: 0.02
2019-03-28 16:37:26 iteration: 36260 loss: 0.0043 lr: 0.02
2019-03-28 16:38:23 iteration: 36265 loss: 0.0049 lr: 0.02
2019-03-28 16:39:18 iteration: 36270 loss: 0.0046 lr: 0.02
2019-03-28 16:40:08 iteration: 36275 loss: 0.0049 lr: 0.02
2019-03-28 16:40:57 iteration: 36280 loss: 0.0038 lr: 0.02
2019-03-28 16:41:51 iteration: 36285 loss: 0.0038 lr: 0.02
2019-03-28 16:42:32 iteration: 36290 loss: 0.0038 lr: 0.02
2019-03-28 16:42:56 iteration: 36295 loss: 0.0057 lr: 0.02
2019-03-28 16:44:10 iteration: 36300 loss: 0.0025 lr: 0.02
2019-03-28 16:44:56 iteration: 36305 loss: 0.0037 lr: 0.02
2019-03-28 16:45:07 iteration: 36310 loss: 0.0042 lr: 0.02
2019-03-28 16:45:59 iteration: 36315 loss: 0.0042 lr: 0.02
2019-03-28 16:47:07 iteration: 36320 loss: 0.0031 lr: 0.02
2019-03-28 16:47:56 iteration: 36325 loss: 0.0045 lr: 0.02
2019-03-28 16:48:07 iteration: 36330 loss: 0.0044 lr: 0.02
2019-03-28 16:48:54 iteration: 36335 loss: 0.0043 lr: 0.02
2019-03-28 16:49:06 iteration: 36340 loss: 0.0038 lr: 0.02
2019-03-28 16:49:35 iteration: 36345 loss: 0.0041 lr: 0.02
2019-03-28 16:50:10 iteration: 36350 loss: 0.0042 lr: 0.02
2019-03-28 16:50:53 iteration: 36355 loss: 0.0051 lr: 0.02
2019-03-28 16:51:39 iteration: 36360 loss: 0.0065 lr: 0.02
2019-03-28 16:51:58 iteration: 36365 loss: 0.0047 lr: 0.02
2019-03-28 16:52:15 iteration: 36370 loss: 0.0078 lr: 0.02
2019-03-28 16:52:47 iteration: 36375 loss: 0.0042 lr: 0.02
2019-03-28 16:53:05 iteration: 36380 loss: 0.0070 lr: 0.02
2019-03-28 16:53:38 iteration: 36385 loss: 0.0034 lr: 0.02
2019-03-28 16:53:51 iteration: 36390 loss: 0.0053 lr: 0.02
2019-03-28 16:54:32 iteration: 36395 loss: 0.0057 lr: 0.02
2019-03-28 16:54:58 iteration: 36400 loss: 0.0047 lr: 0.02
2019-03-28 16:55:18 iteration: 36405 loss: 0.0035 lr: 0.02
2019-03-28 16:55:39 iteration: 36410 loss: 0.0047 lr: 0.02
2019-03-28 16:56:06 iteration: 36415 loss: 0.0036 lr: 0.02
2019-03-28 16:56:35 iteration: 36420 loss: 0.0045 lr: 0.02
2019-03-28 16:57:02 iteration: 36425 loss: 0.0034 lr: 0.02
2019-03-28 16:57:16 iteration: 36430 loss: 0.0035 lr: 0.02
2019-03-28 16:57:29 iteration: 36435 loss: 0.0046 lr: 0.02
2019-03-28 16:57:51 iteration: 36440 loss: 0.0044 lr: 0.02
2019-03-28 16:58:20 iteration: 36445 loss: 0.0043 lr: 0.02
2019-03-28 16:58:34 iteration: 36450 loss: 0.0034 lr: 0.02
2019-03-28 16:59:13 iteration: 36455 loss: 0.0027 lr: 0.02
2019-03-28 16:59:37 iteration: 36460 loss: 0.0043 lr: 0.02
2019-03-28 16:59:50 iteration: 36465 loss: 0.0038 lr: 0.02
2019-03-28 17:00:32 iteration: 36470 loss: 0.0037 lr: 0.02
2019-03-28 17:01:30 iteration: 36475 loss: 0.0037 lr: 0.02
2019-03-28 17:02:15 iteration: 36480 loss: 0.0034 lr: 0.02
2019-03-28 17:02:42 iteration: 36485 loss: 0.0057 lr: 0.02
2019-03-28 17:03:29 iteration: 36490 loss: 0.0039 lr: 0.02
2019-03-28 17:04:16 iteration: 36495 loss: 0.0057 lr: 0.02
2019-03-28 17:05:08 iteration: 36500 loss: 0.0052 lr: 0.02
2019-03-28 17:06:06 iteration: 36505 loss: 0.0042 lr: 0.02
2019-03-28 17:07:00 iteration: 36510 loss: 0.0038 lr: 0.02
2019-03-28 17:07:19 iteration: 36515 loss: 0.0053 lr: 0.02
2019-03-28 17:07:30 iteration: 36520 loss: 0.0049 lr: 0.02
2019-03-28 17:08:24 iteration: 36525 loss: 0.0035 lr: 0.02
2019-03-28 17:09:13 iteration: 36530 loss: 0.0046 lr: 0.02
2019-03-28 17:10:21 iteration: 36535 loss: 0.0040 lr: 0.02
2019-03-28 17:11:03 iteration: 36540 loss: 0.0044 lr: 0.02
2019-03-28 17:11:24 iteration: 36545 loss: 0.0054 lr: 0.02
2019-03-28 17:12:13 iteration: 36550 loss: 0.0052 lr: 0.02
2019-03-28 17:12:36 iteration: 36555 loss: 0.0049 lr: 0.02
2019-03-28 17:13:03 iteration: 36560 loss: 0.0040 lr: 0.02
2019-03-28 17:13:58 iteration: 36565 loss: 0.0060 lr: 0.02
2019-03-28 17:14:23 iteration: 36570 loss: 0.0040 lr: 0.02
2019-03-28 17:15:18 iteration: 36575 loss: 0.0030 lr: 0.02
2019-03-28 17:15:29 iteration: 36580 loss: 0.0040 lr: 0.02
2019-03-28 17:15:48 iteration: 36585 loss: 0.0047 lr: 0.02
2019-03-28 17:15:57 iteration: 36590 loss: 0.0047 lr: 0.02
2019-03-28 17:16:38 iteration: 36595 loss: 0.0044 lr: 0.02
2019-03-28 17:16:56 iteration: 36600 loss: 0.0039 lr: 0.02
2019-03-28 17:18:02 iteration: 36605 loss: 0.0032 lr: 0.02
2019-03-28 17:18:27 iteration: 36610 loss: 0.0036 lr: 0.02
2019-03-28 17:18:45 iteration: 36615 loss: 0.0070 lr: 0.02
2019-03-28 17:19:11 iteration: 36620 loss: 0.0041 lr: 0.02
2019-03-28 17:19:51 iteration: 36625 loss: 0.0045 lr: 0.02
2019-03-28 17:20:11 iteration: 36630 loss: 0.0055 lr: 0.02
2019-03-28 17:20:34 iteration: 36635 loss: 0.0049 lr: 0.02
2019-03-28 17:21:37 iteration: 36640 loss: 0.0033 lr: 0.02
2019-03-28 17:22:35 iteration: 36645 loss: 0.0039 lr: 0.02
2019-03-28 17:23:31 iteration: 36650 loss: 0.0032 lr: 0.02
2019-03-28 17:24:32 iteration: 36655 loss: 0.0042 lr: 0.02
2019-03-28 17:25:12 iteration: 36660 loss: 0.0038 lr: 0.02
2019-03-28 17:25:32 iteration: 36665 loss: 0.0049 lr: 0.02
2019-03-28 17:26:02 iteration: 36670 loss: 0.0035 lr: 0.02
2019-03-28 17:27:04 iteration: 36675 loss: 0.0033 lr: 0.02
2019-03-28 17:27:37 iteration: 36680 loss: 0.0052 lr: 0.02
2019-03-28 17:28:26 iteration: 36685 loss: 0.0034 lr: 0.02
2019-03-28 17:29:33 iteration: 36690 loss: 0.0032 lr: 0.02
2019-03-28 17:30:22 iteration: 36695 loss: 0.0025 lr: 0.02
2019-03-28 17:30:38 iteration: 36700 loss: 0.0048 lr: 0.02
2019-03-28 17:31:04 iteration: 36705 loss: 0.0070 lr: 0.02
2019-03-28 17:31:53 iteration: 36710 loss: 0.0036 lr: 0.02
2019-03-28 17:32:01 iteration: 36715 loss: 0.0054 lr: 0.02
2019-03-28 17:32:18 iteration: 36720 loss: 0.0041 lr: 0.02
2019-03-28 17:33:04 iteration: 36725 loss: 0.0028 lr: 0.02
2019-03-28 17:33:33 iteration: 36730 loss: 0.0031 lr: 0.02
2019-03-28 17:34:47 iteration: 36735 loss: 0.0039 lr: 0.02
2019-03-28 17:35:10 iteration: 36740 loss: 0.0039 lr: 0.02
2019-03-28 17:35:44 iteration: 36745 loss: 0.0031 lr: 0.02
2019-03-28 17:36:23 iteration: 36750 loss: 0.0022 lr: 0.02
2019-03-28 17:36:44 iteration: 36755 loss: 0.0033 lr: 0.02
2019-03-28 17:37:17 iteration: 36760 loss: 0.0045 lr: 0.02
2019-03-28 17:38:07 iteration: 36765 loss: 0.0035 lr: 0.02
2019-03-28 17:38:50 iteration: 36770 loss: 0.0045 lr: 0.02
2019-03-28 17:39:14 iteration: 36775 loss: 0.0043 lr: 0.02
2019-03-28 17:39:50 iteration: 36780 loss: 0.0033 lr: 0.02
2019-03-28 17:40:52 iteration: 36785 loss: 0.0049 lr: 0.02
2019-03-28 17:41:05 iteration: 36790 loss: 0.0042 lr: 0.02
2019-03-28 17:42:43 iteration: 36795 loss: 0.0035 lr: 0.02
2019-03-28 17:42:57 iteration: 36800 loss: 0.0043 lr: 0.02
2019-03-28 17:43:19 iteration: 36805 loss: 0.0064 lr: 0.02
2019-03-28 17:44:30 iteration: 36810 loss: 0.0042 lr: 0.02
2019-03-28 17:44:45 iteration: 36815 loss: 0.0063 lr: 0.02
2019-03-28 17:45:20 iteration: 36820 loss: 0.0052 lr: 0.02
2019-03-28 17:45:34 iteration: 36825 loss: 0.0060 lr: 0.02
2019-03-28 17:45:54 iteration: 36830 loss: 0.0039 lr: 0.02
2019-03-28 17:46:28 iteration: 36835 loss: 0.0052 lr: 0.02
2019-03-28 17:47:25 iteration: 36840 loss: 0.0047 lr: 0.02
2019-03-28 17:47:55 iteration: 36845 loss: 0.0044 lr: 0.02
2019-03-28 17:48:23 iteration: 36850 loss: 0.0035 lr: 0.02
2019-03-28 17:49:46 iteration: 36855 loss: 0.0041 lr: 0.02
2019-03-28 17:50:04 iteration: 36860 loss: 0.0054 lr: 0.02
2019-03-28 17:50:31 iteration: 36865 loss: 0.0038 lr: 0.02
2019-03-28 17:51:18 iteration: 36870 loss: 0.0048 lr: 0.02
2019-03-28 17:51:38 iteration: 36875 loss: 0.0045 lr: 0.02
2019-03-28 17:51:57 iteration: 36880 loss: 0.0045 lr: 0.02
2019-03-28 17:53:00 iteration: 36885 loss: 0.0042 lr: 0.02
2019-03-28 17:53:16 iteration: 36890 loss: 0.0044 lr: 0.02
2019-03-28 17:53:48 iteration: 36895 loss: 0.0035 lr: 0.02
2019-03-28 17:54:26 iteration: 36900 loss: 0.0038 lr: 0.02
2019-03-28 17:55:01 iteration: 36905 loss: 0.0045 lr: 0.02
2019-03-28 17:55:15 iteration: 36910 loss: 0.0052 lr: 0.02
2019-03-28 17:55:31 iteration: 36915 loss: 0.0058 lr: 0.02
2019-03-28 17:55:43 iteration: 36920 loss: 0.0039 lr: 0.02
2019-03-28 17:56:22 iteration: 36925 loss: 0.0029 lr: 0.02
2019-03-28 17:56:44 iteration: 36930 loss: 0.0044 lr: 0.02
2019-03-28 17:57:00 iteration: 36935 loss: 0.0063 lr: 0.02
2019-03-28 17:57:57 iteration: 36940 loss: 0.0044 lr: 0.02
2019-03-28 17:58:32 iteration: 36945 loss: 0.0043 lr: 0.02
2019-03-28 17:59:31 iteration: 36950 loss: 0.0029 lr: 0.02
2019-03-28 17:59:52 iteration: 36955 loss: 0.0051 lr: 0.02
2019-03-28 18:01:12 iteration: 36960 loss: 0.0041 lr: 0.02
2019-03-28 18:01:31 iteration: 36965 loss: 0.0039 lr: 0.02
2019-03-28 18:02:26 iteration: 36970 loss: 0.0034 lr: 0.02
2019-03-28 18:02:46 iteration: 36975 loss: 0.0040 lr: 0.02
2019-03-28 18:02:59 iteration: 36980 loss: 0.0050 lr: 0.02
2019-03-28 18:03:38 iteration: 36985 loss: 0.0043 lr: 0.02
2019-03-28 18:03:51 iteration: 36990 loss: 0.0052 lr: 0.02
2019-03-28 18:04:14 iteration: 36995 loss: 0.0047 lr: 0.02
2019-03-28 18:04:34 iteration: 37000 loss: 0.0038 lr: 0.02
2019-03-28 18:05:01 iteration: 37005 loss: 0.0040 lr: 0.02
2019-03-28 18:05:47 iteration: 37010 loss: 0.0038 lr: 0.02
2019-03-28 18:06:41 iteration: 37015 loss: 0.0058 lr: 0.02
2019-03-28 18:07:11 iteration: 37020 loss: 0.0040 lr: 0.02
2019-03-28 18:07:25 iteration: 37025 loss: 0.0043 lr: 0.02
2019-03-28 18:07:51 iteration: 37030 loss: 0.0035 lr: 0.02
2019-03-28 18:08:14 iteration: 37035 loss: 0.0037 lr: 0.02
2019-03-28 18:08:41 iteration: 37040 loss: 0.0060 lr: 0.02
2019-03-28 18:10:06 iteration: 37045 loss: 0.0038 lr: 0.02
2019-03-28 18:10:18 iteration: 37050 loss: 0.0053 lr: 0.02
2019-03-28 18:11:32 iteration: 37055 loss: 0.0038 lr: 0.02
2019-03-28 18:12:19 iteration: 37060 loss: 0.0035 lr: 0.02
2019-03-28 18:13:08 iteration: 37065 loss: 0.0041 lr: 0.02
2019-03-28 18:14:25 iteration: 37070 loss: 0.0039 lr: 0.02
2019-03-28 18:15:53 iteration: 37075 loss: 0.0047 lr: 0.02
2019-03-28 18:16:45 iteration: 37080 loss: 0.0048 lr: 0.02
2019-03-28 18:17:42 iteration: 37085 loss: 0.0048 lr: 0.02
2019-03-28 18:19:20 iteration: 37090 loss: 0.0038 lr: 0.02
2019-03-28 18:20:08 iteration: 37095 loss: 0.0036 lr: 0.02
2019-03-28 18:20:25 iteration: 37100 loss: 0.0051 lr: 0.02
2019-03-28 18:21:42 iteration: 37105 loss: 0.0041 lr: 0.02
2019-03-28 18:22:44 iteration: 37110 loss: 0.0035 lr: 0.02
2019-03-28 18:22:54 iteration: 37115 loss: 0.0047 lr: 0.02
2019-03-28 18:23:23 iteration: 37120 loss: 0.0038 lr: 0.02
2019-03-28 18:23:52 iteration: 37125 loss: 0.0038 lr: 0.02
2019-03-28 18:24:11 iteration: 37130 loss: 0.0045 lr: 0.02
2019-03-28 18:24:51 iteration: 37135 loss: 0.0050 lr: 0.02
2019-03-28 18:26:10 iteration: 37140 loss: 0.0038 lr: 0.02
2019-03-28 18:26:41 iteration: 37145 loss: 0.0028 lr: 0.02
2019-03-28 18:27:31 iteration: 37150 loss: 0.0035 lr: 0.02
2019-03-28 18:28:24 iteration: 37155 loss: 0.0033 lr: 0.02
2019-03-28 18:28:36 iteration: 37160 loss: 0.0039 lr: 0.02
2019-03-28 18:29:14 iteration: 37165 loss: 0.0071 lr: 0.02
2019-03-28 18:29:44 iteration: 37170 loss: 0.0041 lr: 0.02
2019-03-28 18:30:15 iteration: 37175 loss: 0.0035 lr: 0.02
2019-03-28 18:30:33 iteration: 37180 loss: 0.0040 lr: 0.02
2019-03-28 18:30:55 iteration: 37185 loss: 0.0039 lr: 0.02
2019-03-28 18:31:11 iteration: 37190 loss: 0.0043 lr: 0.02
2019-03-28 18:31:55 iteration: 37195 loss: 0.0042 lr: 0.02
2019-03-28 18:32:18 iteration: 37200 loss: 0.0052 lr: 0.02
2019-03-28 18:32:39 iteration: 37205 loss: 0.0033 lr: 0.02
2019-03-28 18:33:24 iteration: 37210 loss: 0.0032 lr: 0.02
2019-03-28 18:34:17 iteration: 37215 loss: 0.0057 lr: 0.02
2019-03-28 18:34:44 iteration: 37220 loss: 0.0040 lr: 0.02
2019-03-28 18:35:57 iteration: 37225 loss: 0.0033 lr: 0.02
2019-03-28 18:37:10 iteration: 37230 loss: 0.0036 lr: 0.02
2019-03-28 18:37:54 iteration: 37235 loss: 0.0056 lr: 0.02
2019-03-28 18:38:55 iteration: 37240 loss: 0.0038 lr: 0.02
2019-03-28 18:39:35 iteration: 37245 loss: 0.0028 lr: 0.02
2019-03-28 18:40:20 iteration: 37250 loss: 0.0033 lr: 0.02
2019-03-28 18:40:52 iteration: 37255 loss: 0.0033 lr: 0.02
2019-03-28 18:41:33 iteration: 37260 loss: 0.0039 lr: 0.02
2019-03-28 18:42:37 iteration: 37265 loss: 0.0046 lr: 0.02
2019-03-28 18:42:50 iteration: 37270 loss: 0.0054 lr: 0.02
2019-03-28 18:43:08 iteration: 37275 loss: 0.0053 lr: 0.02
2019-03-28 18:43:26 iteration: 37280 loss: 0.0036 lr: 0.02
2019-03-28 18:43:50 iteration: 37285 loss: 0.0041 lr: 0.02
2019-03-28 18:44:31 iteration: 37290 loss: 0.0034 lr: 0.02
2019-03-28 18:45:54 iteration: 37295 loss: 0.0042 lr: 0.02
2019-03-28 18:46:52 iteration: 37300 loss: 0.0031 lr: 0.02
2019-03-28 18:47:15 iteration: 37305 loss: 0.0031 lr: 0.02
2019-03-28 18:47:31 iteration: 37310 loss: 0.0056 lr: 0.02
2019-03-28 18:48:20 iteration: 37315 loss: 0.0027 lr: 0.02
2019-03-28 18:48:54 iteration: 37320 loss: 0.0039 lr: 0.02
2019-03-28 18:49:11 iteration: 37325 loss: 0.0065 lr: 0.02
2019-03-28 18:49:30 iteration: 37330 loss: 0.0040 lr: 0.02
2019-03-28 18:50:18 iteration: 37335 loss: 0.0036 lr: 0.02
2019-03-28 18:51:15 iteration: 37340 loss: 0.0038 lr: 0.02
2019-03-28 18:51:56 iteration: 37345 loss: 0.0039 lr: 0.02
2019-03-28 18:52:42 iteration: 37350 loss: 0.0037 lr: 0.02
2019-03-28 18:53:01 iteration: 37355 loss: 0.0043 lr: 0.02
2019-03-28 18:53:37 iteration: 37360 loss: 0.0047 lr: 0.02
2019-03-28 18:54:25 iteration: 37365 loss: 0.0039 lr: 0.02
2019-03-28 18:54:51 iteration: 37370 loss: 0.0068 lr: 0.02
2019-03-28 18:55:04 iteration: 37375 loss: 0.0044 lr: 0.02
2019-03-28 18:55:20 iteration: 37380 loss: 0.0034 lr: 0.02
2019-03-28 18:55:53 iteration: 37385 loss: 0.0037 lr: 0.02
2019-03-28 18:56:03 iteration: 37390 loss: 0.0062 lr: 0.02
2019-03-28 18:56:16 iteration: 37395 loss: 0.0040 lr: 0.02
2019-03-28 18:56:39 iteration: 37400 loss: 0.0048 lr: 0.02
2019-03-28 18:56:54 iteration: 37405 loss: 0.0048 lr: 0.02
2019-03-28 18:57:42 iteration: 37410 loss: 0.0038 lr: 0.02
2019-03-28 18:58:26 iteration: 37415 loss: 0.0036 lr: 0.02
2019-03-28 19:00:37 iteration: 37420 loss: 0.0029 lr: 0.02
2019-03-28 19:01:10 iteration: 37425 loss: 0.0042 lr: 0.02
2019-03-28 19:01:47 iteration: 37430 loss: 0.0027 lr: 0.02
2019-03-28 19:02:36 iteration: 37435 loss: 0.0038 lr: 0.02
2019-03-28 19:02:58 iteration: 37440 loss: 0.0058 lr: 0.02
2019-03-28 19:03:11 iteration: 37445 loss: 0.0059 lr: 0.02
2019-03-28 19:03:29 iteration: 37450 loss: 0.0041 lr: 0.02
2019-03-28 19:04:06 iteration: 37455 loss: 0.0046 lr: 0.02
2019-03-28 19:04:25 iteration: 37460 loss: 0.0035 lr: 0.02
2019-03-28 19:05:04 iteration: 37465 loss: 0.0036 lr: 0.02
2019-03-28 19:05:28 iteration: 37470 loss: 0.0034 lr: 0.02
2019-03-28 19:06:21 iteration: 37475 loss: 0.0028 lr: 0.02
2019-03-28 19:06:54 iteration: 37480 loss: 0.0028 lr: 0.02
2019-03-28 19:07:47 iteration: 37485 loss: 0.0030 lr: 0.02
2019-03-28 19:08:43 iteration: 37490 loss: 0.0028 lr: 0.02
2019-03-28 19:08:56 iteration: 37495 loss: 0.0041 lr: 0.02
2019-03-28 19:09:08 iteration: 37500 loss: 0.0048 lr: 0.02
2019-03-28 19:09:35 iteration: 37505 loss: 0.0038 lr: 0.02
2019-03-28 19:10:14 iteration: 37510 loss: 0.0042 lr: 0.02
2019-03-28 19:10:32 iteration: 37515 loss: 0.0047 lr: 0.02
2019-03-28 19:11:06 iteration: 37520 loss: 0.0031 lr: 0.02
2019-03-28 19:11:48 iteration: 37525 loss: 0.0028 lr: 0.02
2019-03-28 19:12:15 iteration: 37530 loss: 0.0036 lr: 0.02
2019-03-28 19:12:38 iteration: 37535 loss: 0.0043 lr: 0.02
2019-03-28 19:12:55 iteration: 37540 loss: 0.0061 lr: 0.02
2019-03-28 19:13:33 iteration: 37545 loss: 0.0038 lr: 0.02
2019-03-28 19:14:03 iteration: 37550 loss: 0.0035 lr: 0.02
2019-03-28 19:14:18 iteration: 37555 loss: 0.0057 lr: 0.02
2019-03-28 19:14:29 iteration: 37560 loss: 0.0053 lr: 0.02
2019-03-28 19:14:47 iteration: 37565 loss: 0.0050 lr: 0.02
2019-03-28 19:15:27 iteration: 37570 loss: 0.0049 lr: 0.02
2019-03-28 19:16:30 iteration: 37575 loss: 0.0034 lr: 0.02
2019-03-28 19:17:15 iteration: 37580 loss: 0.0040 lr: 0.02
2019-03-28 19:17:52 iteration: 37585 loss: 0.0040 lr: 0.02
2019-03-28 19:18:30 iteration: 37590 loss: 0.0037 lr: 0.02
2019-03-28 19:19:13 iteration: 37595 loss: 0.0036 lr: 0.02
2019-03-28 19:19:50 iteration: 37600 loss: 0.0069 lr: 0.02
2019-03-28 19:20:45 iteration: 37605 loss: 0.0047 lr: 0.02
2019-03-28 19:21:52 iteration: 37610 loss: 0.0038 lr: 0.02
2019-03-28 19:22:06 iteration: 37615 loss: 0.0054 lr: 0.02
2019-03-28 19:23:04 iteration: 37620 loss: 0.0031 lr: 0.02
2019-03-28 19:23:52 iteration: 37625 loss: 0.0035 lr: 0.02
2019-03-28 19:24:11 iteration: 37630 loss: 0.0037 lr: 0.02
2019-03-28 19:24:33 iteration: 37635 loss: 0.0054 lr: 0.02
2019-03-28 19:24:49 iteration: 37640 loss: 0.0043 lr: 0.02
2019-03-28 19:25:43 iteration: 37645 loss: 0.0031 lr: 0.02
2019-03-28 19:26:18 iteration: 37650 loss: 0.0049 lr: 0.02
2019-03-28 19:26:39 iteration: 37655 loss: 0.0042 lr: 0.02
2019-03-28 19:27:30 iteration: 37660 loss: 0.0041 lr: 0.02
2019-03-28 19:27:50 iteration: 37665 loss: 0.0054 lr: 0.02
2019-03-28 19:28:39 iteration: 37670 loss: 0.0043 lr: 0.02
2019-03-28 19:29:36 iteration: 37675 loss: 0.0032 lr: 0.02
2019-03-28 19:30:05 iteration: 37680 loss: 0.0029 lr: 0.02
2019-03-28 19:30:58 iteration: 37685 loss: 0.0032 lr: 0.02
2019-03-28 19:31:10 iteration: 37690 loss: 0.0046 lr: 0.02
2019-03-28 19:31:43 iteration: 37695 loss: 0.0042 lr: 0.02
2019-03-28 19:32:21 iteration: 37700 loss: 0.0036 lr: 0.02
2019-03-28 19:33:17 iteration: 37705 loss: 0.0048 lr: 0.02
2019-03-28 19:33:52 iteration: 37710 loss: 0.0033 lr: 0.02
2019-03-28 19:34:06 iteration: 37715 loss: 0.0037 lr: 0.02
2019-03-28 19:34:35 iteration: 37720 loss: 0.0029 lr: 0.02
2019-03-28 19:34:48 iteration: 37725 loss: 0.0053 lr: 0.02
2019-03-28 19:35:47 iteration: 37730 loss: 0.0042 lr: 0.02
2019-03-28 19:36:08 iteration: 37735 loss: 0.0053 lr: 0.02
2019-03-28 19:36:32 iteration: 37740 loss: 0.0052 lr: 0.02
2019-03-28 19:37:10 iteration: 37745 loss: 0.0044 lr: 0.02
2019-03-28 19:37:26 iteration: 37750 loss: 0.0048 lr: 0.02
2019-03-28 19:38:03 iteration: 37755 loss: 0.0055 lr: 0.02
2019-03-28 19:38:58 iteration: 37760 loss: 0.0048 lr: 0.02
2019-03-28 19:39:28 iteration: 37765 loss: 0.0031 lr: 0.02
2019-03-28 19:40:11 iteration: 37770 loss: 0.0041 lr: 0.02
2019-03-28 19:40:54 iteration: 37775 loss: 0.0042 lr: 0.02
2019-03-28 19:41:03 iteration: 37780 loss: 0.0054 lr: 0.02
2019-03-28 19:41:15 iteration: 37785 loss: 0.0038 lr: 0.02
2019-03-28 19:42:14 iteration: 37790 loss: 0.0050 lr: 0.02
2019-03-28 19:42:44 iteration: 37795 loss: 0.0043 lr: 0.02
2019-03-28 19:42:57 iteration: 37800 loss: 0.0048 lr: 0.02
2019-03-28 19:43:21 iteration: 37805 loss: 0.0062 lr: 0.02
2019-03-28 19:44:19 iteration: 37810 loss: 0.0042 lr: 0.02
2019-03-28 19:45:00 iteration: 37815 loss: 0.0063 lr: 0.02
2019-03-28 19:45:17 iteration: 37820 loss: 0.0056 lr: 0.02
2019-03-28 19:46:08 iteration: 37825 loss: 0.0042 lr: 0.02
2019-03-28 19:46:25 iteration: 37830 loss: 0.0059 lr: 0.02
2019-03-28 19:47:02 iteration: 37835 loss: 0.0039 lr: 0.02
2019-03-28 19:47:22 iteration: 37840 loss: 0.0041 lr: 0.02
2019-03-28 19:47:39 iteration: 37845 loss: 0.0049 lr: 0.02
2019-03-28 19:48:00 iteration: 37850 loss: 0.0038 lr: 0.02
2019-03-28 19:48:22 iteration: 37855 loss: 0.0046 lr: 0.02
2019-03-28 19:48:44 iteration: 37860 loss: 0.0052 lr: 0.02
2019-03-28 19:49:25 iteration: 37865 loss: 0.0054 lr: 0.02
2019-03-28 19:49:40 iteration: 37870 loss: 0.0061 lr: 0.02
2019-03-28 19:50:25 iteration: 37875 loss: 0.0052 lr: 0.02
2019-03-28 19:51:11 iteration: 37880 loss: 0.0039 lr: 0.02
2019-03-28 19:51:47 iteration: 37885 loss: 0.0046 lr: 0.02
2019-03-28 19:52:06 iteration: 37890 loss: 0.0045 lr: 0.02
2019-03-28 19:52:32 iteration: 37895 loss: 0.0040 lr: 0.02
2019-03-28 19:53:20 iteration: 37900 loss: 0.0048 lr: 0.02
2019-03-28 19:54:01 iteration: 37905 loss: 0.0040 lr: 0.02
2019-03-28 19:54:32 iteration: 37910 loss: 0.0041 lr: 0.02
2019-03-28 19:55:50 iteration: 37915 loss: 0.0033 lr: 0.02
2019-03-28 19:56:54 iteration: 37920 loss: 0.0031 lr: 0.02
2019-03-28 19:58:03 iteration: 37925 loss: 0.0038 lr: 0.02
2019-03-28 19:58:36 iteration: 37930 loss: 0.0045 lr: 0.02
2019-03-28 19:58:55 iteration: 37935 loss: 0.0053 lr: 0.02
2019-03-28 19:59:09 iteration: 37940 loss: 0.0058 lr: 0.02
2019-03-28 19:59:22 iteration: 37945 loss: 0.0043 lr: 0.02
2019-03-28 19:59:43 iteration: 37950 loss: 0.0047 lr: 0.02
2019-03-28 20:00:42 iteration: 37955 loss: 0.0041 lr: 0.02
2019-03-28 20:01:45 iteration: 37960 loss: 0.0048 lr: 0.02
2019-03-28 20:02:06 iteration: 37965 loss: 0.0044 lr: 0.02
2019-03-28 20:03:02 iteration: 37970 loss: 0.0037 lr: 0.02
2019-03-28 20:03:38 iteration: 37975 loss: 0.0035 lr: 0.02
2019-03-28 20:04:31 iteration: 37980 loss: 0.0031 lr: 0.02
2019-03-28 20:05:24 iteration: 37985 loss: 0.0035 lr: 0.02
2019-03-28 20:05:38 iteration: 37990 loss: 0.0058 lr: 0.02
2019-03-28 20:06:12 iteration: 37995 loss: 0.0046 lr: 0.02
2019-03-28 20:06:54 iteration: 38000 loss: 0.0053 lr: 0.02
2019-03-28 20:07:17 iteration: 38005 loss: 0.0049 lr: 0.02
2019-03-28 20:07:51 iteration: 38010 loss: 0.0042 lr: 0.02
2019-03-28 20:08:18 iteration: 38015 loss: 0.0042 lr: 0.02
2019-03-28 20:08:28 iteration: 38020 loss: 0.0051 lr: 0.02
2019-03-28 20:08:44 iteration: 38025 loss: 0.0045 lr: 0.02
2019-03-28 20:09:23 iteration: 38030 loss: 0.0042 lr: 0.02
2019-03-28 20:09:37 iteration: 38035 loss: 0.0044 lr: 0.02
2019-03-28 20:09:59 iteration: 38040 loss: 0.0054 lr: 0.02
2019-03-28 20:10:18 iteration: 38045 loss: 0.0052 lr: 0.02
2019-03-28 20:10:28 iteration: 38050 loss: 0.0050 lr: 0.02
2019-03-28 20:11:03 iteration: 38055 loss: 0.0033 lr: 0.02
2019-03-28 20:12:12 iteration: 38060 loss: 0.0033 lr: 0.02
2019-03-28 20:12:31 iteration: 38065 loss: 0.0046 lr: 0.02
2019-03-28 20:13:50 iteration: 38070 loss: 0.0046 lr: 0.02
2019-03-28 20:14:25 iteration: 38075 loss: 0.0039 lr: 0.02
2019-03-28 20:14:49 iteration: 38080 loss: 0.0041 lr: 0.02
2019-03-28 20:16:02 iteration: 38085 loss: 0.0026 lr: 0.02
2019-03-28 20:16:17 iteration: 38090 loss: 0.0046 lr: 0.02
2019-03-28 20:16:36 iteration: 38095 loss: 0.0044 lr: 0.02
2019-03-28 20:17:00 iteration: 38100 loss: 0.0048 lr: 0.02
2019-03-28 20:17:45 iteration: 38105 loss: 0.0029 lr: 0.02
2019-03-28 20:18:55 iteration: 38110 loss: 0.0039 lr: 0.02
2019-03-28 20:19:37 iteration: 38115 loss: 0.0036 lr: 0.02
2019-03-28 20:20:02 iteration: 38120 loss: 0.0040 lr: 0.02
2019-03-28 20:20:50 iteration: 38125 loss: 0.0036 lr: 0.02
2019-03-28 20:21:34 iteration: 38130 loss: 0.0043 lr: 0.02
2019-03-28 20:22:07 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],
 'all_joints_names': ['mouth_corner_left',
                      'mouth_corner_right',
                      'inner_brow_left',
                      'inner_brow_right',
                      'upper_lip',
                      'lower_lip',
                      'nose_corner_left',
                      'nose_corner_right',
                      'pinna_ear_left',
                      'pinna_ear_right'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\ease_dog_emotions_1_Steve '
            'North95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 5,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'c:\\users\\steve\\anaconda3\\envs\\ease_dog_emotions\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\Documentation_data-ease_dog_emotions_1_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 10,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 2000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                    'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-03-28 20:22:12 Restoring parameters from C:\Users\steve\Anaconda3\envs\ease_dog_emotions\dev\deepcutlab_projects\ease_dog_emotions\ease_dog_emotions_1-Steve North-2019-03-13\dlc-models\iteration-1\ease_dog_emotions_1Mar13-trainset95shuffle1\train\snapshot-38000
2019-03-28 21:40:35 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],
 'all_joints_names': ['mouth_corner_left',
                      'mouth_corner_right',
                      'inner_brow_left',
                      'inner_brow_right',
                      'upper_lip',
                      'lower_lip',
                      'nose_corner_left',
                      'nose_corner_right',
                      'pinna_ear_left',
                      'pinna_ear_right'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\ease_dog_emotions_1_Steve '
            'North95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 5,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'c:\\users\\steve\\anaconda3\\envs\\ease_dog_emotions\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\Documentation_data-ease_dog_emotions_1_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 10,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 2000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                    'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-03-28 21:40:39 Restoring parameters from C:\Users\steve\Anaconda3\envs\ease_dog_emotions\dev\deepcutlab_projects\ease_dog_emotions\ease_dog_emotions_1-Steve North-2019-03-13\dlc-models\iteration-1\ease_dog_emotions_1Mar13-trainset95shuffle1\train\snapshot-38000
2019-03-28 23:04:15 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],
 'all_joints_names': ['mouth_corner_left',
                      'mouth_corner_right',
                      'inner_brow_left',
                      'inner_brow_right',
                      'upper_lip',
                      'lower_lip',
                      'nose_corner_left',
                      'nose_corner_right',
                      'pinna_ear_left',
                      'pinna_ear_right'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\ease_dog_emotions_1_Steve '
            'North95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 5,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'c:\\users\\steve\\anaconda3\\envs\\ease_dog_emotions\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\Documentation_data-ease_dog_emotions_1_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 10,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 2000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                    'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-03-28 23:04:19 Restoring parameters from C:\Users\steve\Anaconda3\envs\ease_dog_emotions\dev\deepcutlab_projects\ease_dog_emotions\ease_dog_emotions_1-Steve North-2019-03-13\dlc-models\iteration-1\ease_dog_emotions_1Mar13-trainset95shuffle1\train\snapshot-38000
2019-03-29 00:28:23 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],
 'all_joints_names': ['mouth_corner_left',
                      'mouth_corner_right',
                      'inner_brow_left',
                      'inner_brow_right',
                      'upper_lip',
                      'lower_lip',
                      'nose_corner_left',
                      'nose_corner_right',
                      'pinna_ear_left',
                      'pinna_ear_right'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\ease_dog_emotions_1_Steve '
            'North95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 5,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'c:\\users\\steve\\anaconda3\\envs\\ease_dog_emotions\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\Documentation_data-ease_dog_emotions_1_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 10,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 2000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                    'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-03-29 00:28:27 Restoring parameters from C:\Users\steve\Anaconda3\envs\ease_dog_emotions\dev\deepcutlab_projects\ease_dog_emotions\ease_dog_emotions_1-Steve North-2019-03-13\dlc-models\iteration-1\ease_dog_emotions_1Mar13-trainset95shuffle1\train\snapshot-38000
2019-03-29 00:58:33 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],
 'all_joints_names': ['mouth_corner_left',
                      'mouth_corner_right',
                      'inner_brow_left',
                      'inner_brow_right',
                      'upper_lip',
                      'lower_lip',
                      'nose_corner_left',
                      'nose_corner_right',
                      'pinna_ear_left',
                      'pinna_ear_right'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\ease_dog_emotions_1_Steve '
            'North95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 5,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'c:\\users\\steve\\anaconda3\\envs\\ease_dog_emotions\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_ease_dog_emotions_1Mar13\\Documentation_data-ease_dog_emotions_1_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 10,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                 'North-2019-03-13',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 2000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\steve\\Anaconda3\\envs\\ease_dog_emotions\\dev\\deepcutlab_projects\\ease_dog_emotions\\ease_dog_emotions_1-Steve '
                    'North-2019-03-13\\dlc-models\\iteration-1\\ease_dog_emotions_1Mar13-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-03-29 00:58:36 Restoring parameters from C:\Users\steve\Anaconda3\envs\ease_dog_emotions\dev\deepcutlab_projects\ease_dog_emotions\ease_dog_emotions_1-Steve North-2019-03-13\dlc-models\iteration-1\ease_dog_emotions_1Mar13-trainset95shuffle1\train\snapshot-38000
